{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xaju-DMYhuw"
      },
      "source": [
        "Here is the **Gemini Edition** of the AI Interviewer.\n",
        "\n",
        "This version is optimized for **Google's Gemini 1.5 Flash**, which is faster, cheaper (has a generous free tier), and supports native JSON output for the grading report.\n",
        "\n",
        "### **1. Prerequisites**\n",
        "\n",
        "You need a Google AI Studio API Key (Free) and the Google SDK.\n",
        "\n",
        "```bash\n",
        "pip install google-generativeai gradio gTTS speechrecognition pydub numpy\n",
        "\n",
        "```\n",
        "\n",
        "*(Note: You also need `ffmpeg` installed on your system for audio processing, which is standard for audio apps).*\n",
        "\n",
        "### **2. The Full Code (`app_gemini.py`)**\n",
        "\n",
        "```python\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Get your free key from: https://aistudio.google.com/app/apikey\n",
        "# os.environ[\"GEMINI_API_KEY\"] = \"YOUR_GOOGLE_API_KEY\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# --- GLOBAL SETTINGS ---\n",
        "# Set to True to bypass real API calls during UI testing\n",
        "MOCK_MODE = False\n",
        "\n",
        "class InterviewManager:\n",
        "    def __init__(self):\n",
        "        self.chat_session = None\n",
        "        self.job_role = \"\"\n",
        "        self.conversation_log = [] # Stores [(\"User\", \"AI\"), ...] for Gradio\n",
        "\n",
        "    def initialize_interview(self, job_role, resume_text):\n",
        "        \"\"\"\n",
        "        Sets up the Gemini Chat Session with a specific System Instruction.\n",
        "        \"\"\"\n",
        "        self.job_role = job_role\n",
        "        self.conversation_log = []\n",
        "        \n",
        "        # 1. Define the Persona (System Instruction)\n",
        "        system_instruction = f\"\"\"\n",
        "        ROLE: You are an expert Technical Recruiter interviewing a candidate for the role of: '{job_role}'.\n",
        "        \n",
        "        CONTEXT:\n",
        "        Candidate Resume Summary: {resume_text}\n",
        "        \n",
        "        RULES:\n",
        "        1. Ask ONE clear question at a time.\n",
        "        2. Start by asking them to introduce themselves.\n",
        "        3. If the candidate answers vaguely, ask a follow-up probing question.\n",
        "        4. Be professional but neutral.\n",
        "        5. Keep your responses concise (under 3 sentences) so the conversation flows fast.\n",
        "        \"\"\"\n",
        "        \n",
        "        # 2. Initialize Model\n",
        "        # Gemini 1.5 Flash is fastest for real-time chat\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=\"gemini-1.5-flash\",\n",
        "            system_instruction=system_instruction\n",
        "        )\n",
        "        \n",
        "        # 3. Start Chat (History is managed automatically by this object)\n",
        "        self.chat_session = model.start_chat(history=[])\n",
        "        \n",
        "        return f\"Gemini is ready to interview for {job_role}. Click 'Start'!\"\n",
        "\n",
        "    def process_response(self, audio_filepath, text_input):\n",
        "        \"\"\"\n",
        "        Core Loop: Audio/Text -> STT -> Gemini -> TTS -> Audio/Text\n",
        "        \"\"\"\n",
        "        user_message = \"\"\n",
        "        \n",
        "        # --- A. HEAR (Speech to Text) ---\n",
        "        if audio_filepath:\n",
        "            r = sr.Recognizer()\n",
        "            with sr.AudioFile(audio_filepath) as source:\n",
        "                audio_data = r.record(source)\n",
        "                try:\n",
        "                    # Uses Google's free Speech Recognition API\n",
        "                    user_message = r.recognize_google(audio_data)\n",
        "                except sr.UnknownValueError:\n",
        "                    return self.conversation_log, None, None, \"Could not understand audio.\"\n",
        "                except sr.RequestError:\n",
        "                    return self.conversation_log, None, None, \"Speech API Error.\"\n",
        "        elif text_input:\n",
        "            user_message = text_input\n",
        "        else:\n",
        "            return self.conversation_log, None, None, \"\"\n",
        "\n",
        "        # --- B. THINK (Gemini Brain) ---\n",
        "        ai_response_text = \"\"\n",
        "        \n",
        "        if MOCK_MODE:\n",
        "            time.sleep(1)\n",
        "            ai_response_text = f\"That is interesting. Tell me more about your experience with {self.job_role}?\"\n",
        "        else:\n",
        "            try:\n",
        "                # Send message to Gemini\n",
        "                response = self.chat_session.send_message(user_message)\n",
        "                ai_response_text = response.text\n",
        "            except Exception as e:\n",
        "                ai_response_text = f\"Gemini Error: {str(e)}\"\n",
        "\n",
        "        # Update Gradio Log\n",
        "        self.conversation_log.append((user_message, ai_response_text))\n",
        "\n",
        "        # --- C. SPEAK (Text to Speech) ---\n",
        "        audio_output_path = None\n",
        "        if not MOCK_MODE:\n",
        "            try:\n",
        "                # gTTS is a free Google TTS wrapper\n",
        "                tts = gTTS(text=ai_response_text, lang='en', slow=False)\n",
        "                audio_output_path = \"temp_ai_response.mp3\"\n",
        "                tts.save(audio_output_path)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return self.conversation_log, audio_output_path, None, \"\" # Returns clear inputs\n",
        "\n",
        "    def generate_final_report(self):\n",
        "        \"\"\"\n",
        "        The 'Grader' Logic - Uses Gemini's JSON Mode\n",
        "        \"\"\"\n",
        "        if not self.chat_session:\n",
        "            return \"No interview found.\"\n",
        "\n",
        "        # Extract history from the chat session\n",
        "        full_transcript = []\n",
        "        for msg in self.chat_session.history:\n",
        "            role = \"Interviewer\" if msg.role == \"model\" else \"Candidate\"\n",
        "            full_transcript.append(f\"{role}: {msg.parts[0].text}\")\n",
        "        \n",
        "        transcript_text = \"\\n\".join(full_transcript)\n",
        "        \n",
        "        # Grading Prompt\n",
        "        grader_prompt = f\"\"\"\n",
        "        Analyze this interview transcript for the role of '{self.job_role}'.\n",
        "        \n",
        "        TRANSCRIPT:\n",
        "        {transcript_text}\n",
        "        \n",
        "        OUTPUT INSTRUCTIONS:\n",
        "        Return a raw JSON object evaluating the candidate.\n",
        "        Use this schema:\n",
        "        {{\n",
        "            \"candidate_name\": \"String\",\n",
        "            \"score_out_of_10\": int,\n",
        "            \"pros\": [\"list\", \"of\", \"strings\"],\n",
        "            \"cons\": [\"list\", \"of\", \"strings\"],\n",
        "            \"verdict\": \"Hire\" or \"No Hire\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        if MOCK_MODE:\n",
        "            return {\"mock\": \"data\"}\n",
        "\n",
        "        try:\n",
        "            # Create a fresh model instance for grading (Stateless)\n",
        "            # We enforce MIME type for guaranteed JSON\n",
        "            grader_model = genai.GenerativeModel(\n",
        "                \"gemini-1.5-flash\",\n",
        "                generation_config={\"response_mime_type\": \"application/json\"}\n",
        "            )\n",
        "            \n",
        "            response = grader_model.generate_content(grader_prompt)\n",
        "            return json.loads(response.text)\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "# --- GRADIO UI ---\n",
        "manager = InterviewManager()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# ♊ Gemini AI Interviewer\")\n",
        "    \n",
        "    with gr.Tab(\"1. Setup\"):\n",
        "        role_input = gr.Textbox(label=\"Job Role\", value=\"Senior Python Developer\")\n",
        "        resume_input = gr.Textbox(label=\"Resume Text\", placeholder=\"Paste resume here...\", lines=3)\n",
        "        init_btn = gr.Button(\"Initialize Gemini\", variant=\"primary\")\n",
        "        status_out = gr.Textbox(label=\"System Status\", interactive=False)\n",
        "        \n",
        "        init_btn.click(manager.initialize_interview, [role_input, resume_input], status_out)\n",
        "\n",
        "    with gr.Tab(\"2. Interview\"):\n",
        "        chatbot = gr.Chatbot(label=\"Live Transcript\", height=400)\n",
        "        with gr.Row():\n",
        "            audio_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Your Answer (Voice)\")\n",
        "            text_in = gr.Textbox(label=\"Your Answer (Text)\")\n",
        "        \n",
        "        submit_btn = gr.Button(\"Reply\")\n",
        "        audio_out = gr.Audio(label=\"Gemini Speaks\", autoplay=True)\n",
        "        \n",
        "        # Function to handle submission\n",
        "        def run_turn(audio, text):\n",
        "            return manager.process_response(audio, text)\n",
        "\n",
        "        submit_btn.click(run_turn, [audio_in, text_in], [chatbot, audio_out, audio_in, text_in])\n",
        "        text_in.submit(run_turn, [audio_in, text_in], [chatbot, audio_out, audio_in, text_in])\n",
        "\n",
        "    with gr.Tab(\"3. Grade\"):\n",
        "        grade_btn = gr.Button(\"Generate Scorecard\", variant=\"stop\")\n",
        "        json_out = gr.JSON(label=\"Gemini Evaluation\")\n",
        "        grade_btn.click(manager.generate_final_report, None, json_out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n",
        "\n",
        "```\n",
        "\n",
        "### **3. Key Differences in Gemini Implementation**\n",
        "\n",
        "1. **`generation_config={\"response_mime_type\": \"application/json\"}`**:\n",
        "* In the `generate_final_report` function, we use this specific Gemini feature. It forces the model to output *only* valid JSON, meaning your code won't crash because the model added extra text like \"Here is your JSON:\". OpenAI requires a specific \"JSON Mode\" flag; Gemini makes it part of the config.\n",
        "\n",
        "\n",
        "2. **`chat_session` Object**:\n",
        "* Unlike OpenAI (where you often manually append to a list of dictionaries `[{role: user...}]`), Gemini's SDK has a `start_chat()` object that manages memory for you. We just call `chat.send_message()`.\n",
        "\n",
        "\n",
        "3. **Cost & Speed**:\n",
        "* We are using **Gemini 1.5 Flash**. This model is specifically designed for high-frequency, low-latency tasks like chat bots. It has a significantly larger free tier than GPT-4o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpZtV_2EXIPs",
        "outputId": "9bd7cee8-7192-4932-c14e-557abc53fe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (0.8.5)\n",
            "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (6.1.0)\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting speechrecognition\n",
            "  Downloading speechrecognition-3.14.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (0.25.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai) (4.21.12)\n",
            "Requirement already satisfied: pydantic in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (2.12.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Collecting protobuf (from google-generativeai)\n",
            "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (4.7.0)\n",
            "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.2.2)\n",
            "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.124.4)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (1.2.3)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio-client==2.0.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.17.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.0)\n",
            "Requirement already satisfied: typer-slim in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Collecting standard-aifc (from speechrecognition)\n",
            "  Downloading standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Collecting standard-chunk (from standard-aifc->speechrecognition)\n",
            "  Downloading standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\n",
            "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading speechrecognition-3.14.4-py3-none-any.whl (32.9 MB)\n",
            "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
            "   - -------------------------------------- 1.3/32.9 MB 5.7 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 2.9/32.9 MB 6.7 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 4.7/32.9 MB 7.0 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 6.6/32.9 MB 7.2 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 8.1/32.9 MB 7.2 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 9.7/32.9 MB 7.2 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 11.0/32.9 MB 7.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 12.1/32.9 MB 6.8 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 13.9/32.9 MB 6.8 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 15.5/32.9 MB 6.9 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 16.8/32.9 MB 6.9 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 18.6/32.9 MB 7.0 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 20.2/32.9 MB 7.0 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 21.5/32.9 MB 7.0 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 23.3/32.9 MB 7.0 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 26.5/32.9 MB 7.0 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 29.1/32.9 MB 7.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 29.9/32.9 MB 6.8 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 31.7/32.9 MB 6.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  32.8/32.9 MB 6.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 32.9/32.9 MB 6.4 MB/s eta 0:00:00\n",
            "Downloading standard_aifc-3.13.0-py3-none-any.whl (10 kB)\n",
            "Downloading standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\n",
            "Installing collected packages: standard-chunk, standard-aifc, protobuf, speechrecognition, gTTS\n",
            "\n",
            "  Attempting uninstall: protobuf\n",
            "\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ---------------- ----------------------- 2/5 [protobuf]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   ------------------------ --------------- 3/5 [speechrecognition]\n",
            "   -------------------------------- ------- 4/5 [gTTS]\n",
            "   ---------------------------------------- 5/5 [gTTS]\n",
            "\n",
            "Successfully installed gTTS-2.5.4 protobuf-5.29.5 speechrecognition-3.14.4 standard-aifc-3.13.0 standard-chunk-3.13.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mysql-connector-python 8.1.0 requires protobuf<=4.21.12,>=4.21.1, but you have protobuf 5.29.5 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai gradio gTTS speechrecognition pydub numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "msXbp0FJYuwj",
        "outputId": "16ff4c0c-8527-44eb-96eb-6fd7089f7a49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_19160\\4123897008.py:165: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Ocean()) as demo:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Get your free key from: https://aistudio.google.com/app/apikey\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyBbW3UmL22kiw4FppXyVrgTCS0V2Ko1N4s\" # Set your API Key here directly or as an environment variable\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# --- GLOBAL SETTINGS ---\n",
        "# Set to True to bypass real API calls during UI testing\n",
        "MOCK_MODE = False\n",
        "\n",
        "class InterviewManager:\n",
        "    def __init__(self):\n",
        "        self.chat_session = None\n",
        "        self.job_role = \"\"\n",
        "        self.conversation_log = [] # Stores [(\"User\", \"AI\"), ...] for Gradio\n",
        "\n",
        "    def initialize_interview(self, job_role, resume_text):\n",
        "        \"\"\"\n",
        "        Sets up the Gemini Chat Session with a specific System Instruction.\n",
        "        \"\"\"\n",
        "        self.job_role = job_role\n",
        "        self.conversation_log = []\n",
        "\n",
        "        # 1. Define the Persona (System Instruction)\n",
        "        system_instruction = f\"\"\"\n",
        "        ROLE: You are an expert Technical Recruiter interviewing a candidate for the role of: '{job_role}'.\n",
        "\n",
        "        CONTEXT:\n",
        "        Candidate Resume Summary: {resume_text}\n",
        "\n",
        "        RULES:\n",
        "        1. Ask ONE clear question at a time.\n",
        "        2. Start by asking them to introduce themselves.\n",
        "        3. If the candidate answers vaguely, ask a follow-up probing question.\n",
        "        4. Be professional but neutral.\n",
        "        5. Keep your responses concise (under 3 sentences) so the conversation flows fast.\n",
        "        \"\"\"\n",
        "\n",
        "        # 2. Initialize Model\n",
        "        # Gemini 1.5 Flash is fastest for real-time chat\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=\"gemini-1.5-flash\",\n",
        "            system_instruction=system_instruction\n",
        "        )\n",
        "\n",
        "        # 3. Start Chat (History is managed automatically by this object)\n",
        "        self.chat_session = model.start_chat(history=[])\n",
        "\n",
        "        return f\"Gemini is ready to interview for {job_role}. Click 'Start'!\"\n",
        "\n",
        "    def process_response(self, audio_filepath, text_input):\n",
        "        \"\"\"\n",
        "        Core Loop: Audio/Text -> STT -> Gemini -> TTS -> Audio/Text\n",
        "        \"\"\"\n",
        "        user_message = \"\"\n",
        "\n",
        "        # --- A. HEAR (Speech to Text) ---\n",
        "        if audio_filepath:\n",
        "            r = sr.Recognizer()\n",
        "            with sr.AudioFile(audio_filepath) as source:\n",
        "                audio_data = r.record(source)\n",
        "                try:\n",
        "                    # Uses Google's free Speech Recognition API\n",
        "                    user_message = r.recognize_google(audio_data)\n",
        "                except sr.UnknownValueError:\n",
        "                    return self.conversation_log, None, None, \"Could not understand audio.\"\n",
        "                except sr.RequestError:\n",
        "                    return self.conversation_log, None, None, \"Speech API Error.\"\n",
        "        elif text_input:\n",
        "            user_message = text_input\n",
        "        else:\n",
        "            return self.conversation_log, None, None, \"\"\n",
        "\n",
        "        # --- B. THINK (Gemini Brain) ---\n",
        "        ai_response_text = \"\"\n",
        "\n",
        "        if MOCK_MODE:\n",
        "            time.sleep(1)\n",
        "            ai_response_text = f\"That is interesting. Tell me more about your experience with {self.job_role}?\"\n",
        "        else:\n",
        "            try:\n",
        "                # Send message to Gemini\n",
        "                response = self.chat_session.send_message(user_message)\n",
        "                ai_response_text = response.text\n",
        "            except Exception as e:\n",
        "                ai_response_text = f\"Gemini Error: {str(e)}\"\n",
        "\n",
        "        # Update Gradio Log\n",
        "        self.conversation_log.append((user_message, ai_response_text))\n",
        "\n",
        "        # --- C. SPEAK (Text to Speech) ---\n",
        "        audio_output_path = None\n",
        "        if not MOCK_MODE:\n",
        "            try:\n",
        "                # gTTS is a free Google TTS wrapper\n",
        "                tts = gTTS(text=ai_response_text, lang='en', slow=False)\n",
        "                audio_output_path = \"temp_ai_response.mp3\"\n",
        "                tts.save(audio_output_path)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return self.conversation_log, audio_output_path, None, \"\" # Returns clear inputs\n",
        "\n",
        "    def generate_final_report(self):\n",
        "        \"\"\"\n",
        "        The 'Grader' Logic - Uses Gemini's JSON Mode\n",
        "        \"\"\"\n",
        "        if not self.chat_session:\n",
        "            return \"No interview found.\"\n",
        "\n",
        "        # Extract history from the chat session\n",
        "        full_transcript = []\n",
        "        for msg in self.chat_session.history:\n",
        "            role = \"Interviewer\" if msg.role == \"model\" else \"Candidate\"\n",
        "            full_transcript.append(f\"{role}: {msg.parts[0].text}\")\n",
        "\n",
        "        transcript_text = \"\\n\".join(full_transcript)\n",
        "\n",
        "        # Grading Prompt\n",
        "        grader_prompt = f\"\"\"\n",
        "        Analyze this interview transcript for the role of '{self.job_role}'.\n",
        "\n",
        "        TRANSCRIPT:\n",
        "        {transcript_text}\n",
        "\n",
        "        OUTPUT INSTRUCTIONS:\n",
        "        Return a raw JSON object evaluating the candidate.\n",
        "        Use this schema:\n",
        "        {{\n",
        "            \"candidate_name\": \"String\",\n",
        "            \"score_out_of_10\": int,\n",
        "            \"pros\": [\"list\", \"of\", \"strings\"],\n",
        "            \"cons\": [\"list\", \"of\", \"strings\"],\n",
        "            \"verdict\": \"Hire\" or \"No Hire\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        if MOCK_MODE:\n",
        "            return {\"mock\": \"data\"}\n",
        "\n",
        "        try:\n",
        "            # Create a fresh model instance for grading (Stateless)\n",
        "            # We enforce MIME type for guaranteed JSON\n",
        "            grader_model = genai.GenerativeModel(\n",
        "                \"gemini-1.5-flash\",\n",
        "                generation_config={\"response_mime_type\": \"application/json\"}\n",
        "            )\n",
        "\n",
        "            response = grader_model.generate_content(grader_prompt)\n",
        "            return json.loads(response.text)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "# --- GRADIO UI ---\n",
        "manager = InterviewManager()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Ocean()) as demo:\n",
        "    gr.Markdown(\"# ☢️ Gemini AI Interviewer\")\n",
        "\n",
        "    with gr.Tab(\"1. Setup\"):\n",
        "        role_input = gr.Textbox(label=\"Job Role\", value=\"Senior Python Developer\")\n",
        "        resume_input = gr.Textbox(label=\"Resume Text\", placeholder=\"Paste resume here...\", lines=3)\n",
        "        init_btn = gr.Button(\"Initialize Gemini\", variant=\"primary\")\n",
        "        status_out = gr.Textbox(label=\"System Status\", interactive=False)\n",
        "\n",
        "        init_btn.click(manager.initialize_interview, [role_input, resume_input], status_out)\n",
        "\n",
        "    with gr.Tab(\"2. Interview\"):\n",
        "        chatbot = gr.Chatbot(label=\"Live Transcript\", height=400)\n",
        "        with gr.Row():\n",
        "            audio_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Your Answer (Voice)\")\n",
        "            text_in = gr.Textbox(label=\"Your Answer (Text)\")\n",
        "\n",
        "        submit_btn = gr.Button(\"Reply\")\n",
        "        audio_out = gr.Audio(label=\"Gemini Speaks\", autoplay=True)\n",
        "\n",
        "        # Function to handle submission\n",
        "        def run_turn(audio, text):\n",
        "            return manager.process_response(audio, text)\n",
        "\n",
        "        submit_btn.click(run_turn, [audio_in, text_in], [chatbot, audio_out, audio_in, text_in])\n",
        "        text_in.submit(run_turn, [audio_in, text_in], [chatbot, audio_out, audio_in, text_in])\n",
        "\n",
        "    with gr.Tab(\"3. Grade\"):\n",
        "        grade_btn = gr.Button(\"Generate Scorecard\", variant=\"stop\")\n",
        "        json_out = gr.JSON(label=\"Gemini Evaluation\")\n",
        "        grade_btn.click(manager.generate_final_report, None, json_out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7V1ZmFrY2kd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFoPlnjBYhQl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eGhqA6oXKR5"
      },
      "source": [
        "Here is the **complete, execution-ready Gradio code** for your **AI Autonomous Interviewer & Grader**.\n",
        "\n",
        "This application includes:\n",
        "\n",
        "1. **Setup Phase:** Define the Job Role and Candidate details.\n",
        "2. **Interview Phase:** Voice-to-Voice (or Text) interaction with the AI.\n",
        "3. **Grading Phase:** One-click generation of the JSON Evaluation Scorecard based on the specific Job Role.\n",
        "\n",
        "### **Prerequisites**\n",
        "\n",
        "You need to install these libraries first:\n",
        "\n",
        "```bash\n",
        "pip install gradio openai numpy\n",
        "\n",
        "```\n",
        "\n",
        "### **The Full Code (`app.py`)**\n",
        "\n",
        "```python\n",
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Replace with your actual API key or set it in your environment variables\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# --- GLOBAL SETTINGS ---\n",
        "# Set this to True to test the UI without spending money on OpenAI credits\n",
        "MOCK_MODE = False\n",
        "\n",
        "class InterviewManager:\n",
        "    def __init__(self):\n",
        "        self.system_prompt = \"\"\n",
        "        self.conversation_history = []\n",
        "        self.job_role = \"\"\n",
        "        self.candidate_context = \"\"\n",
        "\n",
        "    def initialize_interview(self, job_role, resume_text):\n",
        "        \"\"\"Sets up the persona based on user input.\"\"\"\n",
        "        self.job_role = job_role\n",
        "        self.candidate_context = resume_text\n",
        "        self.conversation_history = []\n",
        "        \n",
        "        # Dynamic System Prompt\n",
        "        self.system_prompt = f\"\"\"\n",
        "        ROLE: You are an expert AI Recruiter interviewing a candidate for the role of: '{job_role}'.\n",
        "        \n",
        "        CONTEXT:\n",
        "        Candidate Resume Summary: {resume_text}\n",
        "        \n",
        "        RULES:\n",
        "        1. Ask ONE clear question at a time.\n",
        "        2. Start by asking them to introduce themselves.\n",
        "        3. If the candidate answers vaguely, ask a follow-up probing question.\n",
        "        4. Be professional but neutral.\n",
        "        5. Keep responses concise (under 3 sentences).\n",
        "        \"\"\"\n",
        "        \n",
        "        self.conversation_history.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
        "        return f\"Interview initialized for {job_role}. Click 'Start Interview' to begin.\"\n",
        "\n",
        "    def process_response(self, user_audio, user_text):\n",
        "        \"\"\"\n",
        "        Handles the Core Loop: Audio/Text Input -> LLM \"Brain\" -> Audio/Text Output\n",
        "        \"\"\"\n",
        "        user_message = \"\"\n",
        "        \n",
        "        # 1. Transcribe Audio (Input Ears)\n",
        "        if user_audio is not None:\n",
        "            if MOCK_MODE:\n",
        "                user_message = \"[Mock] I have experience with Python and SQL.\"\n",
        "            else:\n",
        "                try:\n",
        "                    # Gradio passes audio as a tuple (sample_rate, numpy array) or filepath\n",
        "                    # For OpenAI API, we need the file path.\n",
        "                    with open(user_audio, \"rb\") as audio_file:\n",
        "                        transcript = openai.audio.transcriptions.create(\n",
        "                            model=\"whisper-1\",\n",
        "                            file=audio_file\n",
        "                        )\n",
        "                    user_message = transcript.text\n",
        "                except Exception as e:\n",
        "                    return [(\"System Error\", str(e))], None\n",
        "        elif user_text:\n",
        "            user_message = user_text\n",
        "        else:\n",
        "            return self.format_chat(), None # No input\n",
        "\n",
        "        # Add User Input to History\n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "        # 2. Generate AI Response (The Brain)\n",
        "        ai_response_text = \"\"\n",
        "        if MOCK_MODE:\n",
        "            time.sleep(1)\n",
        "            ai_response_text = f\"That is interesting. Tell me more about how you handle database migrations in {self.job_role}?\"\n",
        "        else:\n",
        "            try:\n",
        "                response = openai.chat.completions.create(\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=self.conversation_history,\n",
        "                    temperature=0.7,\n",
        "                    max_tokens=150\n",
        "                )\n",
        "                ai_response_text = response.choices[0].message.content\n",
        "            except Exception as e:\n",
        "                ai_response_text = f\"Error calling OpenAI: {e}\"\n",
        "\n",
        "        self.conversation_history.append({\"role\": \"assistant\", \"content\": ai_response_text})\n",
        "\n",
        "        # 3. Generate Audio (The Mouth)\n",
        "        audio_output_path = None\n",
        "        if not MOCK_MODE:\n",
        "            try:\n",
        "                speech_file_path = \"ai_response.mp3\"\n",
        "                response = openai.audio.speech.create(\n",
        "                    model=\"tts-1\",\n",
        "                    voice=\"onyx\",\n",
        "                    input=ai_response_text\n",
        "                )\n",
        "                response.stream_to_file(speech_file_path)\n",
        "                audio_output_path = speech_file_path\n",
        "            except Exception:\n",
        "                pass # Skip audio on error\n",
        "\n",
        "        return self.format_chat(), audio_output_path\n",
        "\n",
        "    def format_chat(self):\n",
        "        \"\"\"Helper to format history for Gradio Chatbot.\"\"\"\n",
        "        # Gradio expects list of [user_msg, bot_msg]\n",
        "        formatted = []\n",
        "        for i in range(1, len(self.conversation_history), 2):\n",
        "            user_msg = self.conversation_history[i]['content']\n",
        "            # Check if there is a corresponding assistant response\n",
        "            if i+1 < len(self.conversation_history):\n",
        "                bot_msg = self.conversation_history[i+1]['content']\n",
        "                formatted.append([user_msg, bot_msg])\n",
        "        return formatted\n",
        "\n",
        "    def generate_final_report(self):\n",
        "        \"\"\"\n",
        "        The 'Grader' Logic - Generates JSON Scorecard\n",
        "        \"\"\"\n",
        "        if len(self.conversation_history) < 3:\n",
        "            return \"Not enough conversation data to grade.\"\n",
        "\n",
        "        transcript_text = json.dumps(self.conversation_history, indent=2)\n",
        "        \n",
        "        grader_prompt = f\"\"\"\n",
        "        *** SYSTEM PROMPT ***\n",
        "        You are an Expert Hiring Manager. Analyze the interview transcript below for the role of '{self.job_role}'.\n",
        "        \n",
        "        OUTPUT FORMAT: Valid JSON only.\n",
        "        {{\n",
        "          \"candidate_name\": \"Candidate\",\n",
        "          \"role_fit_score\": \"Integer (1-10)\",\n",
        "          \"technical_assessment\": {{\n",
        "            \"strengths\": [\"List strings\"],\n",
        "            \"weaknesses\": [\"List strings\"]\n",
        "          }},\n",
        "          \"behavioral_assessment\": {{\n",
        "            \"communication_style\": \"String\",\n",
        "            \"red_flags\": [\"List strings\"]\n",
        "          }},\n",
        "          \"hiring_recommendation\": \"Strong Hire | Hire | No Hire\",\n",
        "          \"reasoning\": \"String summary\"\n",
        "        }}\n",
        "        \n",
        "        TRANSCRIPT:\n",
        "        {transcript_text}\n",
        "        \"\"\"\n",
        "\n",
        "        if MOCK_MODE:\n",
        "            # Fake JSON for testing\n",
        "            mock_json = {\n",
        "                \"candidate_name\": \"Mock Candidate\",\n",
        "                \"role_fit_score\": 7,\n",
        "                \"technical_assessment\": {\"strengths\": [\"Python\"], \"weaknesses\": [\"SQL\"]},\n",
        "                \"hiring_recommendation\": \"Hire\",\n",
        "                \"reasoning\": \"Good basic skills.\"\n",
        "            }\n",
        "            return json.dumps(mock_json, indent=2)\n",
        "\n",
        "        try:\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"system\", \"content\": grader_prompt}],\n",
        "                response_format={ \"type\": \"json_object\" }\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"Error generating report: {e}\"\n",
        "\n",
        "# --- GRADIO UI SETUP ---\n",
        "\n",
        "interview_manager = InterviewManager()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🤖 AI Autonomous Interviewer & Grader\n",
        "    **Step 1:** Setup the Role. **Step 2:** Chat (Voice/Text). **Step 3:** Get the JSON Report.\n",
        "    \"\"\")\n",
        "    \n",
        "    with gr.Tab(\"1. Setup\"):\n",
        "        with gr.Row():\n",
        "            job_role_input = gr.Textbox(label=\"Job Role (Target)\", placeholder=\"e.g. Senior React Developer, B2B Sales Manager\", value=\"Software Engineer\")\n",
        "            resume_input = gr.Textbox(label=\"Candidate Resume / Context\", placeholder=\"Paste resume text here...\", lines=5)\n",
        "        \n",
        "        init_btn = gr.Button(\"Initialize Interviewer Persona\", variant=\"primary\")\n",
        "        setup_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "        \n",
        "        init_btn.click(\n",
        "            interview_manager.initialize_interview,\n",
        "            inputs=[job_role_input, resume_input],\n",
        "            outputs=setup_status\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"2. Interview Room\"):\n",
        "        chatbot = gr.Chatbot(label=\"Interview Transcript\", height=400)\n",
        "        \n",
        "        with gr.Row():\n",
        "            audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak Response\")\n",
        "            text_input = gr.Textbox(label=\"Or Type Response\", placeholder=\"Type here and press Enter...\")\n",
        "        \n",
        "        submit_btn = gr.Button(\"Submit Response\")\n",
        "        ai_audio_output = gr.Audio(label=\"AI Voice Response\", autoplay=True)\n",
        "\n",
        "        # Logic to handle inputs\n",
        "        def response_wrapper(audio, text):\n",
        "            history, audio_path = interview_manager.process_response(audio, text)\n",
        "            return history, audio_path, None, \"\" # Clear inputs\n",
        "\n",
        "        submit_btn.click(\n",
        "            response_wrapper,\n",
        "            inputs=[audio_input, text_input],\n",
        "            outputs=[chatbot, ai_audio_output, audio_input, text_input]\n",
        "        )\n",
        "        # Allow \"Enter\" key for text\n",
        "        text_input.submit(\n",
        "            response_wrapper,\n",
        "            inputs=[audio_input, text_input],\n",
        "            outputs=[chatbot, ai_audio_output, audio_input, text_input]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"3. Hiring Manager Report\"):\n",
        "        gr.Markdown(\"### 📊 Automated Evaluation Scorecard\")\n",
        "        generate_report_btn = gr.Button(\"End Interview & Generate Report\", variant=\"stop\")\n",
        "        json_output = gr.JSON(label=\"Final Grading JSON\")\n",
        "        \n",
        "        generate_report_btn.click(\n",
        "            interview_manager.generate_final_report,\n",
        "            inputs=None,\n",
        "            outputs=json_output\n",
        "        )\n",
        "\n",
        "# --- LAUNCH ---\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "```\n",
        "\n",
        "### **How to Use This Application**\n",
        "\n",
        "1. **Set your API Key:**\n",
        "* Uncomment line 9: `os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"` and paste your key.\n",
        "* *Or* set `MOCK_MODE = True` (line 14) to run it without an API key (it will give fake static responses).\n",
        "\n",
        "\n",
        "2. **Run the App:**\n",
        "```bash\n",
        "python app.py\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "3. **The Workflow:**\n",
        "* **Tab 1 (Setup):** Type \"Marketing Manager\" in Job Role. Paste a dummy resume. Click \"Initialize\".\n",
        "* **Tab 2 (Interview):**\n",
        "* Click the Microphone icon to record your voice.\n",
        "* Click \"Submit\".\n",
        "* Wait a few seconds. You will see the text transcript appear *and* hear the AI speak back to you.\n",
        "\n",
        "\n",
        "* **Tab 3 (Report):** Once you are done, go to Tab 3 and click \"End Interview\". You will get a professional JSON grading report tailored to \"Marketing Manager\".\n",
        "\n",
        "\n",
        "\n",
        "### **Why this is \"Production Level\" Architecture:**\n",
        "\n",
        "* **Separation of Concerns:** The logic (`InterviewManager` class) is separated from the UI (`gr.Blocks`).\n",
        "* **State Management:** It uses a Class instance to hold the conversation history, which allows context awareness (the AI knows what you said 3 turns ago).\n",
        "* **Error Handling:** It wraps API calls in `try/except` blocks so the app doesn't crash if the internet flickers or the API key is invalid.\n",
        "* **Dynamic Prompting:** The `system_prompt` is not hardcoded; it is injected with the specific `job_role` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDVJx94OYe8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_w5Ng_SYft7"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
