{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd313d3",
   "metadata": {},
   "source": [
    "\n",
    "# **OCR Bootcamp Notes**\n",
    "\n",
    "*(Optical Character Recognition)*\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **1. Introduction to OCR**\n",
    "\n",
    "### **What is OCR?**\n",
    "\n",
    "* OCR = **Optical Character Recognition**\n",
    "* Converts **printed or handwritten text in images** into **editable text**.\n",
    "* Works by detecting **characters, words, and text layout** from an image or document.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why OCR?**\n",
    "\n",
    "* Automates data entry.\n",
    "* Digitizes physical documents.\n",
    "* Enables **searchable PDFs**.\n",
    "* Used in banking, healthcare, transportation, retail.\n",
    "\n",
    "---\n",
    "\n",
    "### **Real-world Applications**\n",
    "\n",
    "* Scanning books into eBooks.\n",
    "* License Plate Recognition.\n",
    "* Invoice & Receipt Automation.\n",
    "* Passport/ID verification.\n",
    "* Subtitle extraction from videos.\n",
    "\n",
    "---\n",
    "\n",
    "### **OCR vs ICR**\n",
    "\n",
    "* **OCR**: Recognizes printed text.\n",
    "* **ICR**: Recognizes **handwritten text** using AI.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **2. How OCR Works**\n",
    "\n",
    "1. **Image Acquisition** â†’ Capture image/document.\n",
    "2. **Preprocessing** â†’ Clean image (noise removal, binarization).\n",
    "3. **Text Detection** â†’ Locate text regions.\n",
    "4. **Character Recognition** â†’ Extract text.\n",
    "5. **Post-processing** â†’ Correct errors.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **3. Image Preprocessing for OCR**\n",
    "\n",
    "**Why preprocessing?**\n",
    "Bad quality images â†’ Low OCR accuracy.\n",
    "Preprocessing helps clean the image for better results.\n",
    "\n",
    "### **Techniques**\n",
    "\n",
    "* **Grayscale conversion** â†’ Reduce complexity.\n",
    "* **Thresholding** â†’ Convert to black & white.\n",
    "\n",
    "  * Binary threshold.\n",
    "  * Adaptive threshold.\n",
    "* **Noise removal** â†’ Gaussian blur, Median filter.\n",
    "* **Morphological operations** â†’ Remove small artifacts.\n",
    "* **Deskewing** â†’ Correct tilted text.\n",
    "\n",
    "**Code Example (OpenCV Preprocessing):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbc00d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Use raw string for path\n",
    "img = cv2.imread(r'C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\images\\lifestyle-02.jpg')\n",
    "\n",
    "# Check if image is loaded\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Image not found. Check the file path.\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply threshold\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save processed image\n",
    "cv2.imwrite('images\\processed.jpg', thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033d9da",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… **4. OCR Engines & Libraries**\n",
    "\n",
    "* **Tesseract OCR** (most popular, by Google)\n",
    "* **EasyOCR** (Deep learning-based, supports multiple languages)\n",
    "* **PaddleOCR** (High accuracy)\n",
    "* **Google Vision API** (Cloud-based)\n",
    "\n",
    "---\n",
    "\n",
    "### **Installing Tesseract**\n",
    "\n",
    "**Windows/Linux Setup:**\n",
    "\n",
    "* Install Tesseract from official site.\n",
    "* Add path to environment variables.\n",
    "* Install Python wrapper:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic OCR in Python:**\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('text_image.png')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d2e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9528",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… **5. Advanced OCR Features**\n",
    "\n",
    "* **Multilingual OCR** â†’ Support for 100+ languages.\n",
    "* **Custom language models** â†’ Train for new fonts.\n",
    "* **Extracting structured data** â†’ Tables, forms.\n",
    "* **Confidence scores** â†’ Check accuracy.\n",
    "* **Handwriting recognition** â†’ Using deep learning (ICR).\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **6. Improving OCR Accuracy**\n",
    "\n",
    "* Use **high-resolution images**.\n",
    "* Apply **deskewing** & **denoising**.\n",
    "* Convert to **grayscale or binary**.\n",
    "* Train custom models for complex fonts.\n",
    "* Use **Deep Learning (CRNN)** for better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **7. OCR in Applications**\n",
    "\n",
    "* **Extract text from PDFs** using `pdf2image` + OCR.\n",
    "* **Real-time OCR** using webcam feed.\n",
    "* **Batch OCR** for multiple documents.\n",
    "* **Integrating OCR with Flask/FastAPI for APIs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e1f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pdf2image) (11.3.0)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\rahish\\anaconda3\\envs\\myenv\\lib\\site-packages (from pdf2image) (11.3.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05154ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pdf2image) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages\\pdf2image\\pdf2image.py:581\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    580\u001b[0m     env[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m poppler_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 581\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\cvenv\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\cvenv\\lib\\subprocess.py:1456\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1458\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdf2image\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_from_path\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m pages \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocument.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[0;32m      8\u001b[0m     text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(page)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages\\pdf2image\\pdf2image.py:127\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(poppler_path, PurePath):\n\u001b[0;32m    125\u001b[0m     poppler_path \u001b[38;5;241m=\u001b[39m poppler_path\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m--> 127\u001b[0m page_count \u001b[38;5;241m=\u001b[39m \u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mownerpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoppler_path\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[39;00m\n\u001b[0;32m    132\u001b[0m parsed_fmt, final_extension, parse_buffer_func, use_pdfcairo_format \u001b[38;5;241m=\u001b[39m _parse_format(\n\u001b[0;32m    133\u001b[0m     fmt, grayscale\n\u001b[0;32m    134\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages\\pdf2image\\pdf2image.py:607\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m     )\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "### **Example: Extract Text from PDF**\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "pages = convert_from_path('document.pdf', 300)\n",
    "for page in pages:\n",
    "    text = pytesseract.image_to_string(page)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff31d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5095850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2318c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 ---\n",
      "MD SHAHIL ANSARI\n",
      "\n",
      "Â® mohammadshahi|4u@gmai|.com ï¬‚ï¬‚ Linkedln Â©GitHub Â©+91 9708549289 ï¬‚ Greater N0lda UP\n",
      "\n",
      " \n",
      "\n",
      "Education\n",
      "\n",
      "Masterâ€™s in Computer Application Marwari College (8.88 CGPA) Ranchi, JH 2021 -2023\n",
      "Bachelorâ€™s in Computer Application DSPMU (8.51 CGPA) Ranchi, JH 2018 - 2021\n",
      "Technical Skills\n",
      "\n",
      "Languages and Tools : Python, SQL (MySQL, PostgreSQL), PowerBI, Excel, Git, GitHub, Mlï¬‚ow, NoSQL, Keras.\n",
      "Libraries & Frameworks : NumPy, Pandas, Matplotlib, Seaborn, PySpark, SKâ€”Learn, Bs4, Flask, Django, Fast API.\n",
      "\n",
      "Data Science & Machine Learning : Data Collection, Data Preprocessing, Data Visualization, Data Warehousing, Linear\n",
      "And Logistic regression, KNN, Decision Tree, Random forest, SVM and K Means\n",
      "Neural Networks, NLP, ETL, LLMS, RestAPI.\n",
      "\n",
      "Mathematics for ML & DL : Algebra, Statistics, Probability, Matrices\n",
      "\n",
      "Extra Tools : Dockers, AWS, Django, CI/ CD.\n",
      "\n",
      "Experience\n",
      "\n",
      "Data Science Trainer | Itvedant (Mar 2024 â€” Now)\n",
      "\n",
      "0 Conduct ofï¬‚ine classes, mock interviews, and practical sessions on data science while mentoring students pre-\n",
      "and postâ€”placement to enhance their skills and employability.\n",
      "Freelance Python Developer/ Part Time (2020 â€” 2024)\n",
      "0 Data science Trainer: Design Curriculum, Mentoring and taking online classes and Project Solution to\n",
      "increased growth and customer satisfaction. (FlipRobo, IIDST)\n",
      "0 Projects related to Web Scraping, Django, EDA, ETL, python, ML, and Data Science.\n",
      "Data Analyst |Fine Air Solutions (Feb 2023 â€”July 2023)\n",
      "\n",
      "0 Work on CRM, data collection from different department and stored also enhancing data accuracy and security.\n",
      "0 Perform statistical and predictive Analysis in projects using excel and PowerBI to minimize cost approx 8%.\n",
      "\n",
      "Internship\n",
      "Data Scientist Intern | PW Skills - (Oct 2023 â€” Feb 2024)\n",
      "0 Krishi Mitra â€”Website| Recommender, Prediction and Chatbot System\n",
      "0 Developed endâ€”toâ€”end l\\/[LProject using a Kaggle dataset and using LLMs create Chatbot as Farming Expert.\n",
      "\n",
      "Machine Learning Intern | Spotle ai - U anâ€”May 2o22)\n",
      "0 Customer Churn Prediction: Leverage predictive modeling with 92% accuracy to forecast customer attrition\n",
      "rates and recommend retention strategies, enhancing customer loyalty and reducing churn using PySpark 1.\n",
      "\n",
      "Projects\n",
      "\n",
      "Krishi Mitra â€”Website| Recommender, Prediction and Chatbot System @[ D e m 0]\n",
      "0 Developed endâ€”toâ€”end crop and fertilizer recommendation system or Plant Disease Prediction using a Kaggle dataset\n",
      "Chatbot as Farming Expert.\n",
      "\n",
      "0 Conducted extensive data preprocessing and feature engineering, Experiment with Different ML Models and\n",
      "Achieve 99% Accuracy in Random Forest techniques.\n",
      "\n",
      "0 Leveraged Deep learning for Image classiï¬cation Problem using RESNET model and got 99.2% Accuracy.\n",
      "0 Use Google Gemini API and integrate LLMs Chatbot as a Farmer Expert.\n",
      "\n",
      "Student Performance Prediction |end-to-end ML Prediction system @ | D emo |\n",
      "\n",
      "0 Task Performed: EDA, Visualization, Data Modeling, Documentation, Flask API, and Frontend, cloud hosting.\n",
      "0 Experiment with different ML models find best model with 88.4% accuracy And Predict Student mathâ€™s score.\n",
      "\n",
      "Achievements & Certiï¬cations\n",
      "0 Get a Data Science Nanodegree â€” Udacigz\n",
      "0 Earned Google Advance Data Analytics â€” Coursera, Google\n",
      "\n",
      "0 Machine Learning and AI projects with python - Udemy\n",
      "\n",
      "0 Earned a Badge of completion for the Openâ€”Access Data Science Virtual Experience Program â€” BA@\"gÂ§\n",
      "0 Achieved a top 10% ranking in a Data Science hackathon hosted by Spotle.ai.\n",
      "\n",
      "0 Python, Problem Solving, SQL â€” Hacker Rank\n",
      "\n",
      "INTRESTS: Travelling, Tech blogs, teaching.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(\"document.pdf\")\n",
    "\n",
    "for i, page in enumerate(doc):\n",
    "    # Render page to image (in memory)\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "\n",
    "    # OCR the image using Tesseract\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(f\"--- Page {i + 1} ---\")\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17683a6c",
   "metadata": {},
   "source": [
    "- PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee246b",
   "metadata": {},
   "source": [
    "## Exract data from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from ocr_utils import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "st.set_page_config(page_title=\"OCR Text Recognition\")\n",
    "st.title(\"ðŸ“ OCR Text Recognition with Pytesseract\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image with text\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "if uploaded_file:\n",
    "    image = load_image(uploaded_file.read())\n",
    "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
    "\n",
    "    thresh = preprocess_image(image)\n",
    "    st.image(thresh, caption=\"Preprocessed Image\", use_column_width=True)\n",
    "\n",
    "    st.subheader(\"ðŸ“„ Extracted Text\")\n",
    "    text = extract_text(thresh)\n",
    "    st.code(text)\n",
    "\n",
    "    st.subheader(\"ðŸ” Word Detection with Bounding Boxes\")\n",
    "    data = extract_data(thresh)\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    st.image(image, caption=\"Detected Words\", use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7f4ef",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âœ… **8. Projects & Case Studies**\n",
    "\n",
    "### **Beginner**\n",
    "\n",
    "âœ” Extract text from an image.\n",
    "âœ” Convert scanned PDF to editable text.\n",
    "\n",
    "### **Intermediate**\n",
    "\n",
    "âœ” License plate recognition.\n",
    "âœ” Business card reader using OCR + OpenCV.\n",
    "\n",
    "### **Advanced**\n",
    "\n",
    "âœ” Automated invoice processing with table extraction.\n",
    "âœ” Real-time subtitle extraction from video feed.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Practice Session**\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Define OCR and its real-world uses.\n",
    "2. Explain why image preprocessing is important for OCR.\n",
    "3. Write Python code to extract text from an image using Tesseract.\n",
    "4. How do you improve OCR accuracy?\n",
    "5. What is the difference between OCR and ICR?\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Assignments**\n",
    "\n",
    "1. Extract text from a scanned handwritten note.\n",
    "2. Create an OCR pipeline for multilingual documents.\n",
    "3. Implement OCR for real-time video stream using OpenCV.\n",
    "4. Process 100 scanned documents and export extracted text into Excel.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Tools & Libraries**\n",
    "\n",
    "* **OpenCV** â†’ Image preprocessing.\n",
    "* **Pytesseract** â†’ OCR engine.\n",
    "* **pdf2image** â†’ Convert PDFs to images.\n",
    "* **EasyOCR** â†’ Multilingual deep learning-based OCR.\n",
    "* **Flask/FastAPI** â†’ Build OCR APIs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518497ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee670df",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLicense plate contour not detected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mrecognize_plate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mds_materials\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m9.Deep_learning\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcv\u001b[39;49m\u001b[38;5;130;43;01m\\5\u001b[39;49;00m\u001b[38;5;124;43m.ocr_text_recognition\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcar.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mrecognize_plate\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Resize (optional for large images)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m     15\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Set path to tesseract.exe if needed\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def recognize_plate(image_path):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Resize (optional for large images)\n",
    "    img = cv2.resize(img, (600, 400))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise reduction\n",
    "    blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blur, 30, 200)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    plate_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        # Approximate the contour\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:  # Looks like a rectangle\n",
    "            plate_contour = approx\n",
    "            break\n",
    "\n",
    "    if plate_contour is not None:\n",
    "        # Create mask and extract plate region\n",
    "        mask = cv2.drawContours(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), [plate_contour], 0, (255, 255, 255), -1)\n",
    "        x, y, w, h = cv2.boundingRect(plate_contour)\n",
    "        plate = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # OCR\n",
    "        text = pytesseract.image_to_string(plate, config='--psm 8')\n",
    "        print(\"Detected Plate Text:\", text.strip())\n",
    "\n",
    "        # Optional: Show detected plate\n",
    "        cv2.imshow(\"Plate\", plate)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"License plate contour not detected.\")\n",
    "\n",
    "# Example usage\n",
    "recognize_plate(\"S:\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\car.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed to load image. Check format or path.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     exit()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Resize safely\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Continue processing...\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "# Path to image\n",
    "image_path = r\"car.jpg\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"âŒ File not found at: {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "if img is None:\n",
    "    print(\"âŒ Failed to load image. Check format or path.\")\n",
    "    exit()\n",
    "\n",
    "# Resize safely\n",
    "img = cv2.resize(img, (600, 400))\n",
    "# Continue processing...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3c8be",
   "metadata": {},
   "source": [
    "## Business carder reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81206e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ƒ Raw OCR Text:\n",
      "  \n",
      "\n",
      "Mariana Anderson\n",
      "\n",
      "Marketing Manager\n",
      "\n",
      "+123â€”456r789O\n",
      "+123â€”456r7890\n",
      "\n",
      "www real\\ygreats\\te.(om\n",
      "hel\\o@rea\\|ygreats>te.com\n",
      "\n",
      "123 Anywhere St., Any Qty, ST\n",
      "12345\n",
      "\n",
      "Business\n",
      "Logo\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Name: Mariana Anderson\n",
      "Email: []\n",
      "Phone: []\n",
      "Website: []\n",
      "Company: Logo\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# Optional: Set path to tesseract if not in PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def extract_business_card_info(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"âŒ Could not load image.\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # OCR to extract text\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    print(\"ðŸ“ƒ Raw OCR Text:\\n\", text)\n",
    "\n",
    "    # Regex-based extraction\n",
    "    email = re.findall(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', text)\n",
    "    phone = re.findall(r'(\\+?\\d[\\d\\s\\-().]{7,})', text)\n",
    "    website = re.findall(r'(https?://\\S+|www\\.\\S+)', text)\n",
    "\n",
    "    # Just mock logic for demo purposes\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    name = lines[0] if lines else \"\"\n",
    "    company = lines[-1] if len(lines) > 2 else \"\"\n",
    "\n",
    "    result = {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Website\": website,\n",
    "        \"Company\": company,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "data = extract_business_card_info(\"business.jpg\")\n",
    "for k, v in data.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90ed73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
