{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd313d3",
   "metadata": {},
   "source": [
    "\n",
    "# **OCR Bootcamp Notes**\n",
    "\n",
    "*(Optical Character Recognition)*\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **1. Introduction to OCR**\n",
    "\n",
    "### **What is OCR?**\n",
    "\n",
    "* OCR = **Optical Character Recognition**\n",
    "* Converts **printed or handwritten text in images** into **editable text**.\n",
    "* Works by detecting **characters, words, and text layout** from an image or document.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why OCR?**\n",
    "\n",
    "* Automates data entry.\n",
    "* Digitizes physical documents.\n",
    "* Enables **searchable PDFs**.\n",
    "* Used in banking, healthcare, transportation, retail.\n",
    "\n",
    "---\n",
    "\n",
    "### **Real-world Applications**\n",
    "\n",
    "* Scanning books into eBooks.\n",
    "* License Plate Recognition.\n",
    "* Invoice & Receipt Automation.\n",
    "* Passport/ID verification.\n",
    "* Subtitle extraction from videos.\n",
    "\n",
    "---\n",
    "\n",
    "### **OCR vs ICR**\n",
    "\n",
    "* **OCR**: Recognizes printed text.\n",
    "* **ICR**: Recognizes **handwritten text** using AI.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **2. How OCR Works**\n",
    "\n",
    "1. **Image Acquisition** ‚Üí Capture image/document.\n",
    "2. **Preprocessing** ‚Üí Clean image (noise removal, binarization).\n",
    "3. **Text Detection** ‚Üí Locate text regions.\n",
    "4. **Character Recognition** ‚Üí Extract text.\n",
    "5. **Post-processing** ‚Üí Correct errors.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **3. Image Preprocessing for OCR**\n",
    "\n",
    "**Why preprocessing?**\n",
    "Bad quality images ‚Üí Low OCR accuracy.\n",
    "Preprocessing helps clean the image for better results.\n",
    "\n",
    "### **Techniques**\n",
    "\n",
    "* **Grayscale conversion** ‚Üí Reduce complexity.\n",
    "* **Thresholding** ‚Üí Convert to black & white.\n",
    "\n",
    "  * Binary threshold.\n",
    "  * Adaptive threshold.\n",
    "* **Noise removal** ‚Üí Gaussian blur, Median filter.\n",
    "* **Morphological operations** ‚Üí Remove small artifacts.\n",
    "* **Deskewing** ‚Üí Correct tilted text.\n",
    "\n",
    "**Code Example (OpenCV Preprocessing):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dbc00d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Use raw string for path\n",
    "img = cv2.imread(r'C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\images\\lifestyle-02.jpg')\n",
    "\n",
    "# Check if image is loaded\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Image not found. Check the file path.\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply threshold\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save processed image\n",
    "cv2.imwrite('images\\processed.jpg', thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033d9da",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ **4. OCR Engines & Libraries**\n",
    "\n",
    "* **Tesseract OCR** (most popular, by Google)\n",
    "* **EasyOCR** (Deep learning-based, supports multiple languages)\n",
    "* **PaddleOCR** (High accuracy)\n",
    "* **Google Vision API** (Cloud-based)\n",
    "\n",
    "---\n",
    "\n",
    "### **Installing Tesseract**\n",
    "\n",
    "**Windows/Linux Setup:**\n",
    "\n",
    "* Install Tesseract from official site.\n",
    "* Add path to environment variables.\n",
    "* Install Python wrapper:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic OCR in Python:**\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('text_image.png')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d2e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9528",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ **5. Advanced OCR Features**\n",
    "\n",
    "* **Multilingual OCR** ‚Üí Support for 100+ languages.\n",
    "* **Custom language models** ‚Üí Train for new fonts.\n",
    "* **Extracting structured data** ‚Üí Tables, forms.\n",
    "* **Confidence scores** ‚Üí Check accuracy.\n",
    "* **Handwriting recognition** ‚Üí Using deep learning (ICR).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **6. Improving OCR Accuracy**\n",
    "\n",
    "* Use **high-resolution images**.\n",
    "* Apply **deskewing** & **denoising**.\n",
    "* Convert to **grayscale or binary**.\n",
    "* Train custom models for complex fonts.\n",
    "* Use **Deep Learning (CRNN)** for better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **7. OCR in Applications**\n",
    "\n",
    "* **Extract text from PDFs** using `pdf2image` + OCR.\n",
    "* **Real-time OCR** using webcam feed.\n",
    "* **Batch OCR** for multiple documents.\n",
    "* **Integrating OCR with Flask/FastAPI for APIs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e1f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pdf2image) (11.3.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Example: Extract Text from PDF**\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "pages = convert_from_path('document.pdf', 300)\n",
    "for page in pages:\n",
    "    text = pytesseract.image_to_string(page)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee246b",
   "metadata": {},
   "source": [
    "## Exract data from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from ocr_utils import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "st.set_page_config(page_title=\"OCR Text Recognition\")\n",
    "st.title(\"üìù OCR Text Recognition with Pytesseract\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image with text\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "if uploaded_file:\n",
    "    image = load_image(uploaded_file.read())\n",
    "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
    "\n",
    "    thresh = preprocess_image(image)\n",
    "    st.image(thresh, caption=\"Preprocessed Image\", use_column_width=True)\n",
    "\n",
    "    st.subheader(\"üìÑ Extracted Text\")\n",
    "    text = extract_text(thresh)\n",
    "    st.code(text)\n",
    "\n",
    "    st.subheader(\"üîç Word Detection with Bounding Boxes\")\n",
    "    data = extract_data(thresh)\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    st.image(image, caption=\"Detected Words\", use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7f4ef",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **8. Projects & Case Studies**\n",
    "\n",
    "### **Beginner**\n",
    "\n",
    "‚úî Extract text from an image.\n",
    "‚úî Convert scanned PDF to editable text.\n",
    "\n",
    "### **Intermediate**\n",
    "\n",
    "‚úî License plate recognition.\n",
    "‚úî Business card reader using OCR + OpenCV.\n",
    "\n",
    "### **Advanced**\n",
    "\n",
    "‚úî Automated invoice processing with table extraction.\n",
    "‚úî Real-time subtitle extraction from video feed.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Practice Session**\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Define OCR and its real-world uses.\n",
    "2. Explain why image preprocessing is important for OCR.\n",
    "3. Write Python code to extract text from an image using Tesseract.\n",
    "4. How do you improve OCR accuracy?\n",
    "5. What is the difference between OCR and ICR?\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Assignments**\n",
    "\n",
    "1. Extract text from a scanned handwritten note.\n",
    "2. Create an OCR pipeline for multilingual documents.\n",
    "3. Implement OCR for real-time video stream using OpenCV.\n",
    "4. Process 100 scanned documents and export extracted text into Excel.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Tools & Libraries**\n",
    "\n",
    "* **OpenCV** ‚Üí Image preprocessing.\n",
    "* **Pytesseract** ‚Üí OCR engine.\n",
    "* **pdf2image** ‚Üí Convert PDFs to images.\n",
    "* **EasyOCR** ‚Üí Multilingual deep learning-based OCR.\n",
    "* **Flask/FastAPI** ‚Üí Build OCR APIs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518497ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rasa-eA7WAmP0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
