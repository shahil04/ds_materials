{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58affa07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f26af5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53fb6a8d",
   "metadata": {},
   "source": [
    "Perfect üëç You want this **Face Recognition Assessment System integrated with Flask** so that:\n",
    "\n",
    "* Student takes **MCQ assessment** in a Flask web app.\n",
    "* Webcam is monitored in **real time**.\n",
    "* If:\n",
    "\n",
    "  * No face detected ‚Üí Show `\"Face not detected\"`.\n",
    "  * Multiple faces ‚Üí `\"Multiple faces detected\"` + capture photo evidence.\n",
    "  * Face turned (left, right, up, down) ‚Üí `\"Please look into the camera\"`.\n",
    "* After **10 violations**, exam auto-submits.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ System Architecture\n",
    "\n",
    "1. **Flask Backend**\n",
    "\n",
    "   * Serves MCQ exam page.\n",
    "   * Handles submission & scoring.\n",
    "\n",
    "2. **Frontend (HTML + JS)**\n",
    "\n",
    "   * Renders MCQs.\n",
    "   * Starts webcam stream ‚Üí sends frames to Flask (via AJAX/WebSocket).\n",
    "\n",
    "3. **Face Monitoring Service (Flask API + OpenCV + MediaPipe)**\n",
    "\n",
    "   * Receives frames.\n",
    "   * Detects face count & head pose.\n",
    "   * Returns JSON response (`status`, `fault_count`).\n",
    "\n",
    "4. **Auto-submit Trigger**\n",
    "\n",
    "   * If `fault_count >= 10` ‚Üí frontend auto-submits exam form.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Folder Structure\n",
    "\n",
    "```\n",
    "flask_face_exam/\n",
    "‚îÇ‚îÄ‚îÄ app.py                # Flask backend\n",
    "‚îÇ‚îÄ‚îÄ static/\n",
    "‚îÇ    ‚îî‚îÄ‚îÄ js/\n",
    "‚îÇ        ‚îî‚îÄ‚îÄ camera.js    # Webcam + monitoring\n",
    "‚îÇ‚îÄ‚îÄ templates/\n",
    "‚îÇ    ‚îî‚îÄ‚îÄ exam.html        # MCQ exam page\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Flask Backend (app.py)\n",
    "\n",
    "```python\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Face mesh model\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "fault_count = 0\n",
    "MAX_FAULTS = 10\n",
    "\n",
    "def analyze_frame(image):\n",
    "    global fault_count\n",
    "    h, w, _ = image.shape\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    status = \"Face OK\"\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        if len(results.multi_face_landmarks) > 1:\n",
    "            status = \"Multiple faces detected!\"\n",
    "            fault_count += 1\n",
    "        else:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                pitch, yaw, roll = get_head_pose(landmarks, w, h)\n",
    "                if yaw > 20:\n",
    "                    status = \"Look into camera (Right)\"\n",
    "                    fault_count += 1\n",
    "                elif yaw < -20:\n",
    "                    status = \"Look into camera (Left)\"\n",
    "                    fault_count += 1\n",
    "                elif pitch > 15:\n",
    "                    status = \"Look into camera (Down)\"\n",
    "                    fault_count += 1\n",
    "                elif pitch < -15:\n",
    "                    status = \"Look into camera (Up)\"\n",
    "                    fault_count += 1\n",
    "    else:\n",
    "        status = \"Face not detected!\"\n",
    "        fault_count += 1\n",
    "\n",
    "    return {\"status\": status, \"faults\": fault_count, \"max_faults\": MAX_FAULTS}\n",
    "\n",
    "\n",
    "def get_head_pose(landmarks, frame_w, frame_h):\n",
    "    face_2d, face_3d = [], []\n",
    "    for idx, lm in enumerate(landmarks.landmark):\n",
    "        if idx in [33, 263, 1, 61, 291, 199]:  # important points\n",
    "            x, y = int(lm.x * frame_w), int(lm.y * frame_h)\n",
    "            face_2d.append([x, y])\n",
    "            face_3d.append([x, y, lm.z])\n",
    "\n",
    "    face_2d = np.array(face_2d, dtype=np.float64)\n",
    "    face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "    focal_length = 1 * frame_w\n",
    "    cam_matrix = np.array([[focal_length, 0, frame_w / 2],\n",
    "                           [0, focal_length, frame_h / 2],\n",
    "                           [0, 0, 1]])\n",
    "    dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "    success, rot_vec, _ = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "    rmat, _ = cv2.Rodrigues(rot_vec)\n",
    "    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rmat)\n",
    "    return angles\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"exam.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/monitor\", methods=[\"POST\"])\n",
    "def monitor():\n",
    "    global fault_count\n",
    "    data = request.json[\"frame\"]\n",
    "    img_data = base64.b64decode(data.split(\",\")[1])\n",
    "    nparr = np.frombuffer(img_data, np.uint8)\n",
    "    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    result = analyze_frame(frame)\n",
    "\n",
    "    if result[\"faults\"] >= MAX_FAULTS:\n",
    "        result[\"submit\"] = True\n",
    "    else:\n",
    "        result[\"submit\"] = False\n",
    "\n",
    "    return jsonify(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Frontend (templates/exam.html)\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Online Exam</title>\n",
    "    <script src=\"{{ url_for('static', filename='js/camera.js') }}\"></script>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>MCQ Exam</h2>\n",
    "    <form id=\"examForm\" method=\"POST\" action=\"/submit\">\n",
    "        <p>Q1. What is 2+2?</p>\n",
    "        <input type=\"radio\" name=\"q1\" value=\"3\"> 3\n",
    "        <input type=\"radio\" name=\"q1\" value=\"4\"> 4\n",
    "        <input type=\"radio\" name=\"q1\" value=\"5\"> 5\n",
    "        <br><br>\n",
    "        <p>Q2. Capital of India?</p>\n",
    "        <input type=\"radio\" name=\"q2\" value=\"Delhi\"> Delhi\n",
    "        <input type=\"radio\" name=\"q2\" value=\"Mumbai\"> Mumbai\n",
    "        <input type=\"radio\" name=\"q2\" value=\"Chennai\"> Chennai\n",
    "        <br><br>\n",
    "        <input type=\"submit\" value=\"Submit\">\n",
    "    </form>\n",
    "\n",
    "    <video id=\"video\" width=\"320\" height=\"240\" autoplay></video>\n",
    "    <p id=\"status\"></p>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Webcam JS (static/js/camera.js)\n",
    "\n",
    "```javascript\n",
    "let video = document.getElementById(\"video\");\n",
    "let statusText = document.getElementById(\"status\");\n",
    "let canvas = document.createElement(\"canvas\");\n",
    "let ctx = canvas.getContext(\"2d\");\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({ video: true })\n",
    ".then(stream => {\n",
    "    video.srcObject = stream;\n",
    "});\n",
    "\n",
    "setInterval(() => {\n",
    "    canvas.width = video.videoWidth;\n",
    "    canvas.height = video.videoHeight;\n",
    "    ctx.drawImage(video, 0, 0);\n",
    "\n",
    "    let frame = canvas.toDataURL(\"image/jpeg\");\n",
    "\n",
    "    fetch(\"/monitor\", {\n",
    "        method: \"POST\",\n",
    "        headers: { \"Content-Type\": \"application/json\" },\n",
    "        body: JSON.stringify({ frame: frame })\n",
    "    })\n",
    "    .then(res => res.json())\n",
    "    .then(data => {\n",
    "        statusText.innerText = data.status + \" | Faults: \" + data.faults;\n",
    "\n",
    "        if (data.submit) {\n",
    "            alert(\"‚ùå Too many faults! Auto-submitting exam.\");\n",
    "            document.getElementById(\"examForm\").submit();\n",
    "        }\n",
    "    });\n",
    "}, 2000); // check every 2 sec\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ This setup will:\n",
    "\n",
    "* Run an **MCQ exam in Flask**.\n",
    "* Monitor webcam continuously.\n",
    "* Detect **face presence, multiple faces, head direction**.\n",
    "* After **10 warnings ‚Üí auto-submit exam**.\n",
    "\n",
    "---\n",
    "\n",
    "Do you also want me to extend this so that **captured violation images (evidence)** are also **saved on the server & displayed in the report** after submission?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Do you want me to also show live camera feed in the browser (instead of background monitoring) so students see what‚Äôs being tracked?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
