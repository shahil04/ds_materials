{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Setting Up Development Environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 13 basic of cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Displaying an Image using OpenCV\n",
    "Article 1: Reading and Displaying an Image using OpenCV\n",
    "\n",
    "Introduction:\n",
    "In computer vision, reading and displaying an image is a basic yet essential task. OpenCV, a powerful library, makes it simple to read an image from a file and display it in a window. This article walks you through reading an image and displaying it using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Read an image from file\n",
    "image = cv2.imread('data.png')  # Replace 'input_image.jpg' with your image path\n",
    " \n",
    "# Show the original image\n",
    "cv2.imshow('Original Image', image)\n",
    " \n",
    "cv2.waitKey(0)  # Wait until any key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Step-by-Step Breakdown:\n",
    "Reading the Image:\n",
    "\n",
    "The function cv2.imread() is used to load an image from a specified file path.\n",
    "\n",
    "Make sure to provide the correct path to your image file.\n",
    "\n",
    "Displaying the Image:\n",
    "\n",
    "cv2.imshow() opens a window to display the image. The first argument is the window title, and the second argument is the image to display.\n",
    "\n",
    "Waiting for a Key Press:\n",
    "\n",
    "The cv2.waitKey(0) function keeps the window open until any key is pressed.\n",
    "\n",
    "Once a key is pressed, cv2.destroyAllWindows() closes the window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping an Image using OpenCV\n",
    "\n",
    "Cropping allows you to extract a portion of an image for further processing or analysis. OpenCV enables easy cropping by using image slicing. In this article, you will learn how to crop an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Cropping the image (here we're cropping a 100x100 square from the top-left corner)\n",
    "cropped_image = image[0:100, 0:100]\n",
    " \n",
    "# Show the cropped image\n",
    "cv2.imshow('Cropped Image', cropped_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step-by-Step Breakdown:\n",
    "Cropping the Image:\n",
    "\n",
    "OpenCV stores images as NumPy arrays, and cropping is achieved by slicing the array.\n",
    "\n",
    "The code image[0:100, 0:100] selects the pixel rows from 0 to 100 and columns from 0 to 100, resulting in a 100x100 cropped image.\n",
    "\n",
    "Displaying the Cropped Image:\n",
    "\n",
    "The cropped portion of the image is displayed using the cv2.imshow() function, similar to how the full image was displayed earlier.\n",
    "\n",
    "Closing the Window:\n",
    "\n",
    "As before, cv2.waitKey(0) waits for a key press and cv2.destroyAllWindows() closes the window.\n",
    "\n",
    "Note: Due to some technical concerns, this lecture is in article form. Our team will try our best to update the article with videos soon, and you will be updated accordingly. Until then, feel free to review this article-based lecture. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing an Image using OpenCV\n",
    "Introduction:\n",
    "Resizing is important when working with images, especially for creating thumbnails or adjusting image dimensions for further analysis. OpenCV allows you to resize an image by scaling its width and height. This article explains how to resize an image in OpenCV.\n",
    "\n",
    "Code Explanation:\n",
    "python\n",
    "Copy code# Resizing the image (scaling it down to 50% of its original size)\n",
    "resized_image = cv2.resize(image, (0, 0), fx=0.5, fy=0.5)\n",
    " \n",
    "# Show the resized image\n",
    "cv2.imshow('Resized Image', resized_image)\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "Step-by-Step Breakdown:\n",
    "Resizing the Image:\n",
    "\n",
    "The cv2.resize() function is used to resize the image.\n",
    "\n",
    "Setting (0, 0) for the size and using the fx=0.5 and fy=0.5 parameters scale the width and height by 50%, effectively resizing the image to half its original size.\n",
    "\n",
    "Displaying the Resized Image:\n",
    "\n",
    "The resized image is displayed in a new window using cv2.imshow(), just as the original image was displayed.\n",
    "\n",
    "Closing the Window:\n",
    "\n",
    "The window is closed using cv2.waitKey(0) and cv2.destroyAllWindows().\n",
    "\n",
    "Note: Due to some technical concerns, this lecture is in article form. Our team will try our best to update the article with videos soon, and you will be updated accordingly. Until then, feel free to review this article-based lecture. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Cropped and Resized Images using OpenCV\n",
    "Introduction:\n",
    "After processing an image, you may want to save the output for future use. OpenCV makes saving images easy with the cv2.imwrite() function. In this article, we will save cropped and resized images using OpenCV.\n",
    "\n",
    "Code Explanation:\n",
    "python\n",
    "Copy code# Save the cropped and resized images\n",
    "cv2.imwrite('cropped_image.jpg', cropped_image)\n",
    "cv2.imwrite('resized_image.jpg', resized_image)\n",
    " \n",
    "print('Images have been saved successfully.')\n",
    "Step-by-Step Breakdown:\n",
    "Saving Images:\n",
    "\n",
    "The function cv2.imwrite() saves an image to the specified file path.\n",
    "\n",
    "The first argument is the file path where the image will be saved, and the second argument is the image to save.\n",
    "\n",
    "In this example, the cropped and resized images are saved as 'cropped_image.jpg' and 'resized_image.jpg', respectively.\n",
    "\n",
    "Completion Message:\n",
    "\n",
    "After saving the images, a message is printed to indicate success.\n",
    "\n",
    "Note: Due to some technical concerns, this lecture is in article form. Our team will try our best to update the article with videos soon, and you will be updated accordingly. Until then, feel free to review this article-based lecture. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 14: Project 1: Basic Image Manipulation (Beginner Level)\n",
    "\n",
    "Section Recap - Project 1\n",
    "Project 1: Basic Image Manipulation with OpenCV\n",
    "In this section, we explore basic image manipulation techniques using OpenCV. This project allows us to understand fundamental operations such as adding text, drawing shapes, and applying transformations (rotation, scaling, and translation) to images. These skills form the foundation for more advanced computer vision tasks.\n",
    "\n",
    "Step 1: Adding Text to an Image\n",
    "The first step involves reading an image and adding text to it. We use the cv2.putText() function to overlay text on the image.\n",
    "\n",
    "python\n",
    "Copy code# Read the image\n",
    "image = cv2.imread('example.jpg')  # Replace 'example.jpg' with your image path\n",
    " \n",
    "# Add text to the image\n",
    "cv2.putText(image, 'OpenCV Tutorial', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)  \n",
    "# Text: 'OpenCV Tutorial', position: (50, 50), font: Hershey Simplex, size: 1, color: white, thickness: 2\n",
    " \n",
    "# Display the image with text\n",
    "cv2.imshow('Image with Text', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.putText(): Adds text to the image.\n",
    "\n",
    "Parameters: Text content, position, font, scale, color, and thickness.\n",
    "\n",
    "Step 2: Drawing Shapes on an Image\n",
    "Next, we explore how to draw basic shapes like circles, rectangles, and lines on an image. This is useful for highlighting specific regions or marking objects.\n",
    "\n",
    "python\n",
    "Copy code# Import OpenCV library\n",
    "import cv2\n",
    " \n",
    "# Read the image\n",
    "image = cv2.imread('example.jpg')  # Replace 'example.jpg' with your image path\n",
    " \n",
    "# Draw a circle on the image\n",
    "cv2.circle(image, (150, 150), 50, (255, 0, 0), 2)  # Center at (150, 150), radius: 50, color: blue, thickness: 2\n",
    " \n",
    "# Draw a rectangle on the image\n",
    "cv2.rectangle(image, (50, 50), (200, 200), (0, 255, 0), 3)  # Top-left (50, 50), bottom-right (200, 200), color: green, thickness: 3\n",
    " \n",
    "# Draw a line on the image\n",
    "cv2.line(image, (10, 10), (300, 300), (0, 0, 255), 1)  # From (10, 10) to (300, 300), color: red, thickness: 1\n",
    " \n",
    "# Display the image with shapes\n",
    "cv2.imshow('Image with Shapes', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.circle(): Draws a circle at a specified position.\n",
    "\n",
    "cv2.rectangle(): Draws a rectangle between two corners.\n",
    "\n",
    "cv2.line(): Draws a line between two points.\n",
    "\n",
    "Step 3: Applying Transformations (Rotation, Scaling, and Translation)\n",
    "Now we apply transformations to manipulate the image, including rotating, scaling, and translating.\n",
    "\n",
    "a. Rotating the Image\n",
    "We rotate the image by 45 degrees around its center.\n",
    "\n",
    "python\n",
    "Copy codeimport cv2\n",
    "import numpy as np\n",
    " \n",
    "# Load the image\n",
    "image = cv2.imread('example.jpg')  # Replace 'example.jpg' with your image path\n",
    " \n",
    "# Get image dimensions\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    " \n",
    "# Apply rotation\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1.0)  # Rotate by 45 degrees\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    " \n",
    "# Display the rotated image\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.getRotationMatrix2D(): Creates a transformation matrix for rotating the image.\n",
    "\n",
    "cv2.warpAffine(): Applies the rotation to the image.\n",
    "\n",
    "b. Scaling the Image\n",
    "We resize the image by scaling it 1.5 times in both width and height.\n",
    "\n",
    "python\n",
    "Copy code# Apply scaling\n",
    "scaled_image = cv2.resize(image, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_LINEAR)  # Scale by 1.5x\n",
    " \n",
    "# Display the scaled image\n",
    "cv2.imshow('Scaled Image', scaled_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.resize(): Resizes the image based on specified scaling factors (fx and fy).\n",
    "\n",
    "c. Translating the Image\n",
    "We shift the image 50 pixels along both the x and y axes.\n",
    "\n",
    "python\n",
    "Copy code# Apply translation\n",
    "translation_matrix = np.float32([[1, 0, 50], [0, 1, 50]])  # Translate by 50 pixels in x and y directions\n",
    "translated_image = cv2.warpAffine(image, translation_matrix, (w, h))\n",
    " \n",
    "# Display the translated image\n",
    "cv2.imshow('Translated Image', translated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.warpAffine(): Applies translation to shift the image.\n",
    "\n",
    "Conclusion\n",
    "In this section, we covered the following basic image manipulation techniques:\n",
    "\n",
    "Adding text to an image.\n",
    "\n",
    "Drawing shapes like circles, rectangles, and lines.\n",
    "\n",
    "Applying transformations such as rotation, scaling, and translation.\n",
    "\n",
    "These basic operations form the groundwork for more advanced image processing tasks in OpenCV, which we will explore in future projects. Stay tuned for the next lecture, where we’ll dive into real-time face detection and continue our journey in computer vision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 15: Project 2: Real-Time Face Detection (Intermediate Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Recap - Project 2\n",
    "### **Project 2: Real-Time Face Detection with OpenCV**\n",
    "\n",
    "\n",
    "\n",
    "In this project, we take our computer vision journey to the next level by building a real-time face detection system using your PC's camera. The aim of this project is to access the system's webcam and detect faces in real-time using a pre-trained Haar cascade classifier.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 1: Importing Libraries**\n",
    "\n",
    "\n",
    "\n",
    "We will begin by importing the necessary libraries, **OpenCV** and **NumPy**. OpenCV is a powerful library for image processing, while NumPy is used for handling arrays and matrices of data.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 2: Loading the Haar Cascade Classifier**\n",
    "\n",
    "\n",
    "\n",
    "The Haar cascade classifier is a pre-trained model that can detect faces. OpenCV provides us with this model in the form of an XML file. This file contains the data needed to identify faces in an image.\n",
    "\n",
    "\n",
    "\n",
    "We will load this file into our program using the `cv2.CascadeClassifier()` function and reference the pre-trained face detection model stored in OpenCV’s data.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 3: Accessing the Webcam**\n",
    "\n",
    "\n",
    "\n",
    "To capture live video, we will use the `cv2.VideoCapture()` function. The parameter `0` is used to select the default webcam. If you have multiple cameras connected, you can change the number to use a different camera.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "\n",
    "    print(\"Error accessing the camera\")\n",
    "\n",
    "    exit()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 4: Capturing Frames in a Loop**\n",
    "\n",
    "\n",
    "\n",
    "We’ll create a while loop to continuously capture frames from the webcam. Each frame will be processed one by one to detect faces in real time.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "   \n",
    "\n",
    "    if not ret:\n",
    "\n",
    "        print(\"Error reading frame from webcam\")\n",
    "\n",
    "        break\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 5: Converting Frames to Grayscale**\n",
    "\n",
    "\n",
    "\n",
    "Face detection works more efficiently with grayscale images, as it reduces the amount of data and makes detection faster. We’ll convert each frame to grayscale using the `cv2.cvtColor()` function.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 6: Detecting Faces**\n",
    "\n",
    "\n",
    "\n",
    "Now that we have the grayscale frame, we will detect faces using the `detectMultiScale()` function. This function finds faces of different sizes in the image. It takes several parameters:\n",
    "\n",
    "- **Scale Factor**: Adjusts for faces of different sizes.\n",
    "\n",
    "- **minNeighbors**: Sets the minimum number of neighboring rectangles required to retain a face.\n",
    "\n",
    "- **minSize**: Specifies the minimum size of the detected face.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "\n",
    "        gray,\n",
    "\n",
    "        scaleFactor=1.1,\n",
    "\n",
    "        minNeighbors=5,\n",
    "\n",
    "        minSize=(30, 30)\n",
    "\n",
    "    )\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### **Project 2 Continued: Drawing Rectangles Around Detected Faces**\n",
    "\n",
    "\n",
    "\n",
    "Now that we’ve successfully detected faces in the video feed, it’s time to enhance our program by visually marking these detections. We’ll draw rectangles around the detected faces, making it easier to identify them in the video frame.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 7: Adding a For Loop to Process Detected Faces**\n",
    "\n",
    "\n",
    "\n",
    "In this step, we will loop through the list of detected faces and draw a rectangle around each one. The `detectMultiScale()` function provides coordinates for the top-left and bottom-right corners of the face, which we’ll use to draw these rectangles.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "```\n",
    "\n",
    "- `x, y`: Top-left corner of the rectangle.\n",
    "\n",
    "- `w, h`: Width and height of the rectangle.\n",
    "\n",
    "- `(255, 0, 0)`: Color of the rectangle (in this case, blue). You can modify the color to red or green.\n",
    "\n",
    "- `2`: Thickness of the rectangle in pixels.\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 8: Displaying the Image with Detected Faces**\n",
    "\n",
    "\n",
    "\n",
    "Once the rectangles are drawn, we need to display the video frame with the detection rectangles. For this, we use `cv2.imshow()` to show the video feed.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "cv2.imshow('Face Detection', frame)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 9: Exiting the Loop**\n",
    "\n",
    "\n",
    "\n",
    "We need to provide a way for users to exit the loop and stop the program. We’ll listen for the 'q' key, and when pressed, the program will break out of the loop and close all OpenCV windows.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "    break\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Step 10: Releasing Resources**\n",
    "\n",
    "\n",
    "\n",
    "After the loop ends, it’s important to free up the webcam and close any windows opened by OpenCV.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **The Full Program Code (with Comments)**\n",
    "\n",
    "\n",
    "\n",
    "Here’s the full code, including comments to explain each step:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier for face detection\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "\n",
    "    print(\"Error accessing the camera\")\n",
    "\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "# Main loop to process each video frame\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "   \n",
    "\n",
    "    if not ret:\n",
    "\n",
    "        print(\"Error reading frame from webcam\")\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    # Convert the captured frame to grayscale\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "\n",
    "        gray,\n",
    "\n",
    "        scaleFactor=1.1,\n",
    "\n",
    "        minNeighbors=5,\n",
    "\n",
    "        minSize=(30, 30)\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Draw a rectangle around each detected face\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### **Face Reveal Demo**\n",
    "\n",
    "\n",
    "\n",
    "After writing the code, the instructor demonstrates the program by showing the webcam capturing their face. The program detects their face and draws a blue rectangle around it. They also showcase how the program detects other objects, such as a Doraemon figure in the background.\n",
    "\n",
    "\n",
    "\n",
    "The program is fully functional but may lag if a heavy recording software is running in the background.\n",
    "\n",
    "\n",
    "\n",
    "### **Conclusion of Project 2**\n",
    "\n",
    "\n",
    "\n",
    "With this, we have completed Project 2. You now have a basic real-time face detection system using OpenCV and Python, capable of identifying and marking faces in live video streams. In the next project, we’ll dive even deeper into computer vision. Stay tuned!\n",
    "\n",
    "\n",
    "\n",
    "**See you in the next lecture!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 16: Face Recognition using FER (Advanced Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Recap - Project 3\n",
    "Project 3: Facial Expression Recognition with OpenCV\n",
    "In this section, we dive deeper into computer vision, a crucial domain of AI, by creating a Facial Expression Recognizer. This project will enable us to detect and classify various emotions such as happiness, sadness, surprise, and more using OpenCV and a pre-trained model. The system analyzes facial expressions in real-time from the webcam feed.\n",
    "\n",
    "Step 1: Setting Up the Environment\n",
    "First, ensure OpenCV is installed. You can install it via pip:\n",
    "\n",
    "bash\n",
    "Copy codepip install opencv-python\n",
    "We will also need a pre-trained model for emotion recognition. For this, the FER (Facial Expression Recognition) library is commonly used, so we import it as well.\n",
    "\n",
    "Step 2: Importing Libraries\n",
    "We’ll begin by importing the necessary libraries for this project:\n",
    "\n",
    "python\n",
    "Copy codeimport cv2\n",
    "from fer import FER\n",
    "cv2: OpenCV for image processing.\n",
    "\n",
    "FER: A pre-trained facial expression recognition model.\n",
    "\n",
    "Step 3: Initializing the Emotion Detector and Webcam Feed\n",
    "Next, we initialize the Emotion Detector using the pre-trained FER model. Then, we start capturing video from the webcam, just as we did in previous face detection projects.\n",
    "\n",
    "python\n",
    "Copy codeemotion_detector = FER()\n",
    "cap = cv2.VideoCapture(0)  # Start webcam feed\n",
    "Step 4: Capturing Frames in a Loop\n",
    "We now capture video frames continuously in a loop, allowing us to process them one by one to recognize emotions in real time.\n",
    "\n",
    "python\n",
    "Copy codewhile True:\n",
    "    ret, frame = cap.read()  # Capture each frame\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "Step 5: Detecting Emotions\n",
    "The next step is to detect the emotions in each captured frame. The FER model provides us with emotion predictions for the face(s) detected in the frame.\n",
    "\n",
    "python\n",
    "Copy code    emotions = emotion_detector.detect_emotions(frame)\n",
    "    if emotions:\n",
    "        emotion_data = emotions[0]  # Take the first detected face\n",
    "        # Get the emotion with the highest confidence\n",
    "        highest_confidence_emotion = max(emotion_data[\"emotions\"], key=emotion_data[\"emotions\"].get)\n",
    "Here, we are capturing the emotion with the highest confidence to display it.\n",
    "\n",
    "Step 6: Drawing the Rectangle and Emotion Text\n",
    "Once an emotion is detected, we draw a rectangle around the face and display the detected emotion on the screen, along with its confidence level.\n",
    "\n",
    "python\n",
    "Copy code        (x, y, w, h) = emotion_data[\"box\"]  # Get coordinates for the rectangle\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw rectangle\n",
    "        cv2.putText(frame, highest_confidence_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "Step 7: Displaying the Video Feed\n",
    "We’ll use cv2.imshow() to display the video feed with the detected emotion and bounding box around the face.\n",
    "\n",
    "python\n",
    "Copy code    cv2.imshow('Emotion Detector', frame)\n",
    "Step 8: Exiting the Loop\n",
    "We allow the user to exit the program by pressing the 'q' key. When this happens, we release the webcam and close all OpenCV windows.\n",
    "\n",
    "python\n",
    "Copy code    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "Step 9: Releasing Resources\n",
    "Finally, we release the webcam and close any windows that were opened by OpenCV.\n",
    "\n",
    "python\n",
    "Copy codecap.release()\n",
    "cv2.destroyAllWindows()\n",
    "Full Code (with Comments)\n",
    "Here’s the full code with comments to explain each part:\n",
    "\n",
    "python\n",
    "Copy codeimport cv2\n",
    "from fer import FER\n",
    " \n",
    "# Initialize emotion detector\n",
    "emotion_detector = FER()\n",
    " \n",
    "# Start webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Loop to capture frames from the webcam\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    " \n",
    "    # Detect emotions in the frame\n",
    "    emotions = emotion_detector.detect_emotions(frame)\n",
    "    \n",
    "    if emotions:\n",
    "        # Get the first detected face's emotion data\n",
    "        emotion_data = emotions[0]\n",
    "        # Find the emotion with the highest confidence\n",
    "        highest_confidence_emotion = max(emotion_data[\"emotions\"], key=emotion_data[\"emotions\"].get)\n",
    "        \n",
    "        # Get coordinates of the face and draw a rectangle around it\n",
    "        (x, y, w, h) = emotion_data[\"box\"]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    " \n",
    "        # Display the emotion with the highest confidence on the frame\n",
    "        cv2.putText(frame, highest_confidence_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    " \n",
    "    # Display the frame with emotion detection\n",
    "    cv2.imshow('Emotion Detector', frame)\n",
    " \n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# Release webcam and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "Demonstration and Emotion Detection\n",
    "Once the program is running, you can show your face on the webcam, and the system will detect your emotions in real-time. The instructor demonstrates the emotion detection by showing various facial expressions, including happiness, sadness, and surprise. The software also detects the emotions of other animated characters, such as Doraemon and Mickey Mouse.\n",
    "\n",
    "Conclusion\n",
    "This facial expression recognizer uses the power of AI and computer vision to detect and classify emotions in real-time video streams. By leveraging pre-trained models, the task of emotion recognition becomes straightforward and effective. This marks the completion of our Facial Expression Recognizer project.\n",
    "\n",
    "In the next project, we’ll explore further applications of computer vision, taking our AI skills even deeper.\n",
    "\n",
    "See you in the next lecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - OpenCV\n",
    "Congratulations! You’ve now completed the course on OpenCV and Computer Vision, covering everything from basic image manipulations to real-time face detection and facial emotion recognition. By the end of this course, you have learned key skills in image processing, transformations, and even real-time computer vision applications that are widely used in the industry today.\n",
    "\n",
    "Throughout the course, you gained hands-on experience with the core libraries, tools, and techniques necessary for working in the field of computer vision. Whether you were just starting with OpenCV or looking to advance your existing skills, this course has equipped you with a strong foundation in both beginner and intermediate-level topics.\n",
    "\n",
    "We also explored real-world applications of face detection and emotion recognition using FER, which are practical and valuable in a wide range of sectors such as security, healthcare, and entertainment.\n",
    "\n",
    "Next Steps\n",
    "Now that you’ve completed this course, here are some recommendations for your next steps:\n",
    "\n",
    "Explore More Complex Computer Vision Projects:\n",
    "Consider building on your current skills by exploring more advanced topics like object detection, image segmentation, or deep learning in computer vision with libraries such as TensorFlow or PyTorch.\n",
    "\n",
    "Work on Personal Projects:\n",
    "Start applying the skills you’ve learned in real-world projects. Whether it's a face recognition system, an emotion detection app, or a personal camera project, practicing is key to mastering computer vision.\n",
    "\n",
    "Stay Updated with OpenCV and CV Libraries:\n",
    "OpenCV is a continuously evolving library. Keep up with the latest updates, tutorials, and features that the OpenCV community and other computer vision resources provide.\n",
    "\n",
    "Consider Exploring AI Integration:\n",
    "Computer vision combined with AI technologies opens up numerous opportunities. You can expand your knowledge by learning how to integrate computer vision with machine learning algorithms to create even smarter applications.\n",
    "\n",
    "Lecture 23: Thank You!\n",
    "Thank you for enrolling in this course and dedicating your time to learn Computer Vision with OpenCV. I hope you have found the content helpful, engaging, and informative. I encourage you to take the skills you’ve learned here and apply them to your own creative projects. The world of computer vision is vast and exciting, and now you are equipped to explore it further!\n",
    "\n",
    "If you have any questions, need additional resources, or want to share your progress, feel free to reach out. The journey doesn’t stop here, and I’m excited to see how you continue to grow and apply what you’ve learned!\n",
    "\n",
    "Good luck with your projects, and I look forward to seeing the amazing things you will create!\n",
    "\n",
    "All the best, and happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You and Conclusion\n",
    "Congratulations on completing the course! You’ve come a long way in learning how to build your own AI assistant using Python, as well as exploring the exciting field of computer vision. Throughout this course, we’ve covered a wide range of topics that have equipped you with valuable skills. Let’s take a moment to reflect on what you've achieved:\n",
    "\n",
    "In the Python AI Assistant Section:\n",
    "You learned the basics of creating a voice-enabled AI assistant, incorporating features like text-to-speech, speech recognition, and various functionalities like Wikipedia search, weather updates, translations, and system controls.\n",
    "\n",
    "You gained practical experience working with libraries like pyttsx3, speech_recognition, googletrans, and wikipediaapi.\n",
    "\n",
    "We even explored building a user-friendly GUI using Tkinter, which added a professional touch to your project.\n",
    "\n",
    "In the Computer Vision Section:\n",
    "You mastered the basics of image manipulation using OpenCV, drawing shapes, adding text, and performing transformations.\n",
    "\n",
    "You then moved on to more advanced applications like face detection, real-time emotion recognition, and working with Haar cascades.\n",
    "\n",
    "You also explored object tracking and enhanced your skills in edge detection and image enhancement.\n",
    "\n",
    "What’s Next?\n",
    "Now that you've completed this course, here are some suggested next steps to continue your journey:\n",
    "\n",
    "Expand Your Projects:\n",
    "\n",
    "With the knowledge gained, try creating more advanced AI applications or dive deeper into computer vision with machine learning and deep learning techniques using libraries like TensorFlow or PyTorch.\n",
    "\n",
    "Personalize Your AI Assistant:\n",
    "\n",
    "Add more functionality to your assistant, like connecting it to third-party APIs or integrating it with a database to store user preferences or past interactions.\n",
    "\n",
    "Explore More Advanced Computer Vision Topics:\n",
    "\n",
    "Dive into object detection, image segmentation, and explore more in-depth algorithms like YOLO or Mask R-CNN for real-time image recognition tasks.\n",
    "\n",
    "Contribute to Open-Source Projects:\n",
    "\n",
    "Share your knowledge and projects with the community! Consider contributing to open-source repositories or starting your own.\n",
    "\n",
    "Stay Updated:\n",
    "\n",
    "The world of AI and computer vision is constantly evolving. Keep learning, follow the latest trends in the field, and experiment with new techniques and technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
