{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9cc2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ba9b41",
   "metadata": {},
   "source": [
    "Perfect ğŸ‘ Letâ€™s build a **Rule-Based FAQ Chatbot for Customer Service** â€” step-by-step.\n",
    "Weâ€™ll use **Python** and **Streamlit** (so it can run on your browser easily).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Concept Overview\n",
    "\n",
    "A **rule-based chatbot** doesnâ€™t use ML or AI â€” instead, it uses **predefined patterns or keywords** to respond to user queries.\n",
    "\n",
    "You can use it for:\n",
    "\n",
    "* Answering common customer queries (refunds, delivery, pricing)\n",
    "* Providing contact info\n",
    "* Guiding users through basic help\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ Project Structure\n",
    "\n",
    "```\n",
    "faq_chatbot/\n",
    "â”‚\n",
    "â”œâ”€â”€ app.py                  # Streamlit app (main chatbot interface)\n",
    "â”œâ”€â”€ responses.py            # Rule-based response logic\n",
    "â”œâ”€â”€ faqs.json               # FAQ dataset (optional)\n",
    "â””â”€â”€ requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“œ Step 1: Create `responses.py`\n",
    "\n",
    "This file contains the rules for responses.\n",
    "\n",
    "```python\n",
    "# responses.py\n",
    "\n",
    "def get_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    if \"hello\" in user_input or \"hi\" in user_input:\n",
    "        return \"Hello! ğŸ‘‹ How can I assist you today?\"\n",
    "\n",
    "    elif \"refund\" in user_input:\n",
    "        return \"Refunds are processed within 5â€“7 business days after product return confirmation.\"\n",
    "\n",
    "    elif \"return\" in user_input:\n",
    "        return \"You can initiate a return from your account under 'Orders' â†’ 'Return Item'.\"\n",
    "\n",
    "    elif \"delivery\" in user_input:\n",
    "        return \"Standard delivery takes 3â€“5 business days. You can track it from your order page.\"\n",
    "\n",
    "    elif \"cancel order\" in user_input or \"cancellation\" in user_input:\n",
    "        return \"You can cancel your order within 24 hours of placing it.\"\n",
    "\n",
    "    elif \"payment\" in user_input:\n",
    "        return \"We accept payments via credit card, debit card, UPI, and PayPal.\"\n",
    "\n",
    "    elif \"contact\" in user_input or \"support\" in user_input:\n",
    "        return \"You can reach our support team at ğŸ“§ support@easysolution.com or â˜ï¸ +91-9876543210.\"\n",
    "\n",
    "    elif \"price\" in user_input or \"cost\" in user_input:\n",
    "        return \"Our prices vary depending on the product category. Please visit the pricing page for details.\"\n",
    "\n",
    "    elif \"thank\" in user_input:\n",
    "        return \"You're welcome! ğŸ˜Š Happy to help.\"\n",
    "\n",
    "    else:\n",
    "        return \"I'm sorry, I didnâ€™t quite understand that. Please try asking about delivery, refund, or return.\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¨ Step 2: Create `app.py` (Streamlit Interface)\n",
    "\n",
    "```python\n",
    "# app.py\n",
    "import streamlit as st\n",
    "from responses import get_response\n",
    "\n",
    "st.set_page_config(page_title=\"Customer Service Chatbot\", page_icon=\"ğŸ¤–\", layout=\"centered\")\n",
    "\n",
    "st.title(\"ğŸ¤– Customer Service FAQ Chatbot\")\n",
    "st.write(\"Ask me anything about your order, refund, or delivery!\")\n",
    "\n",
    "# Session state to store chat history\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "\n",
    "# Input field\n",
    "user_input = st.chat_input(\"Type your question...\")\n",
    "\n",
    "if user_input:\n",
    "    bot_response = get_response(user_input)\n",
    "    st.session_state.history.append((\"You\", user_input))\n",
    "    st.session_state.history.append((\"Bot\", bot_response))\n",
    "\n",
    "# Display chat history\n",
    "for sender, message in st.session_state.history:\n",
    "    if sender == \"You\":\n",
    "        st.markdown(f\"ğŸ§‘â€ğŸ’» **You:** {message}\")\n",
    "    else:\n",
    "        st.markdown(f\"ğŸ¤– **Bot:** {message}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ Step 3: `requirements.txt`\n",
    "\n",
    "```\n",
    "streamlit==1.39.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## â–¶ï¸ Step 4: Run the App\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Step 5: (Optional) Add a JSON FAQ file\n",
    "\n",
    "You can extend the chatbot by storing FAQs in a JSON file:\n",
    "\n",
    "**faqs.json**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"refund\": \"Refunds are processed within 5â€“7 business days.\",\n",
    "    \"delivery\": \"Delivery usually takes 3â€“5 days.\",\n",
    "    \"return\": \"You can return items within 7 days of delivery.\",\n",
    "    \"contact\": \"Email us at support@easysolution.com.\"\n",
    "}\n",
    "```\n",
    "\n",
    "And load it dynamically in `responses.py`:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "with open(\"faqs.json\") as f:\n",
    "    faqs = json.load(f)\n",
    "\n",
    "def get_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    for key, answer in faqs.items():\n",
    "        if key in user_input:\n",
    "            return answer\n",
    "    return \"Sorry, I don't have an answer for that.\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§± Future Upgrades\n",
    "\n",
    "| Feature           | Description                                            |\n",
    "| ----------------- | ------------------------------------------------------ |\n",
    "| ğŸ§© NLP support    | Use spaCy or HuggingFace to match intents semantically |\n",
    "| ğŸ’¾ Database       | Store chat logs in SQLite or Firebase                  |\n",
    "| ğŸŒ Deployment     | Host on Streamlit Cloud, AWS, or Railway               |\n",
    "| ğŸ” Authentication | Add user login before chat                             |\n",
    "| ğŸ§  Hybrid model   | Combine rule-based with GPT-powered fallback           |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to:\n",
    "\n",
    "1. ğŸ”¹ Add **a downloadable ZIP** of this full project (ready to run)?\n",
    "2. ğŸ”¹ Or extend it with **a FastAPI backend + Streamlit frontend** (for production use)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55051d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ed256",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e540989",
   "metadata": {},
   "source": [
    "Excellent ğŸ”¥ â€” Letâ€™s build a **Machine Learningâ€“based Intent Classifier Chatbot** for a **Restaurant Booking Assistant** (with Named Entity Recognition for extracting details like date, time, people, etc.).\n",
    "\n",
    "Youâ€™ll get:\n",
    "\n",
    "* âœ… **Intent classification model** (ML-based)\n",
    "* âœ… **NER extraction** (using spaCy)\n",
    "* âœ… **FastAPI or Streamlit interface**\n",
    "* âœ… **Downloadable ZIP (complete project)**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Objective\n",
    "\n",
    "Build a chatbot that can handle conversations like:\n",
    "\n",
    "> \"Book a table for 2 at 8 PM tomorrow\"\n",
    "> \"Cancel my reservation for today evening\"\n",
    "> \"What's the restaurant address?\"\n",
    "> \"Do you serve vegan food?\"\n",
    "\n",
    "It will:\n",
    "\n",
    "1. Classify the userâ€™s **intent** (book_table, cancel_reservation, restaurant_info, menu_query, etc.)\n",
    "2. Extract **entities** like number of people, date, time.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Architecture\n",
    "\n",
    "```\n",
    "ML-based Chatbot (Restaurant Assistant)\n",
    "â”‚\n",
    "â”œâ”€â”€ intents.json              # Training data for intent classification\n",
    "â”œâ”€â”€ train_intent_model.py     # Train a TF-IDF + Logistic Regression model\n",
    "â”œâ”€â”€ ner_extractor.py          # spaCy NER for date, time, people\n",
    "â”œâ”€â”€ chatbot.py                # Logic combining intent + NER\n",
    "â”œâ”€â”€ app.py                    # Streamlit frontend\n",
    "â””â”€â”€ requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Step 1: intents.json\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"intents\": [\n",
    "    {\"intent\": \"book_table\", \"patterns\": [\"Book a table\", \"I need a reservation\", \"Reserve for two people\", \"Table for 4 tonight\"]},\n",
    "    {\"intent\": \"cancel_reservation\", \"patterns\": [\"Cancel my booking\", \"Cancel reservation\", \"I want to cancel my table\"]},\n",
    "    {\"intent\": \"restaurant_info\", \"patterns\": [\"Where is the restaurant?\", \"Address please\", \"Whatâ€™s your location?\"]},\n",
    "    {\"intent\": \"menu_query\", \"patterns\": [\"Show me the menu\", \"Do you serve vegan?\", \"What dishes do you have?\"]},\n",
    "    {\"intent\": \"greeting\", \"patterns\": [\"Hi\", \"Hello\", \"Hey there\", \"Good morning\"]},\n",
    "    {\"intent\": \"goodbye\", \"patterns\": [\"Bye\", \"See you\", \"Good night\", \"Thanks\"]}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Step 2: Intent Classifier â€” `train_intent_model.py`\n",
    "\n",
    "```python\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load intents\n",
    "with open(\"intents.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for item in data[\"intents\"]:\n",
    "    for pattern in item[\"patterns\"]:\n",
    "        texts.append(pattern)\n",
    "        labels.append(item[\"intent\"])\n",
    "\n",
    "# TF-IDF + Logistic Regression model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Save\n",
    "joblib.dump(model, \"intent_model.pkl\")\n",
    "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
    "\n",
    "print(\"âœ… Intent classification model trained and saved!\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Step 3: Named Entity Recognition â€” `ner_extractor.py`\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {}\n",
    "    for ent in doc.ents:\n",
    "        entities[ent.label_] = ent.text\n",
    "    return entities\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Step 4: Chatbot Logic â€” `chatbot.py`\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "from ner_extractor import extract_entities\n",
    "\n",
    "model = joblib.load(\"intent_model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "def predict_intent(text):\n",
    "    X = vectorizer.transform([text])\n",
    "    return model.predict(X)[0]\n",
    "\n",
    "def chatbot_response(text):\n",
    "    intent = predict_intent(text)\n",
    "    entities = extract_entities(text)\n",
    "\n",
    "    if intent == \"book_table\":\n",
    "        return f\"Got it! Booking a table. Details: {entities if entities else 'Please provide date and time.'}\"\n",
    "    elif intent == \"cancel_reservation\":\n",
    "        return \"Your reservation has been canceled.\"\n",
    "    elif intent == \"restaurant_info\":\n",
    "        return \"Our restaurant is located at MG Road, Bengaluru.\"\n",
    "    elif intent == \"menu_query\":\n",
    "        return \"We serve Italian, Indian, and Continental dishes. Vegan options available!\"\n",
    "    elif intent == \"greeting\":\n",
    "        return \"Hello! ğŸ‘‹ How can I help you today?\"\n",
    "    elif intent == \"goodbye\":\n",
    "        return \"Goodbye! Have a great day! ğŸ‘‹\"\n",
    "    else:\n",
    "        return \"I'm not sure how to respond to that.\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ–¥ï¸ Step 5: Streamlit App â€” `app.py`\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from chatbot import chatbot_response\n",
    "\n",
    "st.set_page_config(page_title=\"Restaurant Chatbot\", page_icon=\"ğŸ½ï¸\", layout=\"centered\")\n",
    "\n",
    "st.title(\"ğŸ½ï¸ Restaurant Booking Assistant\")\n",
    "st.write(\"Ask me about booking, cancellation, menu, or location!\")\n",
    "\n",
    "if \"chat\" not in st.session_state:\n",
    "    st.session_state.chat = []\n",
    "\n",
    "user_input = st.chat_input(\"Type your message here...\")\n",
    "\n",
    "if user_input:\n",
    "    bot_reply = chatbot_response(user_input)\n",
    "    st.session_state.chat.append((\"You\", user_input))\n",
    "    st.session_state.chat.append((\"Bot\", bot_reply))\n",
    "\n",
    "for sender, msg in st.session_state.chat:\n",
    "    if sender == \"You\":\n",
    "        st.markdown(f\"ğŸ§‘â€ğŸ’» **{sender}:** {msg}\")\n",
    "    else:\n",
    "        st.markdown(f\"ğŸ¤– **{sender}:** {msg}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ Step 6: requirements.txt\n",
    "\n",
    "```\n",
    "streamlit==1.39.0\n",
    "scikit-learn\n",
    "spacy\n",
    "joblib\n",
    "```\n",
    "\n",
    "Before running, download the spaCy model:\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## â–¶ï¸ Step 7: Run the Project\n",
    "\n",
    "```bash\n",
    "python train_intent_model.py\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Future Enhancements\n",
    "\n",
    "| Feature          | Description                                   |\n",
    "| ---------------- | --------------------------------------------- |\n",
    "| ğŸ§  Deep Learning | Use BERT-based intent classification          |\n",
    "| ğŸ—£ï¸ Voice Input  | Add mic input via SpeechRecognition           |\n",
    "| ğŸ’¾ Database      | Store bookings in SQLite/PostgreSQL           |\n",
    "| ğŸŒ Deployment    | Deploy to Streamlit Cloud / AWS / Railway     |\n",
    "| ğŸ¤ Integration   | Connect to restaurantâ€™s API for real bookings |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to now **generate and give you the full ZIP file (ready to run)** for this ML-based Restaurant Chatbot (with NER)?\n",
    "ğŸ‘‰ Options:\n",
    "\n",
    "1. **Streamlit frontend** (simple chatbot UI)\n",
    "2. **FastAPI backend + Streamlit frontend** (production style)\n",
    "\n",
    "Which one do you prefer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c0a6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b70ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ff714",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c792f97",
   "metadata": {},
   "source": [
    "ğŸš€ All set! Iâ€™ve generated a complete **Advanced Conversational AI** project with:\n",
    "\n",
    "* Transformer chat (FLAN-T5 small, CPU-friendly)\n",
    "* Encoderâ€“Decoder prompt building\n",
    "* **RAG** with FAISS + MiniLM embeddings\n",
    "* **Zero-shot Intent** (BART-MNLI)\n",
    "* **spaCy NER**\n",
    "* **FastAPI** backend + **Streamlit** UI\n",
    "* **Dockerfile** & helper scripts\n",
    "\n",
    "ğŸ‘‰ **Download the ZIP:** [advanced_conversational_ai.zip](sandbox:/mnt/data/advanced_conversational_ai.zip)\n",
    "\n",
    "### Run it locally\n",
    "\n",
    "```bash\n",
    "# 1) Setup\n",
    "python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\\Scripts\\activate)\n",
    "pip install -r requirements.txt\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "# 2) (optional) Warm up small models\n",
    "python scripts/download_models.py\n",
    "\n",
    "# 3) Build RAG index\n",
    "python backend/rag/build_index.py\n",
    "\n",
    "# 4) Start backend\n",
    "uvicorn backend.main:app --reload --port 8000\n",
    "\n",
    "# 5) Start UI\n",
    "streamlit run frontend/app.py\n",
    "```\n",
    "\n",
    "### Highlights\n",
    "\n",
    "* Swap models/providers in `config.yaml` (e.g., upgrade to `google/flan-t5-base`).\n",
    "* Plug in OpenAI/Mistral/Together by filling adapters in `backend/models/` and setting API keys.\n",
    "* Toggle RAG and set `top_k` directly in the UI.\n",
    "\n",
    "If you want, I can also:\n",
    "\n",
    "* add an **OpenAI/Mistral provider mode** wired to environment variables,\n",
    "* include a **SQLite reservations DB** + endpoints,\n",
    "* or ship **Kubernetes manifests / Docker Compose**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
