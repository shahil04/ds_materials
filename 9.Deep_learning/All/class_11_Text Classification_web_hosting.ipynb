{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“˜ **Lesson Plan: Text Classification Using Email Spam Dataset**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ **1. Problem Statement**\n",
    "\n",
    "Classify email messages as **Spam** or **Not Spam (Ham)** using machine learning and deep learning techniques.\n",
    "We will use:\n",
    "\n",
    "* **CountVectorizer** and **TF-IDF** for feature extraction\n",
    "* ML models: **Naive Bayes**, **Logistic Regression**, **SVM**\n",
    "* **ANN** using Keras\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ **Dataset Used**\n",
    "\n",
    "* Email spam dataset with two columns:\n",
    "\n",
    "  * `label`: 'spam' or 'ham'\n",
    "  * `text`: email content\n",
    "\n",
    "> Example dataset: [Kaggle Email Spam Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Steps for All Approaches**\n",
    "\n",
    "### **Step 1: Load & Preprocess Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"class_11_spam.csv\", encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Encode label\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])  # ham = 0, spam = 1\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ğŸ”¹ **2. CountVectorizer + ML Models**\n",
    "\n",
    "### Vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_cv = vectorizer.fit_transform(X_train)\n",
    "X_test_cv = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9838565022421525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.89      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Classification\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_cv, y_train)\n",
    "y_pred = model.predict(X_test_cv)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9623318385650225\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ğŸ“Œ **Try with Logistic Regression and SVM as well.**\n",
    "\n",
    "\n",
    "## ğŸ”¹ **3. TF-IDF + ML Models**\n",
    "\n",
    "### TF-IDF Vectorization\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "### Classification (same as above)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## ğŸ”¹ **4. Text Classification using ANN (Keras)**\n",
    "\n",
    "### Preprocess using TF-IDF and Convert to Array\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "X_train_arr = X_train_tfidf.toarray()\n",
    "X_test_arr = X_test_tfidf.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\nlp\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.8342 - loss: 0.5842 - val_accuracy: 0.8987 - val_loss: 0.2784\n",
      "Epoch 2/5\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9269 - loss: 0.2271 - val_accuracy: 0.9722 - val_loss: 0.1204\n",
      "Epoch 3/5\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9823 - loss: 0.0837 - val_accuracy: 0.9794 - val_loss: 0.0793\n",
      "Epoch 4/5\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9938 - loss: 0.0448 - val_accuracy: 0.9785 - val_loss: 0.0677\n",
      "Epoch 5/5\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0247 - val_accuracy: 0.9803 - val_loss: 0.0629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x212383619a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define ANN Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_arr.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_arr, y_train, epochs=5, batch_size=64, validation_data=(X_test_arr, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Predict with Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "Prediction: Spam (0.9854)\n"
     ]
    }
   ],
   "source": [
    "# Sample email text\n",
    "sample_email = [\"Congratulations! You've won a free iPhone. Click the link to claim now!\"]\n",
    "\n",
    "# Vectorize using the same TF-IDF vectorizer\n",
    "sample_tfidf = tfidf.transform(sample_email).toarray()\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(sample_tfidf)\n",
    "\n",
    "# Interpret result\n",
    "label = \"Spam\" if prediction[0][0] >= 0.5 else \"Ham\"\n",
    "print(f\"Prediction: {label} ({prediction[0][0]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
      "Email: Congratulations! You have won a lottery worth $1,000,000.\n",
      "Prediction: Spam (0.9313)\n",
      "\n",
      "Email: Hey, are we still meeting for lunch today?\n",
      "Prediction: Ham (0.0016)\n",
      "\n",
      "Email: Limited-time offer just for you! Get 90% off on your next purchase.\n",
      "Prediction: Ham (0.1808)\n",
      "\n",
      "Email: Please find the attached report for the project.\n",
      "Prediction: Ham (0.1389)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with Multiple Samples\n",
    "sample_emails = [\n",
    "    \"Congratulations! You have won a lottery worth $1,000,000.\",\n",
    "    \"Hey, are we still meeting for lunch today?\",\n",
    "    \"Limited-time offer just for you! Get 90% off on your next purchase.\",\n",
    "    \"Please find the attached report for the project.\"\n",
    "]\n",
    "\n",
    "sample_tfidf = tfidf.transform(sample_emails).toarray()\n",
    "predictions = model.predict(sample_tfidf)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    label = \"Spam\" if pred[0] >= 0.5 else \"Ham\"\n",
    "    print(f\"Email: {sample_emails[i]}\\nPrediction: {label} ({pred[0]:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… How to Save and Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"ann_spam_model.h5\")\n",
    "\n",
    "# Save TF-IDF vectorizer\n",
    "import pickle\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Streamlit App: spam_detector_app.py\n",
    "\n",
    "âœ… How to Run Streamlit App\n",
    "\n",
    "streamlit run spam_detector_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"ann_spam_model.h5\")\n",
    "\n",
    "# Load saved TF-IDF vectorizer\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"ğŸ“§ Email Spam Classifier\")\n",
    "st.write(\"Enter an email below to check if it's **Spam** or **Ham**\")\n",
    "\n",
    "email_text = st.text_area(\"âœ‰ï¸ Email Content\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    if email_text.strip() == \"\":\n",
    "        st.warning(\"Please enter some email text.\")\n",
    "    else:\n",
    "        # Transform text\n",
    "        email_vector = tfidf.transform([email_text]).toarray()\n",
    "        \n",
    "        # Predict\n",
    "        prediction = model.predict(email_vector)\n",
    "        label = \"ğŸ›‘ Spam\" if prediction[0][0] >= 0.5 else \"âœ… Ham\"\n",
    "        confidence = prediction[0][0] if label == \"ğŸ›‘ Spam\" else 1 - prediction[0][0]\n",
    "        \n",
    "        st.subheader(\"ğŸ“Š Prediction Result\")\n",
    "        st.write(f\"**Prediction:** {label}\")\n",
    "        st.write(f\"**Confidence:** {confidence:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask API: app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 2. Save Model and Vectorizer\n",
    "# After training in your main notebook:\n",
    "\n",
    "model.save(\"ann_spam_model.h5\")\n",
    "\n",
    "import pickle\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model and vectorizer\n",
    "model = load_model('ann_spam_model.h5')\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return jsonify({'message': 'Email Spam Detection API is running!'})\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    \n",
    "    if 'email' not in data:\n",
    "        return jsonify({'error': 'No email content provided'}), 400\n",
    "\n",
    "    email_text = data['email']\n",
    "    \n",
    "    # Preprocess and predict\n",
    "    email_vector = tfidf.transform([email_text]).toarray()\n",
    "    prediction = model.predict(email_vector)\n",
    "    \n",
    "    label = 'Spam' if prediction[0][0] >= 0.5 else 'Ham'\n",
    "    confidence = float(prediction[0][0]) if label == \"Spam\" else float(1 - prediction[0][0])\n",
    "\n",
    "    return jsonify({\n",
    "        'prediction': label,\n",
    "        'confidence': round(confidence, 4)\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 3. Run the Flask API\n",
    "\n",
    "# pip install flask tensorflow scikit-learn\n",
    "# python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… **4. Test the API (Using curl or Postman)**\n",
    "\n",
    "### Example `POST` request using **curl**:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://127.0.0.1:5000/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"email\":\"Congratulations! You have won a free ticket. Click here!\"}'\n",
    "```\n",
    "\n",
    "### Sample Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"prediction\": \"Spam\",\n",
    "  \"confidence\": 0.9813\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's deploy your **Flask API** for Email Spam Detection to a free cloud platform.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Recommended Hosting Platforms\n",
    "\n",
    "| Platform                | Free Tier | Supports Flask            | Custom Domain        | Setup Effort |\n",
    "| ----------------------- | --------- | ------------------------- | -------------------- | ------------ |\n",
    "| **Render**              | âœ… Yes     | âœ… Yes                     | âœ…                    | â­â­ Easy      |\n",
    "| **Railway**             | âœ… Yes     | âœ… Yes                     | âœ…                    | â­â­ Easy      |\n",
    "| **Hugging Face Spaces** | âœ… Yes     | âœ… (via Gradio or FastAPI) | âŒ (no custom domain) | â­ Easy       |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Letâ€™s Use **Render** (Free & Flask-Friendly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ **Step-by-Step Deployment on Render**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Prepare Folder Structure**\n",
    "\n",
    "```\n",
    "email-spam-api/\n",
    "â”œâ”€â”€ app.py\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â”œâ”€â”€ ann_spam_model.h5\n",
    "â”œâ”€â”€ tfidf_vectorizer.pkl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `requirements.txt`**\n",
    "\n",
    "```txt\n",
    "Flask\n",
    "tensorflow\n",
    "scikit-learn\n",
    "numpy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Create a GitHub Repo**\n",
    "\n",
    "1. Create a GitHub repository: e.g., `email-spam-api`\n",
    "2. Push your files (`app.py`, `requirements.txt`, `.h5`, `.pkl`) to GitHub\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Deploy on Render**\n",
    "\n",
    "1. Visit [https://render.com](https://render.com)\n",
    "2. Sign in â†’ Click **â€œNew +â€** â†’ **â€œWeb Serviceâ€**\n",
    "3. Connect your GitHub â†’ Select your repo\n",
    "4. Fill out:\n",
    "\n",
    "   * **Name**: `email-spam-api`\n",
    "   * **Runtime**: Python\n",
    "   * **Build Command**: `pip install -r requirements.txt`\n",
    "   * **Start Command**: `python app.py`\n",
    "5. Click **Deploy**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Modify `app.py` for Production on Render\n",
    "\n",
    "Replace the last line with:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… After Deployment\n",
    "\n",
    "* Youâ€™ll get a public URL like:\n",
    "  `https://email-spam-api.onrender.com/predict`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ Example `POST` Request\n",
    "\n",
    "```bash\n",
    "curl -X POST https://email-spam-api.onrender.com/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"email\":\"You won a lottery! Click to claim\"}'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Want Me to:\n",
    "\n",
    "* **Package and zip the code for Render**?\n",
    "* **Give you a `Gradio` version for Hugging Face Spaces** instead?\n",
    "* Or **set it up for FastAPI deployment**?\n",
    "\n",
    "Let me know your preferred path and Iâ€™ll deliver it fully ready-to-deploy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Here's a step-by-step guide to **deploy your Flask Email Spam Detection API on Railway** â€” one of the easiest free hosting platforms for Python apps.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ **Deploy Flask API to Railway**\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Step 1: Prepare Your Project Folder**\n",
    "\n",
    "Folder name: `email-spam-api`\n",
    "\n",
    "```\n",
    "email-spam-api/\n",
    "â”œâ”€â”€ app.py\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â”œâ”€â”€ ann_spam_model.h5\n",
    "â”œâ”€â”€ tfidf_vectorizer.pkl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Step 2: Modify `app.py` for Production**\n",
    "\n",
    "Update the `app.py` bottom section for Railway:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = int(os.environ.get(\"PORT\", 5000))\n",
    "    app.run(host='0.0.0.0', port=port)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Step 3: Create `requirements.txt`**\n",
    "\n",
    "```txt\n",
    "Flask\n",
    "tensorflow\n",
    "scikit-learn\n",
    "numpy\n",
    "```\n",
    "\n",
    "> Add `gunicorn` if Railway asks for production server (usually Flask dev server works fine for small apps).\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Step 4: Push Code to GitHub**\n",
    "\n",
    "If you donâ€™t have Git setup:\n",
    "\n",
    "```bash\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit\"\n",
    "gh repo create email-spam-api --public --source=. --remote=origin\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "Make sure your repo contains all 4 files: `app.py`, `requirements.txt`, `.h5`, `.pkl`.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Step 5: Deploy to Railway**\n",
    "\n",
    "1. Go to [https://railway.app](https://railway.app)\n",
    "2. Login with GitHub\n",
    "3. Click **â€œNew Projectâ€ â†’ â€œDeploy from GitHub Repoâ€**\n",
    "4. Select your `email-spam-api` repo\n",
    "5. Railway will auto-detect and install dependencies\n",
    "6. Once deployed, youâ€™ll get a public URL like:\n",
    "\n",
    "```\n",
    "https://email-spam-api.up.railway.app\n",
    "```\n",
    "\n",
    "âœ… Try `POST /predict`:\n",
    "\n",
    "```bash\n",
    "curl -X POST https://email-spam-api.up.railway.app/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"email\":\"You have won a free iPhone. Click here to claim.\"}'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ Want Me to Package It?\n",
    "\n",
    "I can give you:\n",
    "\n",
    "* âœ… A downloadable `.zip` of the full project (Flask, model, vectorizer)\n",
    "* âœ… GitHub-ready project folder\n",
    "* âœ… `README.md` for easy Railway deployment\n",
    "\n",
    "Would you like the `.zip` download or GitHub repo version?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
