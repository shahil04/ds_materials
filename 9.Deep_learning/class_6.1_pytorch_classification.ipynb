{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìå Binary Classification Using ANN in PyTorch - From Scratch**\n",
    "This tutorial covers the step-by-step implementation of a **basic Artificial Neural Network (ANN) for binary classification** using **PyTorch**.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ What is an ANN?**\n",
    "An **Artificial Neural Network (ANN)** is a computational model inspired by biological neural networks. It consists of:\n",
    "1. **Input Layer**: Accepts the features (independent variables).\n",
    "2. **Hidden Layers**: Performs computations using neurons and activation functions.\n",
    "3. **Output Layer**: Produces the final prediction (binary in this case).\n",
    "\n",
    "üí° **Goal**: Train an ANN to classify data points into two categories (0 or 1).\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Steps to Implement**\n",
    "1Ô∏è‚É£ Install & Import Required Libraries  \n",
    "2Ô∏è‚É£ Create a Dummy Dataset (Binary Classification)  \n",
    "3Ô∏è‚É£ Preprocess the Data  \n",
    "4Ô∏è‚É£ Build a Neural Network with PyTorch  \n",
    "5Ô∏è‚É£ Train the Model  \n",
    "6Ô∏è‚É£ Evaluate Performance  \n",
    "7Ô∏è‚É£ Make Predictions  \n",
    "\n",
    "---\n",
    "\n",
    "## **1Ô∏è‚É£ Install & Import Required Libraries**\n",
    "```python\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons  # Dummy dataset\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- **NumPy**: For handling numerical operations.\n",
    "- **Torch**: The core PyTorch library for building and training models.\n",
    "- **Torch.nn**: Contains neural network layers and activation functions.\n",
    "- **Torch.optim**: Provides optimizers (e.g., Adam, SGD) to update weights.\n",
    "- **Matplotlib**: Used for visualizing data and results.\n",
    "- **Scikit-learn (sklearn)**:\n",
    "  - `make_moons()`: Generates a **dummy dataset** for binary classification.\n",
    "  - `train_test_split()`: Splits data into **training** and **testing sets**.\n",
    "  - `StandardScaler()`: Normalizes feature values to improve model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Create a Dummy Dataset (Binary Classification)**\n",
    "```python\n",
    "# Generate a dummy dataset (moons dataset - useful for binary classification)\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Plot the dataset\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\")\n",
    "plt.title(\"Dummy Dataset (make_moons)\")\n",
    "plt.show()\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- `make_moons(n_samples=1000, noise=0.2)`: Generates **1000** points in a moon-shaped pattern with some noise.\n",
    "- `train_test_split()`: Splits the dataset into **80% training and 20% testing**.\n",
    "- `plt.scatter()`: Visualizes the dataset with colors representing class labels.\n",
    "\n",
    "‚úÖ **Output**: A dataset with two clusters representing **Class 0** and **Class 1**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Preprocess the Data**\n",
    "```python\n",
    "# Normalize the input features for better training\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- **Feature Scaling**:\n",
    "  - `StandardScaler()`: Transforms data so that it has **zero mean and unit variance**.\n",
    "  - **Why?** Scaling helps neural networks converge faster during training.\n",
    "- **Convert to PyTorch Tensors**:\n",
    "  - `torch.tensor()`: Converts NumPy arrays into **tensors** (PyTorch‚Äôs data structure).\n",
    "  - `reshape(-1, 1)`: Ensures the label tensor has a **column vector shape**.\n",
    "\n",
    "‚úÖ **Preprocessing ensures better learning and stability.**\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Build a Neural Network in PyTorch**\n",
    "```python\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 8)  # Input layer ‚Üí Hidden layer (8 neurons)\n",
    "        self.fc2 = nn.Linear(8, 4)  # Hidden layer ‚Üí Hidden layer (4 neurons)\n",
    "        self.fc3 = nn.Linear(4, 1)  # Hidden layer ‚Üí Output layer (1 neuron)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = ANN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- **Neural Network Structure**:\n",
    "  - `nn.Linear(2, 8)`: **Input layer** with 2 features ‚Üí **8 neurons**.\n",
    "  - `nn.Linear(8, 4)`: **Hidden layer** with 8 neurons ‚Üí **4 neurons**.\n",
    "  - `nn.Linear(4, 1)`: **Output layer** with 1 neuron (for binary classification).\n",
    "- **Activation Functions**:\n",
    "  - `nn.ReLU()`: Used in hidden layers to introduce **non-linearity**.\n",
    "  - `nn.Sigmoid()`: Converts output to a probability (0 to 1).\n",
    "- **Loss Function**:\n",
    "  - `nn.BCELoss()`: **Binary Cross-Entropy Loss** for binary classification.\n",
    "- **Optimizer**:\n",
    "  - `optim.Adam()`: **Adaptive optimization algorithm** for faster convergence.\n",
    "\n",
    "‚úÖ **The model is now ready for training.**\n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Train the Model**\n",
    "```python\n",
    "# Training loop\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- **Training Loop**:\n",
    "  - `zero_grad()`: Clears previous gradients.\n",
    "  - `forward()`: Makes a prediction.\n",
    "  - `backward()`: Computes gradients.\n",
    "  - `step()`: Updates model parameters.\n",
    "- **Loss Plot**:\n",
    "  - Helps monitor model training.\n",
    "\n",
    "‚úÖ **The loss should decrease over time, indicating learning.**\n",
    "\n",
    "---\n",
    "\n",
    "## **6Ô∏è‚É£ Evaluate Performance**\n",
    "```python\n",
    "# Evaluate on test data\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_tensor)\n",
    "    y_pred_labels = (y_pred_test > 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (y_pred_labels.eq(y_test_tensor).sum() / float(y_test_tensor.shape[0])).item()\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- `torch.no_grad()`: Disables gradient computation for **faster inference**.\n",
    "- **Accuracy Calculation**:\n",
    "  - `eq()`: Compares predicted and actual labels.\n",
    "  - `sum()`: Counts correct predictions.\n",
    "\n",
    "‚úÖ **Good accuracy indicates a well-trained model.**\n",
    "\n",
    "---\n",
    "\n",
    "## **7Ô∏è‚É£ Make Predictions**\n",
    "```python\n",
    "# Convert predictions to NumPy for visualization\n",
    "y_pred_np = y_pred_labels.numpy()\n",
    "\n",
    "# Plot test data with predicted labels\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred_np.flatten(), cmap=\"coolwarm\")\n",
    "plt.title(\"Predicted Classes\")\n",
    "plt.show()\n",
    "```\n",
    "### **üîπ Explanation**\n",
    "- **Plots the predicted class labels** on the test set.\n",
    "\n",
    "‚úÖ **The model correctly classifies most data points.**\n",
    "\n",
    "---\n",
    "\n",
    "## **üéØ Summary**\n",
    "‚úî **Built a Neural Network in PyTorch**  \n",
    "‚úî **Used a dummy dataset (moons) for classification**  \n",
    "‚úî **Preprocessed data using StandardScaler**  \n",
    "‚úî **Trained the model and achieved high accuracy**  \n",
    "‚úî **Visualized results with graphs & predictions**  \n",
    "\n",
    "Would you like **hyperparameter tuning** or a **comparison with TensorFlow?** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
