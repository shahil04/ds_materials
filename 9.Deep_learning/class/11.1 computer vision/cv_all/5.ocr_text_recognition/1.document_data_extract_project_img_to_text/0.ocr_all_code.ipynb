{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec35d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyhthon 3.10 for project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd313d3",
   "metadata": {},
   "source": [
    "\n",
    "# **OCR Bootcamp Notes**\n",
    "\n",
    "*(Optical Character Recognition)*\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **1. Introduction to OCR**\n",
    "\n",
    "### **What is OCR?**\n",
    "\n",
    "* OCR = **Optical Character Recognition**\n",
    "* Converts **printed or handwritten text in images** into **editable text**.\n",
    "* Works by detecting **characters, words, and text layout** from an image or document.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why OCR?**\n",
    "\n",
    "* Automates data entry.\n",
    "* Digitizes physical documents.\n",
    "* Enables **searchable PDFs**.\n",
    "* Used in banking, healthcare, transportation, retail.\n",
    "\n",
    "---\n",
    "\n",
    "### **Real-world Applications**\n",
    "\n",
    "* Scanning books into eBooks.\n",
    "* License Plate Recognition.\n",
    "* Invoice & Receipt Automation.\n",
    "* Passport/ID verification.\n",
    "* Subtitle extraction from videos.\n",
    "\n",
    "---\n",
    "\n",
    "### **OCR vs ICR**\n",
    "\n",
    "* **OCR**: Recognizes printed text.\n",
    "* **ICR**: Recognizes **handwritten text** using AI.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **2. How OCR Works**\n",
    "\n",
    "1. **Image Acquisition** ‚Üí Capture image/document.\n",
    "2. **Preprocessing** ‚Üí Clean image (noise removal, binarization).\n",
    "3. **Text Detection** ‚Üí Locate text regions.\n",
    "4. **Character Recognition** ‚Üí Extract text.\n",
    "5. **Post-processing** ‚Üí Correct errors.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **3. Image Preprocessing for OCR**\n",
    "\n",
    "**Why preprocessing?**\n",
    "Bad quality images ‚Üí Low OCR accuracy.\n",
    "Preprocessing helps clean the image for better results.\n",
    "\n",
    "### **Techniques**\n",
    "\n",
    "* **Grayscale conversion** ‚Üí Reduce complexity.\n",
    "* **Thresholding** ‚Üí Convert to black & white.\n",
    "\n",
    "  * Binary threshold.\n",
    "  * Adaptive threshold.\n",
    "* **Noise removal** ‚Üí Gaussian blur, Median filter.\n",
    "* **Morphological operations** ‚Üí Remove small artifacts.\n",
    "* **Deskewing** ‚Üí Correct tilted text.\n",
    "\n",
    "**Code Example (OpenCV Preprocessing):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbc00d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Image not found. Check the file path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check if image is loaded\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found. Check the file path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m     11\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Image not found. Check the file path."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Use raw string for path\n",
    "img = cv2.imread(r'C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\images\\lifestyle-02.jpg')\n",
    "\n",
    "# Check if image is loaded\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Image not found. Check the file path.\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply threshold\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Save processed image\n",
    "cv2.imwrite('images\\processed.jpg', thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033d9da",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ **4. OCR Engines & Libraries**\n",
    "\n",
    "* **Tesseract OCR** (most popular, by Google)\n",
    "* **EasyOCR** (Deep learning-based, supports multiple languages)\n",
    "* **PaddleOCR** (High accuracy)\n",
    "* **Google Vision API** (Cloud-based)\n",
    "\n",
    "---\n",
    "\n",
    "### **Installing Tesseract**\n",
    "\n",
    "**Windows/Linux Setup:**\n",
    "\n",
    "* Install Tesseract from official site.\n",
    "* Add path to environment variables.\n",
    "* Install Python wrapper:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic OCR in Python:**\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('text_image.png')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9528",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ **5. Advanced OCR Features**\n",
    "\n",
    "* **Multilingual OCR** ‚Üí Support for 100+ languages.\n",
    "* **Custom language models** ‚Üí Train for new fonts.\n",
    "* **Extracting structured data** ‚Üí Tables, forms.\n",
    "* **Confidence scores** ‚Üí Check accuracy.\n",
    "* **Handwriting recognition** ‚Üí Using deep learning (ICR).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **6. Improving OCR Accuracy**\n",
    "\n",
    "* Use **high-resolution images**.\n",
    "* Apply **deskewing** & **denoising**.\n",
    "* Convert to **grayscale or binary**.\n",
    "* Train custom models for complex fonts.\n",
    "* Use **Deep Learning (CRNN)** for better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **7. OCR in Applications**\n",
    "\n",
    "* **Extract text from PDFs** using `pdf2image` + OCR.\n",
    "* **Real-time OCR** using webcam feed.\n",
    "* **Batch OCR** for multiple documents.\n",
    "* **Integrating OCR with Flask/FastAPI for APIs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb48af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a90f3dc",
   "metadata": {},
   "source": [
    "## ‚úÖ **8. Projects & Case Studies**\n",
    "\n",
    "### **Beginner**\n",
    "\n",
    "‚úî Extract text from an image.\n",
    "‚úî Convert scanned PDF to editable text.\n",
    "\n",
    "### **Intermediate**\n",
    "\n",
    "‚úî License plate recognition.\n",
    "‚úî Business card reader using OCR + OpenCV.\n",
    "\n",
    "### **Advanced**\n",
    "\n",
    "‚úî Automated invoice processing with table extraction.\n",
    "‚úî Real-time subtitle extraction from video feed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52ca09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05154ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (from pdf2image) (11.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### **Example: Extract Text from PDF**\n",
    "# #  Alternative of  pdf2img  use if not run pymupdf\n",
    "# from pdf2image import convert_from_path\n",
    "# import pytesseract\n",
    "\n",
    "# pages = convert_from_path('document.pdf', 300)\n",
    "# for page in pages:\n",
    "#     text = pytesseract.image_to_string(page)\n",
    "#     print(text)\n",
    "\n",
    "# for this install 1. Install Poppler on Windows\n",
    "\n",
    "# Download Poppler for Windows from:\n",
    "# üëâ Poppler for Windows (GitHub releases) https://github.com/oschwartz10612/poppler-windows/releases/\n",
    "\n",
    "# Get the latest .zip file (e.g., poppler-xx.x.0.zip).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff31d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c9c1a",
   "metadata": {},
   "source": [
    "## Alternative pdf2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5095850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.4-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\cvenv\\lib\\site-packages (11.3.0)\n",
      "Downloading pymupdf-1.26.4-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.8/18.7 MB 14.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 10.2/18.7 MB 31.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.5/18.7 MB 28.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 25.7 MB/s  0:00:00\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf pillow\n",
    "# ‚úÖ Pros: Very fast, keeps text layout fairly well.\n",
    "# ‚ö†Ô∏è Cons: Won‚Äôt extract text from scanned PDFs (because they are images, not real text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(\"document.pdf\")\n",
    "\n",
    "for i, page in enumerate(doc):\n",
    "    # Render page to image (in memory)\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "\n",
    "    # OCR the image using Tesseract\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(f\"--- Page {i + 1} ---\")\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17683a6c",
   "metadata": {},
   "source": [
    "- PDFInfoNotInstalledError: Unable to get page count. Is poppler installed and in PATH?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92142d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ 2. pdfplumber\n",
    "\n",
    "# Great for structured text (tables, rows, columns).\n",
    "# ‚úÖ Pros: Keeps formatting, works well for tables.\n",
    "# ‚ö†Ô∏è Cons: Also won‚Äôt work for scanned PDFs.\n",
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"document.pdf\") as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        print(f\"--- Page {page_num} ---\")\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b044391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38ee246b",
   "metadata": {},
   "source": [
    "## Exract data from image  --> streamlit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from ocr_utils import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "st.set_page_config(page_title=\"OCR Text Recognition\")\n",
    "st.title(\"üìù OCR Text Recognition with Pytesseract\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image with text\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "if uploaded_file:\n",
    "    image = load_image(uploaded_file.read())\n",
    "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
    "\n",
    "    thresh = preprocess_image(image)\n",
    "    st.image(thresh, caption=\"Preprocessed Image\", use_column_width=True)\n",
    "\n",
    "    st.subheader(\"üìÑ Extracted Text\")\n",
    "    text = extract_text(thresh)\n",
    "    st.code(text)\n",
    "\n",
    "    st.subheader(\"üîç Word Detection with Bounding Boxes\")\n",
    "    data = extract_data(thresh)\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    st.image(image, caption=\"Detected Words\", use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518497ca",
   "metadata": {},
   "source": [
    "## 2. License plate number detections Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9836dc8",
   "metadata": {},
   "source": [
    "## code \n",
    "\n",
    "<!-- \n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Set path to tesseract.exe if needed\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def recognize_plate(image_path):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Resize (optional for large images)\n",
    "    img = cv2.resize(img, (600, 400))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise reduction\n",
    "    blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blur, 30, 200)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    plate_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        # Approximate the contour\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:  # Looks like a rectangle\n",
    "            plate_contour = approx\n",
    "            break\n",
    "\n",
    "    if plate_contour is not None:\n",
    "        # Create mask and extract plate region\n",
    "        mask = cv2.drawContours(cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR), [plate_contour], 0, (255, 255, 255), -1)\n",
    "        x, y, w, h = cv2.boundingRect(plate_contour)\n",
    "        plate = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # OCR\n",
    "        text = pytesseract.image_to_string(plate, config='--psm 8')\n",
    "        print(\"Detected Plate Text:\", text.strip())\n",
    "\n",
    "        # Optional: Show detected plate\n",
    "        cv2.imshow(\"Plate\", plate)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"License plate contour not detected.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "path =r\"C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\document_data_extract_project_img_to_text\\car.jpg\"\n",
    "recognize_plate(path)\n",
    "\n",
    "\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43105ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully!\n",
      "Detected Plate Text: TN 09 BY 9726\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set path to tesseract.exe if needed\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def recognize_plate(image_path):\n",
    "    # Check if path exists\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "    # Load image using PIL\n",
    "    try:\n",
    "        pil_img = Image.open(image_path)\n",
    "        print(\"Image loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to load image: {e}\")\n",
    "\n",
    "    # Convert PIL image to OpenCV format\n",
    "    img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize (optional)\n",
    "    img = cv2.resize(img, (600, 400))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise reduction\n",
    "    blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blur, 30, 200)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "    plate_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        # Approximate contour\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        if len(approx) == 4:  # Rectangle-like contour\n",
    "            plate_contour = approx\n",
    "            break\n",
    "\n",
    "    if plate_contour is not None:\n",
    "        # Extract plate region\n",
    "        x, y, w, h = cv2.boundingRect(plate_contour)\n",
    "        plate = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # OCR\n",
    "        config = \"--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "        text = pytesseract.image_to_string(plate, config=config)\n",
    "        print(\"Detected Plate Text:\", text.strip())\n",
    "\n",
    "        # Optional: Show detected plate\n",
    "        cv2.imshow(\"Detected Plate\", plate)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Optional: Draw contour on original image\n",
    "        cv2.drawContours(img, [plate_contour], -1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Plate Contour\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"License plate contour not detected.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "path = r\"C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\cv\\5.ocr_text_recognition\\document_data_extract_project_img_to_text\\car.jpg\"\n",
    "recognize_plate(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3c8be",
   "metadata": {},
   "source": [
    "## 3.Business carder reader Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81206e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÉ Raw OCR Text:\n",
      "  \n",
      "\n",
      "Mariana Anderson\n",
      "\n",
      "Marketing Manager\n",
      "\n",
      "+123‚Äî456r789O\n",
      "+123‚Äî456r7890\n",
      "\n",
      "www real\\ygreats\\te.(om\n",
      "hel\\o@rea\\|ygreats>te.com\n",
      "\n",
      "123 Anywhere St., Any Qty, ST\n",
      "12345\n",
      "\n",
      "Business\n",
      "Logo\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Name: Mariana Anderson\n",
      "Email: []\n",
      "Phone: []\n",
      "Website: []\n",
      "Company: Logo\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# Optional: Set path to tesseract if not in PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def extract_business_card_info(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"‚ùå Could not load image.\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # OCR to extract text\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    print(\"üìÉ Raw OCR Text:\\n\", text)\n",
    "\n",
    "    # Regex-based extraction\n",
    "    email = re.findall(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', text)\n",
    "    phone = re.findall(r'(\\+?\\d[\\d\\s\\-().]{7,})', text)\n",
    "    website = re.findall(r'(https?://\\S+|www\\.\\S+)', text)\n",
    "\n",
    "    # Just mock logic for demo purposes\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    name = lines[0] if lines else \"\"\n",
    "    company = lines[-1] if len(lines) > 2 else \"\"\n",
    "\n",
    "    result = {\n",
    "        \"Name\": name,\n",
    "        \"Email\": email,\n",
    "        \"Phone\": phone,\n",
    "        \"Website\": website,\n",
    "        \"Company\": company,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "data = extract_business_card_info(\"business.jpg\")\n",
    "for k, v in data.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90ed73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
