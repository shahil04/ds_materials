{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608d2208",
   "metadata": {},
   "source": [
    "# Basic LLM Usage\n",
    "\n",
    "This notebook demonstrates basic usage of Hugging Face Transformers for generation, classification, and translation. Designed to run on local machine or Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555cc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment when running in a fresh environment)\n",
    "# !pip install transformers accelerate sentencepiece\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "print('transformers version loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ca468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Generate some sample data\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1) # Features\n",
    "y = np.array([2, 4, 5, 4, 5, 7, 8, 9, 10, 12]) # Target variable\n",
    "\n",
    "# 2. Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# 4. Make a prediction\n",
    "new_X = np.array([11]).reshape(-1, 1)\n",
    "prediction = model.predict(new_X)\n",
    "\n",
    "print(f\"Trained model coefficient: {model.coef_[0]:.2f}\")\n",
    "print(f\"Trained model intercept: {model.intercept_:.2f}\")\n",
    "print(f\"Prediction for new data {new_X[0][0]}: {prediction[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62c233",
   "metadata": {},
   "source": [
    "## 1.text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c703422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d917a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ded28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pipe(\"This restaurant is not awesome\")\n",
    "data[0]['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce86c4",
   "metadata": {},
   "source": [
    "‚≠ê 3.6 Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "result = pipe(\n",
    "    \"This is a course about AI and machine learning.\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"sports\"]\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cac254",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/v4.57.0/en/main_classes/pipelines#transformers.Pipeline.model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff371e0",
   "metadata": {},
   "source": [
    "## 2.Text Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "result = pipe(\n",
    "    \"Once upon a time in India, there was a data scientist\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc94fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990ef88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(task=\"text-generation\", model=\"google/gemma-2-2b\")\n",
    "pipeline(\"the secret to baking a really good cake is \")\n",
    "[{'generated_text': 'the secret to baking a really good cake is 1. the right ingredients 2. the'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26831749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dc5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7584ec8",
   "metadata": {},
   "source": [
    "## 3. text summarizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(task=\"summarization\", model=\"google/pegasus-billsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47321c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_text = pipeline(\"Section was formerly set out as section 44 of this title. As originally enacted, this section contained two further provisions that 'nothing in this act shall be construed as in any wise affecting the grant of lands made to the State of California by virtue of the act entitled 'An act authorizing a grant to the State of California of the Yosemite Valley, and of the land' embracing the Mariposa Big-Tree Grove, approved June thirtieth, eighteen hundred and sixty-four; or as affecting any bona-fide entry of land made within the limits above described under any law of the United States prior to the approval of this act.' The first quoted provision was omitted from the Code because the land, granted to the state of California pursuant to the Act cite, was receded to the United States. Resolution June 11, 1906, No. 27, accepted the recession.\")\n",
    "[{'summary_text': 'Instructs the Secretary of the Interior to convey to the State of California all right, title, and interest of the United States in and to specified lands which are located within the Yosemite and Mariposa National Forests, California.'}]\n",
    "\n",
    "\n",
    "summarize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = pipe(\"I love using Hugging Face pipelines!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6148d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed3c6a86",
   "metadata": {},
   "source": [
    "‚≠ê 3.5 Translation (English ‚Üí Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944280ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pipeline(\"translation_en_to_hi\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "print(pipe(\"I love learning transformers!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd9527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dee8408",
   "metadata": {},
   "source": [
    "‚≠ê 3.7 Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb02dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(\"/content/new_pic.jpg\")\n",
    "\n",
    "print(pipe(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9476d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66179d3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê 3.8 Speech-to-Text (ASR)\n",
    "pipe = pipeline(\"automatic-speech-recognition\",\n",
    "                model=\"openai/whisper-small\")\n",
    "\n",
    "\n",
    "# print(pipe(\"audio.wav\"))\n",
    "# https://huggingface.co/docs/transformers/en/model_doc/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089460c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff9637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71f3493",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef73bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê 3.9 Embeddings / Feature Extraction\n",
    "pipe = pipeline(\"feature-extraction\",\n",
    "                model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "emb = pipe(\"This is a feature extraction example.\")\n",
    "print(len(emb[0]))   # 384 dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c339c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # hf_ CXeDvBPImWhKBaiJ\n",
    "    # BFfuuKpqlQKxjIgIIA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab0156",
   "metadata": {},
   "source": [
    "## ‚≠ê 3.10 Text-to-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚≠ê 3.10 Text-to-Image\n",
    "\n",
    "# (Pipeline does NOT support; must use Diffusers)\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607add7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"a futuristic city in neon lights\").images[0]\n",
    "image.save(\"city.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4d609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c01830",
   "metadata": {},
   "outputs": [],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025171eb",
   "metadata": {},
   "source": [
    "Nice, let‚Äôs turn all those Hugging Face models into **one Streamlit app with a dropdown menu** üòÑ\n",
    "\n",
    "Below is a **single `app.py`** file where you can:\n",
    "\n",
    "* Pick a **task** from a dropdown.\n",
    "* See task-specific inputs (text, labels, image upload, audio upload).\n",
    "* Run the corresponding **Hugging Face pipeline / diffusers model**.\n",
    "* View the result directly in the browser.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß 1. `requirements.txt`\n",
    "\n",
    "Create a `requirements.txt`:\n",
    "\n",
    "```txt\n",
    "streamlit\n",
    "transformers\n",
    "torch\n",
    "diffusers\n",
    "sentencepiece\n",
    "accelerate\n",
    "safetensors\n",
    "Pillow\n",
    "```\n",
    "\n",
    "Install:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† 2. `app.py` ‚Äì Streamlit Multi-Model Demo\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"Hugging Face Multi-Model Demo\", layout=\"wide\")\n",
    "st.title(\"ü§ó Hugging Face Multi-Model Playground (Streamlit)\")\n",
    "\n",
    "st.sidebar.header(\"‚öôÔ∏è Settings\")\n",
    "task = st.sidebar.selectbox(\n",
    "    \"Choose a task\",\n",
    "    [\n",
    "        \"Sentiment Analysis\",\n",
    "        \"Text Classification\",\n",
    "        \"Text Generation\",\n",
    "        \"Summarization\",\n",
    "        \"Translation EN‚ÜíHI\",\n",
    "        \"Zero-shot Classification\",\n",
    "        \"Image Classification\",\n",
    "        \"Speech to Text\",\n",
    "        \"Feature Extraction (Embeddings)\",\n",
    "        \"Text to Image (Stable Diffusion)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.write(\"üß† Models are loaded lazily and cached.\")\n",
    "st.sidebar.write(\"üí° First run of a task may take time (downloads model).\")\n",
    "\n",
    "\n",
    "# -------------------- CACHED PIPELINES -------------------- #\n",
    "\n",
    "@st.cache_resource\n",
    "def get_sentiment_pipe():\n",
    "    return pipeline(\"sentiment-analysis\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_text_cls_pipe():\n",
    "    return pipeline(\"text-classification\", model=\"distilbert-base-uncased\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_text_gen_pipe():\n",
    "    return pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_summarization_pipe():\n",
    "    return pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_translation_pipe():\n",
    "    return pipeline(\"translation_en_to_hi\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_zero_shot_pipe():\n",
    "    return pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_image_cls_pipe():\n",
    "    return pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_asr_pipe():\n",
    "    # Small Whisper model for demo\n",
    "    return pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_embedding_pipe():\n",
    "    return pipeline(\n",
    "        \"feature-extraction\",\n",
    "        model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "@st.cache_resource\n",
    "def get_sd_pipe():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=dtype,\n",
    "    ).to(device)\n",
    "    return pipe, device\n",
    "\n",
    "\n",
    "# -------------------- TASK UIs -------------------- #\n",
    "\n",
    "if task == \"Sentiment Analysis\":\n",
    "    st.subheader(\"üß™ Sentiment Analysis\")\n",
    "    text = st.text_area(\"Enter text\", \"I love using Hugging Face with Streamlit!\")\n",
    "\n",
    "    if st.button(\"Analyze Sentiment\"):\n",
    "        if text.strip():\n",
    "            pipe = get_sentiment_pipe()\n",
    "            result = pipe(text)\n",
    "            st.json(result)\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif task == \"Text Classification\":\n",
    "    st.subheader(\"üè∑Ô∏è Text Classification\")\n",
    "    text = st.text_area(\"Enter text\", \"This course is amazing and very helpful.\")\n",
    "\n",
    "    if st.button(\"Classify\"):\n",
    "        if text.strip():\n",
    "            pipe = get_text_cls_pipe()\n",
    "            result = pipe(text)\n",
    "            st.json(result)\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif task == \"Text Generation\":\n",
    "    st.subheader(\"‚úçÔ∏è Text Generation\")\n",
    "    prompt = st.text_area(\"Enter prompt\", \"Once upon a time in India, there was a data scientist\")\n",
    "    max_len = st.slider(\"Max length\", 20, 200, 60)\n",
    "    num_return = st.slider(\"Number of sequences\", 1, 5, 1)\n",
    "\n",
    "    if st.button(\"Generate Text\"):\n",
    "        if prompt.strip():\n",
    "            pipe = get_text_gen_pipe()\n",
    "            outputs = pipe(\n",
    "                prompt,\n",
    "                max_length=max_len,\n",
    "                num_return_sequences=num_return,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "            )\n",
    "            for i, out in enumerate(outputs):\n",
    "                st.markdown(f\"**Output {i+1}:**\")\n",
    "                st.write(out[\"generated_text\"])\n",
    "        else:\n",
    "            st.warning(\"Please enter a prompt.\")\n",
    "\n",
    "elif task == \"Summarization\":\n",
    "    st.subheader(\"üìù Summarization\")\n",
    "    text = st.text_area(\"Enter long text to summarize\", height=200)\n",
    "\n",
    "    max_len = st.slider(\"Max summary length\", 20, 200, 100)\n",
    "    min_len = st.slider(\"Min summary length\", 5, 100, 30)\n",
    "\n",
    "    if st.button(\"Summarize\"):\n",
    "        if text.strip():\n",
    "            pipe = get_summarization_pipe()\n",
    "            result = pipe(\n",
    "                text,\n",
    "                max_length=max_len,\n",
    "                min_length=min_len,\n",
    "                do_sample=False\n",
    "            )\n",
    "            st.subheader(\"Summary\")\n",
    "            st.write(result[0][\"summary_text\"])\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif task == \"Translation EN‚ÜíHI\":\n",
    "    st.subheader(\"üåê Translation (English ‚Üí Hindi)\")\n",
    "    text = st.text_area(\"Enter English text\", \"I love learning Transformers and Generative AI.\")\n",
    "\n",
    "    if st.button(\"Translate\"):\n",
    "        if text.strip():\n",
    "            pipe = get_translation_pipe()\n",
    "            result = pipe(text)\n",
    "            st.subheader(\"Hindi Translation\")\n",
    "            st.write(result[0][\"translation_text\"])\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif task == \"Zero-shot Classification\":\n",
    "    st.subheader(\"üéØ Zero-shot Classification\")\n",
    "    text = st.text_area(\"Enter text\", \"This is a course about AI and machine learning.\")\n",
    "    labels_input = st.text_input(\n",
    "        \"Candidate labels (comma-separated)\",\n",
    "        \"education, politics, sports, technology\"\n",
    "    )\n",
    "    multi_label = st.checkbox(\"Multi-label classification\", value=False)\n",
    "\n",
    "    if st.button(\"Classify (Zero-shot)\"):\n",
    "        if text.strip() and labels_input.strip():\n",
    "            labels = [l.strip() for l in labels_input.split(\",\") if l.strip()]\n",
    "            pipe = get_zero_shot_pipe()\n",
    "            result = pipe(text, candidate_labels=labels, multi_label=multi_label)\n",
    "            st.json(result)\n",
    "        else:\n",
    "            st.warning(\"Please enter text and at least one label.\")\n",
    "\n",
    "elif task == \"Image Classification\":\n",
    "    st.subheader(\"üñºÔ∏è Image Classification\")\n",
    "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "        if st.button(\"Classify Image\"):\n",
    "            pipe = get_image_cls_pipe()\n",
    "            result = pipe(image)\n",
    "            st.subheader(\"Predictions\")\n",
    "            st.json(result)\n",
    "\n",
    "elif task == \"Speech to Text\":\n",
    "    st.subheader(\"üéôÔ∏è Speech to Text (ASR)\")\n",
    "    st.write(\"Upload an audio file (e.g., .wav, .mp3).\")\n",
    "    uploaded_audio = st.file_uploader(\"Upload audio\", type=[\"wav\", \"mp3\", \"flac\", \"ogg\", \"m4a\"])\n",
    "\n",
    "    if uploaded_audio is not None:\n",
    "        st.audio(uploaded_audio)\n",
    "\n",
    "        if st.button(\"Transcribe\"):\n",
    "            # Save to temp file and send path to pipeline\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_audio.name)[1]) as tmp:\n",
    "                tmp.write(uploaded_audio.read())\n",
    "                tmp_path = tmp.name\n",
    "\n",
    "            pipe = get_asr_pipe()\n",
    "            result = pipe(tmp_path)\n",
    "            st.subheader(\"Transcription\")\n",
    "            st.write(result[\"text\"])\n",
    "\n",
    "            # cleanup temp file\n",
    "            os.remove(tmp_path)\n",
    "\n",
    "elif task == \"Feature Extraction (Embeddings)\":\n",
    "    st.subheader(\"üìê Feature Extraction / Embeddings\")\n",
    "    text = st.text_area(\"Enter text\", \"This is an example sentence for embeddings.\")\n",
    "\n",
    "    if st.button(\"Get Embeddings\"):\n",
    "        if text.strip():\n",
    "            pipe = get_embedding_pipe()\n",
    "            emb = pipe(text)\n",
    "            # emb shape: [1, seq_len, hidden_dim]\n",
    "            seq_len = len(emb[0])\n",
    "            hidden_dim = len(emb[0][0])\n",
    "            st.write(f\"Embedding shape: [1, {seq_len}, {hidden_dim}]\")\n",
    "            st.markdown(\"**First token vector (truncated):**\")\n",
    "            st.write(emb[0][0][:10])\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif task == \"Text to Image (Stable Diffusion)\":\n",
    "    st.subheader(\"üé® Text to Image (Stable Diffusion)\")\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        st.warning(\"CUDA GPU not detected. This will be VERY slow on CPU, or may run out of memory.\")\n",
    "\n",
    "    prompt = st.text_area(\"Enter image prompt\", \"a cute robot teaching data science, digital art, vibrant colors\")\n",
    "    steps = st.slider(\"Inference steps\", 10, 50, 25)\n",
    "    guidance = st.slider(\"Guidance scale\", 1.0, 15.0, 7.5)\n",
    "\n",
    "    if st.button(\"Generate Image\"):\n",
    "        if prompt.strip():\n",
    "            with st.spinner(\"Generating image... (first time may take a while)\"):\n",
    "                pipe, device = get_sd_pipe()\n",
    "                image = pipe(\n",
    "                    prompt,\n",
    "                    num_inference_steps=steps,\n",
    "                    guidance_scale=guidance\n",
    "                ).images[0]\n",
    "            st.image(image, caption=\"Generated Image\", use_column_width=True)\n",
    "        else:\n",
    "            st.warning(\"Please enter a prompt.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è 3. Run the App\n",
    "\n",
    "In the folder with `app.py`:\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "Then open the local URL (usually `http://localhost:8501`).\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can next:\n",
    "\n",
    "* add **model selection dropdown per task** (e.g., different sentiment models),\n",
    "* or export this as a **zip-ready project structure** (with `app.py`, `requirements.txt`, `README.md`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e6a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98e1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c273464f",
   "metadata": {},
   "source": [
    "Alright, let‚Äôs build a **free image generation setup using Hugging Face + Transformers** üòé\n",
    "\n",
    "I‚Äôll show you two options:\n",
    "\n",
    "1. **Completely free & easiest** ‚Üí Use **Hugging Face Inference API** (no GPU needed, runs on HF servers)\n",
    "2. **Local free (needs GPU/strong CPU)** ‚Üí Download model and run via `transformers` / `diffusers`\n",
    "\n",
    "Since you wrote *‚Äúusing tranfrmer‚Äù*, I‚Äôll keep it focused on Hugging Face ecosystem (Transformers-style pipelines).\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Setup ‚Äì Hugging Face Account & Token (One Time)\n",
    "\n",
    "1. Go to Hugging Face ‚Üí create a free account.\n",
    "2. Go to **Settings ‚Üí Access Tokens** ‚Üí create a **Read token**.\n",
    "3. Install required libraries:\n",
    "\n",
    "```bash\n",
    "pip install transformers torch pillow requests\n",
    "```\n",
    "\n",
    "If you want to use diffusion models (recommended for images):\n",
    "\n",
    "```bash\n",
    "pip install diffusers accelerate safetensors\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Easiest Way: Use Hugging Face Inference API (Free Tier)\n",
    "\n",
    "Here we **don‚Äôt download** the model; we just call it using HTTPS.\n",
    "Example using a Stable Diffusion model (text ‚Üí image):\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-2-1\"\n",
    "HF_TOKEN = \"YOUR_HF_API_TOKEN\"   # <--- paste your token here\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer HF_TOKEN_REPLACE\"}\n",
    "\n",
    "def generate_image(prompt, output_path=\"generated.png\"):\n",
    "    payload = {\"inputs\": prompt}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Saved image to {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"a futuristic city at sunset, ultra realistic, 4k\"\n",
    "    generate_image(prompt)\n",
    "```\n",
    "\n",
    "üëâ **Important:** Replace\n",
    "\n",
    "```python\n",
    "headers = {\"Authorization\": f\"Bearer HF_TOKEN_REPLACE\"}\n",
    "```\n",
    "\n",
    "with\n",
    "\n",
    "```python\n",
    "headers = {\"Authorization\": f\"Bearer \" + HF_TOKEN}\n",
    "```\n",
    "\n",
    "This gives you a **free image generator** using a Hugging Face model, no GPU on your side.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Using `diffusers` + Transformers Locally (Open-Source, Free)\n",
    "\n",
    "This uses a **Transformers-style pipeline** but via the `diffusers` library (Hugging Face official for diffusion models).\n",
    "\n",
    "```python\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Download any free text-to-image model, example:\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,  # use float32 if you don't have GPU\n",
    ")\n",
    "\n",
    "# If you have a GPU (recommended)\n",
    "if torch.cuda.is_available():\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a cute robot teaching data science, digital art, vibrant colors\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "image.save(\"robot_ds.png\")\n",
    "print(\"Image saved as robot_ds.png\")\n",
    "```\n",
    "\n",
    "If you **don‚Äôt** have GPU, change to:\n",
    "\n",
    "```python\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32\n",
    ").to(\"cpu\")\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è CPU will be **very slow** but still free.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ ‚ÄúTransformers‚Äù Style Pipeline (Non-diffusers models)\n",
    "\n",
    "Some image models are available directly via `transformers` pipelines (e.g., text-to-image, image-to-image). Example:\n",
    "\n",
    "```python\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Example: Phi-3-Vision / Qwen-VL etc. can generate images or reason about them\n",
    "# (Many models are more multimodal than pure generators)\n",
    "```\n",
    "\n",
    "But for **pure image generation**, **diffusers** is the normal + recommended way in HF ecosystem, and it‚Äôs built to work **with transformers under the hood**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Wrap It as a Simple ‚ÄúFree HF Image Generator‚Äù Function\n",
    "\n",
    "Here‚Äôs a neat utility that automatically uses GPU if available:\n",
    "\n",
    "```python\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "class HFImageGenerator:\n",
    "    def __init__(self, model_id=\"runwayml/stable-diffusion-v1-5\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        dtype = torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "\n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=dtype,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def generate(self, prompt: str, file_name: str = \"output.png\"):\n",
    "        image = self.pipe(prompt).images[0]\n",
    "        image.save(file_name)\n",
    "        print(f\"‚úÖ Saved: {file_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gen = HFImageGenerator()\n",
    "    gen.generate(\"a fantasy landscape with floating islands, matte painting\", \"fantasy.png\")\n",
    "```\n",
    "\n",
    "This is basically a **free image generator model using Hugging Face** that you can plug into Flask, FastAPI, Streamlit, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ If You Tell Me Your Goal‚Ä¶\n",
    "\n",
    "For example:\n",
    "\n",
    "* ‚ÄúUse it in **Flask API**‚Äù\n",
    "* ‚ÄúUse it in **Streamlit app**‚Äù\n",
    "* ‚ÄúUse it in a **Jupyter Notebook** as a teaching demo‚Äù\n",
    "\n",
    "‚Ä¶I can give you **full project code** (app.py + requirements.txt + sample prompts) tailored to that.\n",
    "\n",
    "For now, you can copy-paste any of the above blocks and run them directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b0df0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9007eb5",
   "metadata": {},
   "source": [
    "## Text generation with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = 'Artificial intelligence is'\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = model.generate(inputs['input_ids'], max_length=50, temperature=0.7, top_p=0.9)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2e2d4",
   "metadata": {},
   "source": [
    "## Text classification (BERT pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4380a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('text-classification', model='bert-base-uncased')\n",
    "print(classifier('I love using AI for automation!'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f3b38",
   "metadata": {},
   "source": [
    "## Translation (T5) using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline('translation_en_to_de', model='t5-small')  # or use 't5-small'\n",
    "print(translator('How are you?'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
