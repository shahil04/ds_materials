{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df00129e",
   "metadata": {},
   "source": [
    "### python version --> 3.10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqL3kau2XEfR",
   "metadata": {
    "id": "eqL3kau2XEfR"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tempfile\n",
    "\n",
    "st.set_page_config(page_title=\"MediaPipe Demo\", layout=\"wide\")\n",
    "\n",
    "# Sidebar options\n",
    "st.sidebar.title(\"MediaPipe Features\")\n",
    "option = st.sidebar.selectbox(\n",
    "    \"Choose a Model\",\n",
    "    [\"Face Detection\", \"Hand Tracking\", \"Face Mesh\", \"Pose Detection\", \"Holistic\"]\n",
    ")\n",
    "\n",
    "st.title(\"ðŸŽ¥ MediaPipe Computer Vision Demo\")\n",
    "st.write(\"Select a feature from the sidebar and upload a video or use webcam.\")\n",
    "\n",
    "# File upload or Webcam option\n",
    "source = st.sidebar.radio(\"Select Input Source\", [\"Webcam\", \"Upload Video\"])\n",
    "\n",
    "if source == \"Upload Video\":\n",
    "    uploaded_file = st.file_uploader(\"Upload a video file\", type=[\"mp4\", \"avi\", \"mov\"])\n",
    "else:\n",
    "    uploaded_file = None\n",
    "\n",
    "# Initialize MediaPipe solutions\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Function to process frame\n",
    "def process_frame(image, model):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if model == \"Face Detection\":\n",
    "        with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as fd:\n",
    "            results = fd.process(rgb)\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "    elif model == \"Hand Tracking\":\n",
    "        with mp_hands.Hands() as hands:\n",
    "            results = hands.process(rgb)\n",
    "            if results.multi_hand_landmarks:\n",
    "                for landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    elif model == \"Face Mesh\":\n",
    "        with mp_face_mesh.FaceMesh() as fm:\n",
    "            results = fm.process(rgb)\n",
    "            if results.multi_face_landmarks:\n",
    "                for landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(image, landmarks, mp_face_mesh.FACEMESH_TESSELATION)\n",
    "\n",
    "    elif model == \"Pose Detection\":\n",
    "        with mp_pose.Pose() as pose:\n",
    "            results = pose.process(rgb)\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    elif model == \"Holistic\":\n",
    "        with mp_holistic.Holistic() as holistic:\n",
    "            results = holistic.process(rgb)\n",
    "            if results.face_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "            if results.left_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.right_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Show video\n",
    "stframe = st.empty()\n",
    "\n",
    "if source == \"Webcam\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "else:\n",
    "    if uploaded_file is not None:\n",
    "        tfile = tempfile.NamedTemporaryFile(delete=False)\n",
    "        tfile.write(uploaded_file.read())\n",
    "        cap = cv2.VideoCapture(tfile.name)\n",
    "    else:\n",
    "        cap = None\n",
    "\n",
    "if cap is not None:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = process_frame(frame, option)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        stframe.image(frame, channels=\"RGB\")\n",
    "\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kSAQnDTXqicO",
   "metadata": {
    "id": "kSAQnDTXqicO"
   },
   "outputs": [],
   "source": [
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L6MNxhjPXHqx",
   "metadata": {
    "id": "L6MNxhjPXHqx"
   },
   "source": [
    "## Volumn Increase and decrease using hand gasture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EE5G0JhUf3hU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EE5G0JhUf3hU",
    "outputId": "47f19eb7-baf4-4b23-9ae0-32629a4a1e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting comtypes\n",
      "  Downloading comtypes-1.4.12-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pycaw\n",
      "  Downloading pycaw-20240210-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pycaw) (7.0.0)\n",
      "Downloading comtypes-1.4.12-py3-none-any.whl (253 kB)\n",
      "Downloading pycaw-20240210-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: comtypes, pycaw\n",
      "\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   ---------------------------------------- 0/2 [comtypes]\n",
      "   -------------------- ------------------- 1/2 [pycaw]\n",
      "   -------------------- ------------------- 1/2 [pycaw]\n",
      "   ---------------------------------------- 2/2 [pycaw]\n",
      "\n",
      "Successfully installed comtypes-1.4.12 pycaw-20240210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install comtypes pycaw\n",
    "# !pip install ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73363cb",
   "metadata": {
    "id": "b73363cb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from math import hypot\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "min_vol, max_vol = volume.GetVolumeRange()[:2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "\n",
    "    lmList = []\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handlandmark in results.multi_hand_landmarks:\n",
    "            for id,lm in enumerate(handlandmark.landmark):\n",
    "                h,w,_ = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "                lmList.append([id,cx,cy])\n",
    "            mpDraw.draw_landmarks(img,handlandmark,mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    if lmList != []:\n",
    "        x1,y1 = lmList[4][1],lmList[4][2]\n",
    "        x2,y2 = lmList[8][1],lmList[8][2]\n",
    "\n",
    "        cv2.circle(img,(x1,y1),4,(255,0,0),cv2.FILLED)\n",
    "        cv2.circle(img,(x2,y2),4,(255,0,0),cv2.FILLED)\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(255,0,0),3)\n",
    "\n",
    "        length = hypot(x2-x1,y2-y1)\n",
    "\n",
    "        value = np.interp(length,[15,300],[min_vol,max_vol])\n",
    "        volume.SetMasterVolumeLevel(value, None)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('Image',img)\n",
    "    if cv2.waitKey(1) & 0xff==ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb31cc",
   "metadata": {
    "id": "4bfb31cc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d09068",
   "metadata": {
    "id": "67d09068"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17b0a6b",
   "metadata": {
    "id": "d17b0a6b"
   },
   "source": [
    "I've added a cell to install the required libraries. I've also removed the `ctypes` import from the next cell as it's a built-in library and doesn't need to be imported explicitly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rasa-eA7WAmP0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
