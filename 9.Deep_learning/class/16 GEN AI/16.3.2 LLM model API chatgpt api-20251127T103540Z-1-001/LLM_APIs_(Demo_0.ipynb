{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Api\n",
        "<!-- --api_hf_ piqjFDQzitppOQtOAMDVDWOQPdHZXwXAAZ\n",
        "gemmi_AIzaSyDHXP-hKN5b4 QFXLAope3kYOCUiie-BA2o\n",
        "openrouter_sk-or-v1-dca6b0e74f09804c0b20205c20b7 9bbb3f02a994265521d8804831e01295c3a1https://openrouter.ai/docs/quickstart\n",
        "gpt_sk-proj-3BEo7CsSpL8BD8yiO70cFP8Cw-67I-D-tW1ICOGhOYFFixtVQ28wDAWreRf5aMslaFRsF7pLtuT3BlbkFJ-BVV_9HiVw-CYMg-OP5_tXtxcJKn91WEdrZSiZVe6Od-kybIqVnNgFBUG1G0kq8iGaE4u33kcA\n",
        "xai-yVNhQxrpPVIuvQvLl30lC38JeOyceCgC9ZQfsahillPmY0rr3PAscbC8hVLUQR55I03EywUGTtU83N24F8K1B_yes -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ordFFsr9BEla"
      },
      "source": [
        "Below is a **SINGLE, ALL-IN-ONE, TEACHING-READY NOTES** for **API setup of ALL major LLM providers**.\n",
        "You can **share this as notes, convert to PDF, or use directly in class/interviews**.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“˜ ALL-IN-ONE NOTES\n",
        "\n",
        "## LLM API Setup Guide (Cloud + Open + Private)\n",
        "\n",
        "![Image](https://i0.wp.com/novita-blog.s3.ap-southeast-1.amazonaws.com/simple-guide-to-using-llm-api-key-1%2ALepAS5O6oR9V-gqhz8_-jQ.png?ssl=1\\&w=1200)\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/0%2A5epoR920g76jgG4K.png)\n",
        "\n",
        "![Image](https://a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-1-of-4-2.png)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  What is an LLM API? (1-Line)\n",
        "\n",
        "An **LLM API** allows your application to send a **prompt** to a model and receive a **response** over HTTP securely using an **API key**.\n",
        "\n",
        "```\n",
        "App / Notebook â†’ API Key â†’ LLM Provider â†’ Response\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸŸ¢ FREE / FREE-TIER (BEST FOR DEMOS)\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ Hugging Face Inference API (FREE)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**Hugging Face**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âœ… Free tier (no credit card)\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Open-source LLMs (Mistral, Qwen, Falcon-small)\n",
        "* Workshops, teaching demos\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://huggingface.co](https://huggingface.co)\n",
        "2. Sign up / Login\n",
        "3. Profile â†’ **Settings**\n",
        "4. **Access Tokens**\n",
        "5. **New Token**\n",
        "6. Name: `demo-token`\n",
        "7. Role: **Read**\n",
        "8. Generate & copy token\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "HF_TOKEN = \"hf_xxxxxxxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ Google Gemini API (FREE Tier)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**Google**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âœ… Free tier\n",
        "âŒ No credit card needed\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Education demos\n",
        "* Fast responses\n",
        "* Multimodal AI\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://aistudio.google.com](https://aistudio.google.com)\n",
        "2. Login with Google account\n",
        "3. Click **Get API Key**\n",
        "4. Create API key\n",
        "5. Copy key\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "GEMINI_API_KEY = \"AIzaSyxxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ OpenRouter (FREE Quota)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**OpenRouter**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âœ… Free credits available\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Calling multiple models with one API\n",
        "* Model comparison demos\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://openrouter.ai](https://openrouter.ai)\n",
        "2. Sign up\n",
        "3. Dashboard â†’ **API Keys**\n",
        "4. Create key\n",
        "5. Copy key\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "OPENROUTER_API_KEY = \"sk-or-xxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# âš ï¸ TRIAL / LIMITED FREE\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ ChatGPT / OpenAI API\n",
        "\n",
        "### Provider\n",
        "\n",
        "**OpenAI**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âš ï¸ Free credits on signup\n",
        "ğŸ’³ Card required after credits\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Reasoning\n",
        "* Coding\n",
        "* General AI\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://platform.openai.com](https://platform.openai.com)\n",
        "2. Login / Signup\n",
        "3. Profile â†’ **API Keys**\n",
        "4. Create new secret key\n",
        "5. Copy key (shown once)\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "OPENAI_API_KEY = \"sk-xxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ Claude API (Anthropic)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**Anthropic**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âš ï¸ Trial credits sometimes available\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Long documents\n",
        "* Legal & policy analysis\n",
        "* Government / compliance\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://console.anthropic.com](https://console.anthropic.com)\n",
        "2. Login / Signup\n",
        "3. **API Keys**\n",
        "4. Create key\n",
        "5. Copy key\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "ANTHROPIC_API_KEY = \"sk-ant-xxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ Grok API (xAI)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**xAI**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âŒ No permanent free tier\n",
        "âš ï¸ Trial / promotional access only\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Real-time trends\n",
        "* Social / X data\n",
        "\n",
        "### API Key Setup Steps\n",
        "\n",
        "1. Go to ğŸ‘‰ [https://console.x.ai](https://console.x.ai)\n",
        "2. Login with X (Twitter) account\n",
        "3. Developer Dashboard\n",
        "4. Create API key\n",
        "5. Copy key\n",
        "\n",
        "### Use in Code\n",
        "\n",
        "```python\n",
        "GROK_API_KEY = \"xai-xxxxxxxx\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ  PRIVATE AI (NO API KEY REQUIRED)\n",
        "\n",
        "---\n",
        "\n",
        "## 7ï¸âƒ£ Ollama (Local / Private)\n",
        "\n",
        "### Provider\n",
        "\n",
        "**Ollama**\n",
        "\n",
        "### Cost\n",
        "\n",
        "âœ… 100% Free\n",
        "âœ… Offline\n",
        "âœ… Private\n",
        "\n",
        "### Used For\n",
        "\n",
        "* Government\n",
        "* HR / Healthcare\n",
        "* Sensitive business data\n",
        "\n",
        "### Setup Steps\n",
        "\n",
        "1. Download ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)\n",
        "2. Install Ollama\n",
        "3. Pull models:\n",
        "\n",
        "   ```bash\n",
        "   ollama pull mistral\n",
        "   ollama pull llama2\n",
        "   ollama pull qwen\n",
        "   ```\n",
        "4. Ollama runs at:\n",
        "\n",
        "   ```\n",
        "   http://localhost:11434\n",
        "   ```\n",
        "\n",
        "âŒ No API key needed\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“Š QUICK COMPARISON TABLE\n",
        "\n",
        "| Provider     | Free       | Card Needed | Best For          |\n",
        "| ------------ | ---------- | ----------- | ----------------- |\n",
        "| Hugging Face | âœ…          | âŒ           | Open-source demos |\n",
        "| Gemini       | âœ…          | âŒ           | Education         |\n",
        "| OpenRouter   | âœ… (quota)  | âŒ           | Multi-model       |\n",
        "| ChatGPT      | âš ï¸ Credits | âœ…           | Reasoning         |\n",
        "| Claude       | âš ï¸ Trial   | â“           | Long docs         |\n",
        "| Grok         | âŒ          | â“           | Trends            |\n",
        "| Ollama       | âœ…          | âŒ           | Private AI        |\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ¤ INTERVIEW-READY SUMMARY (MEMORIZE)\n",
        "\n",
        "> â€œFor demos, I use Hugging Face, Gemini, and OpenRouter because they offer free API access. For sensitive data, I use Ollama locally with no API key. Claude and Grok are premium APIs mainly used for enterprise or trial comparisons.â€\n",
        "\n",
        "---\n",
        "\n",
        "# âœ… RECOMMENDED ZERO-COST DEMO STACK\n",
        "\n",
        "```\n",
        "Hugging Face  â†’ Open-source LLMs\n",
        "Gemini        â†’ Big-tech AI\n",
        "OpenRouter    â†’ Multi-model comparison\n",
        "Ollama        â†’ Private / offline AI\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJx06w5tBTl5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v4nx9QUBU0g"
      },
      "source": [
        "Below is a **SINGLE, ALL-IN-ONE PYTHON DEMO NOTE** that shows **API setup + runnable demo code** for **ALL major LLM providers** you asked about.\n",
        "You can paste this into **one Colab / Jupyter notebook** and run provider-by-provider.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§ª One-Notebook Python Demo â€” All LLM APIs\n",
        "\n",
        "![Image](https://datasciencedojo.com/wp-content/uploads/llm-application-architecture-scaled.jpg)\n",
        "\n",
        "![Image](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abbec59b2312c1630329c_overall_workflow.max-1200x1200.png)\n",
        "\n",
        "![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/0%2AySTq9YW4MyxNez0t)\n",
        "\n",
        "**Providers covered**\n",
        "\n",
        "* ğŸŸ¢ **Hugging Face** (FREE tier)\n",
        "* ğŸŸ¢ **Google** Gemini (FREE tier)\n",
        "* ğŸŸ¢ **OpenRouter** (FREE quota)\n",
        "* âš ï¸ **OpenAI** (free credits)\n",
        "* âš ï¸ **Anthropic** Claude (trial)\n",
        "* âš ï¸ **xAI** Grok (trial)\n",
        "* ğŸ  **Ollama** (PRIVATE, no key)\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 1 â€” Install libraries\n",
        "\n",
        "```python\n",
        "!pip install -q requests google-generativeai openai anthropic\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 2 â€” Put all API keys in one place\n",
        "\n",
        "```python\n",
        "HF_TOKEN = \"YOUR_HF_TOKEN\"                  # FREE\n",
        "GEMINI_API_KEY = \"YOUR_GEMINI_KEY\"          # FREE\n",
        "OPENROUTER_API_KEY = \"YOUR_OPENROUTER_KEY\"  # FREE quota\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR_OPENAI_KEY\"          # optional\n",
        "ANTHROPIC_API_KEY = \"YOUR_ANTHROPIC_KEY\"    # optional\n",
        "GROK_API_KEY = \"YOUR_GROK_API_KEY\"           # optional\n",
        "\n",
        "# Ollama runs locally â†’ no key\n",
        "OLLAMA_URL = \"http://localhost:11434\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 3 â€” Hugging Face (FREE, Open-Source)\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "def hf_llm(prompt, model=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
        "    r = requests.post(\n",
        "        f\"https://api-inference.huggingface.co/models/{model}\",\n",
        "        headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n",
        "        json={\"inputs\": prompt}\n",
        "    )\n",
        "    return r.json()[0][\"generated_text\"]\n",
        "\n",
        "print(hf_llm(\"Explain AI in simple words\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 4 â€” Google Gemini (FREE tier)\n",
        "\n",
        "```python\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "def gemini_llm(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    return model.generate_content(prompt).text\n",
        "\n",
        "print(gemini_llm(\"Create a short ML lesson for beginners\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 5 â€” OpenRouter (FREE quota, multi-model)\n",
        "\n",
        "```python\n",
        "def openrouter_llm(prompt, model=\"mistralai/mistral-7b-instruct\"):\n",
        "    r = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(openrouter_llm(\"Compare cloud AI vs private AI\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 6 â€” ChatGPT / OpenAI (free credits)\n",
        "\n",
        "```python\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "def chatgpt_llm(prompt):\n",
        "    r = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return r.choices[0].message.content\n",
        "\n",
        "print(chatgpt_llm(\"Summarize AI in 3 bullets\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 7 â€” Claude / Anthropic (trial)\n",
        "\n",
        "```python\n",
        "import anthropic\n",
        "client_claude = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "def claude_llm(prompt):\n",
        "    msg = client_claude.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=300,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return msg.content[0].text\n",
        "\n",
        "print(claude_llm(\"Summarize a policy in simple language\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 8 â€” Grok / xAI (trial)\n",
        "\n",
        "```python\n",
        "def grok_llm(prompt):\n",
        "    r = requests.post(\n",
        "        \"https://api.x.ai/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {GROK_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"grok-beta\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(grok_llm(\"What are today's AI trends?\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 9 â€” Ollama (PRIVATE, local)\n",
        "\n",
        "```python\n",
        "def ollama_llm(prompt, model=\"mistral\"):\n",
        "    r = requests.post(\n",
        "        f\"{OLLAMA_URL}/api/generate\",\n",
        "        json={\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
        "    )\n",
        "    return r.json()[\"response\"]\n",
        "\n",
        "# requires `ollama serve` running locally\n",
        "print(ollama_llm(\"Explain data privacy in simple terms\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## CELL 10 â€” Universal Router (teach this â­)\n",
        "\n",
        "```python\n",
        "def run_llm(provider, prompt):\n",
        "    if provider == \"HuggingFace\":\n",
        "        return hf_llm(prompt)\n",
        "    if provider == \"Gemini\":\n",
        "        return gemini_llm(prompt)\n",
        "    if provider == \"OpenRouter\":\n",
        "        return openrouter_llm(prompt)\n",
        "    if provider == \"ChatGPT\":\n",
        "        return chatgpt_llm(prompt)\n",
        "    if provider == \"Claude\":\n",
        "        return claude_llm(prompt)\n",
        "    if provider == \"Grok\":\n",
        "        return grok_llm(prompt)\n",
        "    if provider == \"Ollama\":\n",
        "        return ollama_llm(prompt)\n",
        "    return \"Unknown provider\"\n",
        "\n",
        "PROMPT = \"Analyze this resume for Data Analyst role: SQL, Python, Power BI, Excel\"\n",
        "\n",
        "for p in [\"HuggingFace\",\"Gemini\",\"OpenRouter\"]:\n",
        "    print(f\"\\n--- {p} ---\")\n",
        "    print(run_llm(p, PROMPT))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤ How to explain in 20 seconds\n",
        "\n",
        "> â€œThis notebook compares **free cloud APIs**, **premium APIs**, and **private local AI** using the same prompt. Businesses use this exact approach to evaluate vendors and choose cloud, private, or hybrid AI.â€\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Zero-Cost Demo Stack (recommended)\n",
        "\n",
        "* **Hugging Face** â†’ open-source models\n",
        "* **Gemini** â†’ big-tech AI\n",
        "* **OpenRouter** â†’ multi-model comparison\n",
        "* **Ollama** â†’ private/offline AI\n",
        "\n",
        "If you want, I can **add a Gradio UI**, **side-by-side tables**, or **convert this into a PDF handout**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YZtRJmu_ks-"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "import anthropic\n",
        "\n",
        "# ---------------------------\n",
        "# Provider Functions (KEYS FROM UI)\n",
        "# ---------------------------\n",
        "\n",
        "def hf_llm_ui(prompt, hf_key):\n",
        "    r = requests.post(\n",
        "        \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "        headers={\"Authorization\": f\"Bearer {hf_key}\"},\n",
        "        json={\"inputs\": prompt}\n",
        "    )\n",
        "    return r.json()[0][\"generated_text\"]\n",
        "\n",
        "def gemini_llm_ui(prompt, gemini_key):\n",
        "    genai.configure(api_key=gemini_key)\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    return model.generate_content(prompt).text\n",
        "\n",
        "def openrouter_llm_ui(prompt, openrouter_key):\n",
        "    r = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {openrouter_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"mistralai/mistral-7b-instruct\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "def chatgpt_llm_ui(prompt, openai_key):\n",
        "    client = OpenAI(api_key=openai_key)\n",
        "    r = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return r.choices[0].message.content\n",
        "\n",
        "def claude_llm_ui(prompt, anthropic_key):\n",
        "    client = anthropic.Anthropic(api_key=anthropic_key)\n",
        "    msg = client.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=300,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return msg.content[0].text\n",
        "\n",
        "def grok_llm_ui(prompt, grok_key):\n",
        "    r = requests.post(\n",
        "        \"https://api.x.ai/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {grok_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"grok-beta\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "def ollama_llm_ui(prompt):\n",
        "    r = requests.post(\n",
        "        \"http://localhost:11434/api/generate\",\n",
        "        json={\"model\": \"mistral\", \"prompt\": prompt, \"stream\": False}\n",
        "    )\n",
        "    return r.json()[\"response\"]\n",
        "\n",
        "# ---------------------------\n",
        "# Router\n",
        "# ---------------------------\n",
        "\n",
        "def run_llm_ui(provider, prompt, hf_key, gemini_key, openrouter_key, openai_key, anthropic_key, grok_key):\n",
        "    if prompt.strip() == \"\":\n",
        "        return \"âŒ Please enter a prompt.\"\n",
        "\n",
        "    try:\n",
        "        if provider == \"HuggingFace\":\n",
        "            return hf_llm_ui(prompt, hf_key)\n",
        "        elif provider == \"Gemini\":\n",
        "            return gemini_llm_ui(prompt, gemini_key)\n",
        "        elif provider == \"OpenRouter\":\n",
        "            return openrouter_llm_ui(prompt, openrouter_key)\n",
        "        elif provider == \"ChatGPT\":\n",
        "            return chatgpt_llm_ui(prompt, openai_key)\n",
        "        elif provider == \"Claude\":\n",
        "            return claude_llm_ui(prompt, anthropic_key)\n",
        "        elif provider == \"Grok\":\n",
        "            return grok_llm_ui(prompt, grok_key)\n",
        "        elif provider == \"Ollama\":\n",
        "            return ollama_llm_ui(prompt)\n",
        "        else:\n",
        "            return \"Unknown provider\"\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Error: {str(e)}\"\n",
        "\n",
        "# ---------------------------\n",
        "# Gradio UI\n",
        "# ---------------------------\n",
        "\n",
        "with gr.Blocks(title=\"All LLM API Demo (With API Key Input)\") as demo:\n",
        "    gr.Markdown(\"## ğŸ¤– All LLM APIs â€“ Live Demo Dashboard\")\n",
        "    gr.Markdown(\"Paste API keys securely â†’ Select provider â†’ Run same prompt\")\n",
        "\n",
        "    provider = gr.Dropdown(\n",
        "        [\"HuggingFace\", \"Gemini\", \"OpenRouter\", \"ChatGPT\", \"Claude\", \"Grok\", \"Ollama\"],\n",
        "        value=\"HuggingFace\",\n",
        "        label=\"Select LLM Provider\"\n",
        "    )\n",
        "\n",
        "    prompt = gr.Textbox(\n",
        "        lines=4,\n",
        "        placeholder=\"e.g. Analyze this resume for Data Analyst role: SQL, Python, Power BI\",\n",
        "        label=\"Prompt\"\n",
        "    )\n",
        "\n",
        "    with gr.Accordion(\"ğŸ”‘ API Keys (Paste Here)\", open=False):\n",
        "        hf_key = gr.Textbox(label=\"Hugging Face API Key\", type=\"password\")\n",
        "        gemini_key = gr.Textbox(label=\"Gemini API Key\", type=\"password\")\n",
        "        openrouter_key = gr.Textbox(label=\"OpenRouter API Key\", type=\"password\")\n",
        "        openai_key = gr.Textbox(label=\"OpenAI API Key\", type=\"password\")\n",
        "        anthropic_key = gr.Textbox(label=\"Anthropic (Claude) API Key\", type=\"password\")\n",
        "        grok_key = gr.Textbox(label=\"Grok API Key\", type=\"password\")\n",
        "\n",
        "    output = gr.Textbox(lines=14, label=\"Model Output\")\n",
        "\n",
        "    run_btn = gr.Button(\"Run LLM ğŸš€\")\n",
        "\n",
        "    run_btn.click(\n",
        "        run_llm_ui,\n",
        "        inputs=[provider, prompt, hf_key, gemini_key, openrouter_key, openai_key, anthropic_key, grok_key],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CAMM0LYBUXo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skuw_We4_m-J"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ğŸ“˜ Single Notebook â€“ ALL Free LLM APIs (Demo Ready)\n",
        "\n",
        "![Image](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/04/03/ml-17345-semantic-routing-004.png)\n",
        "\n",
        "![Image](https://cdn.prod.website-files.com/655bc1860a87f22da98dd83c/684abbec59b2312c1630329c_overall_workflow.max-1200x1200.png)\n",
        "\n",
        "![Image](https://www.aporia.com/wp-content/uploads/2024/02/image-1.png)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  APIs Covered (FREE / FREE-TIER)\n",
        "\n",
        "* ğŸŸ¢ **Hugging Face** (Open-source, free tier)\n",
        "* ğŸŸ¢ **Google** Gemini (Free tier)\n",
        "* ğŸŸ¢ **OpenRouter** (Free quota)\n",
        "* âš ï¸ **OpenAI** (Free credits)\n",
        "* âš ï¸ **Anthropic** (Trial credits)\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 1: Install Libraries (Colab)\n",
        "\n",
        "```python\n",
        "!pip install -q requests google-generativeai openai anthropic\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 2: Add Your API Keys (ONE PLACE)\n",
        "\n",
        "```python\n",
        "HF_TOKEN = \"YOUR_HF_TOKEN\"\n",
        "GEMINI_API_KEY = \"YOUR_GEMINI_KEY\"\n",
        "OPENROUTER_API_KEY = \"YOUR_OPENROUTER_KEY\"\n",
        "OPENAI_API_KEY = \"YOUR_OPENAI_KEY\"        # optional\n",
        "ANTHROPIC_API_KEY = \"YOUR_ANTHROPIC_KEY\"  # optional\n",
        "```\n",
        "\n",
        "ğŸ‘‰ For demos, **HF + Gemini + OpenRouter is enough (100% free)**\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 3: Hugging Face (FREE â€“ Open-Source Models)\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "def hf_llm(prompt, model=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
        "    response = requests.post(\n",
        "        f\"https://api-inference.huggingface.co/models/{model}\",\n",
        "        headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n",
        "        json={\"inputs\": prompt}\n",
        "    )\n",
        "    return response.json()[0][\"generated_text\"]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 4: Google Gemini (FREE Tier)\n",
        "\n",
        "```python\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "def gemini_llm(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    return model.generate_content(prompt).text\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 5: OpenRouter (FREE Multi-Model Gateway)\n",
        "\n",
        "```python\n",
        "def openrouter_llm(prompt, model=\"mistralai/mistral-7b-instruct\"):\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "    )\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 6: ChatGPT (Optional â€“ Free Credits)\n",
        "\n",
        "```python\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "def chatgpt_llm(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 7: Claude (Optional â€“ Trial)\n",
        "\n",
        "```python\n",
        "import anthropic\n",
        "client_claude = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "def claude_llm(prompt):\n",
        "    message = client_claude.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=300,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 8: Universal Router (â­ MOST IMPORTANT)\n",
        "\n",
        "```python\n",
        "def run_llm(provider, prompt):\n",
        "    if provider == \"HuggingFace\":\n",
        "        return hf_llm(prompt)\n",
        "    elif provider == \"Gemini\":\n",
        "        return gemini_llm(prompt)\n",
        "    elif provider == \"OpenRouter\":\n",
        "        return openrouter_llm(prompt)\n",
        "    elif provider == \"ChatGPT\":\n",
        "        return chatgpt_llm(prompt)\n",
        "    elif provider == \"Claude\":\n",
        "        return claude_llm(prompt)\n",
        "    else:\n",
        "        return \"Invalid provider\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 9: Real-World Demo Prompt\n",
        "\n",
        "```python\n",
        "PROMPT = \"\"\"\n",
        "You are an HR assistant.\n",
        "Analyze this resume and tell if the candidate is suitable for Data Analyst role.\n",
        "Skills: SQL, Python, Power BI, Excel\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ CELL 10: Run ALL Models (Side-by-Side)\n",
        "\n",
        "```python\n",
        "providers = [\"HuggingFace\", \"Gemini\", \"OpenRouter\"]\n",
        "\n",
        "for p in providers:\n",
        "    print(f\"\\n--- {p} OUTPUT ---\")\n",
        "    print(run_llm(p, PROMPT))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤ How to Explain This in Class / Interview\n",
        "\n",
        "> â€œThis single notebook compares **multiple AI providers** using their APIs.\n",
        "> Open-source models come from Hugging Face, Big-Tech models from Google Gemini, and multi-model access via OpenRouter.\n",
        "> This is exactly how companies evaluate AI vendors.â€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ† Best FREE Combo (Recommended)\n",
        "\n",
        "| Purpose          | Provider       |\n",
        "| ---------------- | -------------- |\n",
        "| Open-source demo | Hugging Face   |\n",
        "| Big-Tech AI      | Gemini         |\n",
        "| Model comparison | OpenRouter     |\n",
        "| Private AI       | Ollama (local) |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“¦ Download Notebook\n",
        "\n",
        "In Colab:\n",
        "\n",
        "```\n",
        "File â†’ Download â†’ .ipynb\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ Want Next?\n",
        "\n",
        "I can now:\n",
        "\n",
        "* ğŸ”„ Add **Gradio UI** to switch providers\n",
        "* ğŸ“Š Add **side-by-side comparison table**\n",
        "* ğŸ“„ Add **RAG demo (PDF â†’ answer)**\n",
        "* ğŸ  Add **Ollama private AI in same notebook**\n",
        "* ğŸ“˜ Convert this into **PDF teaching notes**\n",
        "\n",
        "Just tell me **next step** ğŸ‘¨â€ğŸ«ğŸ”¥\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
