{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Next word predictions"
      ],
      "metadata": {
        "id": "dWVLypwCayiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import time\n"
      ],
      "metadata": {
        "id": "1CGIeeanZaux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- Raw FAQ Text ----------\n",
        "faqs = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (CSWS 2025)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "...\n",
        "(Trimmed for brevity; use full FAQ from your original post)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "sNuD6WSuZdy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 1: Tokenization ----------\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([faqs])\n",
        "total_words = len(tokenizer.word_index) + 1  # add 1 for padding token\n"
      ],
      "metadata": {
        "id": "spGVkDHEZgE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 2: Create Input Sequences ----------\n",
        "input_sequences = []\n",
        "\n",
        "for sentence in faqs.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        input_sequences.append(token_list[:i+1])\n"
      ],
      "metadata": {
        "id": "3udd0sHUZh-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 3: Padding ----------\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n"
      ],
      "metadata": {
        "id": "m8RkTHtrZkC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split into input (X) and label (y)\n",
        "X = padded_sequences[:, :-1]\n",
        "y = padded_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "3GXm2QCyHdyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 4: Model ----------\n",
        "modelrnn = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1),\n",
        "    tf.keras.layers.SimpleRNN(150, return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(150),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "zSprmT2Rt2sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelrnn.build(input_shape=(None, max_sequence_len - 1)) # Explicitly build the modelrnn\n",
        "modelrnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "modelrnn.summary()"
      ],
      "metadata": {
        "id": "2iPGH0_Gt_wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 5: Train the Model ----------\n",
        "modelrnn.fit(X, y, epochs=10, verbose=1)"
      ],
      "metadata": {
        "id": "1gkVlG2zuMKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 6: Generate Text ----------\n",
        "seed_text = \"can i find detail syllabus\"\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = modelrnn.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word\n",
        "            break\n",
        "\n",
        "    print(seed_text)\n",
        "    time.sleep(1)\n",
        "\n",
        "# ---------- Optional: Check tokenizer mapping ----------\n",
        "# print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "id": "tPSb0sY2uTWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "ZDYdVIrSuCOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 4: Model ----------\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1),\n",
        "    LSTM(150, return_sequences=True),\n",
        "    LSTM(150),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "P6zti6XyZJSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, max_sequence_len - 1)) # Explicitly build the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BLVVQ61mHfjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 5: Train the Model ----------\n",
        "model.fit(X, y, epochs=10, verbose=1)"
      ],
      "metadata": {
        "id": "h9a9ySrSIHZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 6: Generate Text ----------\n",
        "seed_text = \"what is the fee\"\n",
        "next_words = 10\n"
      ],
      "metadata": {
        "id": "7Qd7BtMvIJ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 6: Generate Text ----------\n",
        "seed_text = \"can i find detail syllabus\"\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word\n",
        "            break\n",
        "\n",
        "    print(seed_text)\n",
        "    time.sleep(1)\n",
        "\n",
        "# ---------- Optional: Check tokenizer mapping ----------\n",
        "# print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "id": "v78YqFz0G7pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU\n",
        "\n",
        "Gated recurrent neural networks Gated Recurrent Unit (GRU) is a commonly used type of gated recurrent neural network, which is a simplified version of LSTM (Long Short-Term Memory) . Compared to LSTM, GRU simplifies one gating unit, which reduces the number of network parameters and reduces the risk of overfitting.\n"
      ],
      "metadata": {
        "id": "IZ5gkHleucal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 4: Model (GRU) ----------\n",
        "model_gru = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1),\n",
        "    tf.keras.layers.GRU(150, return_sequences=True),\n",
        "    tf.keras.layers.GRU(150),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "cf3IIIRAG8Nc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.build(input_shape=(None, max_sequence_len - 1)) # Explicitly build the model_gru\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "TJ5OKgm7utj4",
        "outputId": "d6d57fe0-8aff-49bc-cf5c-d24622e60897"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m12,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m113,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m135,900\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m)            │        \u001b[38;5;34m18,573\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">113,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,900</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,573</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m280,173\u001b[0m (1.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,173</span> (1.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m280,173\u001b[0m (1.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,173</span> (1.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 5: Train the Model ----------\n",
        "model_gru.fit(X, y, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_fOJwG0u1qr",
        "outputId": "80c9e90a-00fb-4b47-8c6e-f36d0af31109"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0389 - loss: 4.8084  \n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0917 - loss: 4.7342\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0893 - loss: 4.5355\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0789 - loss: 4.3707\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0538 - loss: 4.4088\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1085 - loss: 4.2708\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0919 - loss: 4.2905\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0878 - loss: 4.1329\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0859 - loss: 3.9877\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0871 - loss: 3.9182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b1a54164c20>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Step 6: Generate Text ----------\n",
        "seed_text = \"can i find detail syllabus\"\n",
        "next_words = 10\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model_gru.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            seed_text += \" \" + word\n",
        "            break\n",
        "\n",
        "    print(seed_text)\n",
        "    time.sleep(1)\n",
        "\n",
        "# ---------- Optional: Check tokenizer mapping ----------\n",
        "# print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tegWL6UOu4RC",
        "outputId": "36938de4-a699-42b6-aaec-3caf5e7acb9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can i find detail syllabus the\n",
            "can i find detail syllabus the the\n",
            "can i find detail syllabus the the the\n",
            "can i find detail syllabus the the the of\n",
            "can i find detail syllabus the the the of of\n",
            "can i find detail syllabus the the the of of of\n",
            "can i find detail syllabus the the the of of of of\n",
            "can i find detail syllabus the the the of of of of of\n",
            "can i find detail syllabus the the the of of of of of of\n",
            "can i find detail syllabus the the the of of of of of of of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvA9trZCvBwO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}