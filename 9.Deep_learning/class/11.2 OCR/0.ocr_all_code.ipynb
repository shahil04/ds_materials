{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8fd313d3",
      "metadata": {
        "id": "8fd313d3"
      },
      "source": [
        "\n",
        "# **OCR Bootcamp Notes**\n",
        "\n",
        "*(Optical Character Recognition)*\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **1. Introduction to OCR**\n",
        "\n",
        "### **What is OCR?**\n",
        "\n",
        "* OCR = **Optical Character Recognition**\n",
        "* Converts **printed or handwritten text in images** into **editable text**.\n",
        "* Works by detecting **characters, words, and text layout** from an image or document.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why OCR?**\n",
        "\n",
        "* Automates data entry.\n",
        "* Digitizes physical documents.\n",
        "* Enables **searchable PDFs**.\n",
        "* Used in banking, healthcare, transportation, retail.\n",
        "\n",
        "---\n",
        "\n",
        "### **Real-world Applications**\n",
        "\n",
        "* Scanning books into eBooks.\n",
        "* License Plate Recognition.\n",
        "* Invoice & Receipt Automation.\n",
        "* Passport/ID verification.\n",
        "* Subtitle extraction from videos.\n",
        "\n",
        "---\n",
        "\n",
        "### **OCR vs ICR**\n",
        "\n",
        "* **OCR**: Recognizes printed text.\n",
        "* **ICR**: Recognizes **handwritten text** using AI.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **2. How OCR Works**\n",
        "\n",
        "1. **Image Acquisition** ‚Üí Capture image/document.\n",
        "2. **Preprocessing** ‚Üí Clean image (noise removal, binarization).\n",
        "3. **Text Detection** ‚Üí Locate text regions.\n",
        "4. **Character Recognition** ‚Üí Extract text.\n",
        "5. **Post-processing** ‚Üí Correct errors.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **3. Image Preprocessing for OCR**\n",
        "\n",
        "**Why preprocessing?**\n",
        "Bad quality images ‚Üí Low OCR accuracy.\n",
        "Preprocessing helps clean the image for better results.\n",
        "\n",
        "### **Techniques**\n",
        "\n",
        "* **Grayscale conversion** ‚Üí Reduce complexity.\n",
        "* **Thresholding** ‚Üí Convert to black & white.\n",
        "\n",
        "  * Binary threshold.\n",
        "  * Adaptive threshold.\n",
        "* **Noise removal** ‚Üí Gaussian blur, Median filter.\n",
        "* **Morphological operations** ‚Üí Remove small artifacts.\n",
        "* **Deskewing** ‚Üí Correct tilted text.\n",
        "\n",
        "**Code Example (OpenCV Preprocessing):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbc00d3",
      "metadata": {
        "id": "5dbc00d3",
        "outputId": "070d62dc-fe67-4265-b929-2fdb362fb7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: invalid escape sequence '\\p'\n",
            "<>:17: SyntaxWarning: invalid escape sequence '\\p'\n",
            "/tmp/ipython-input-2347752896.py:17: SyntaxWarning: invalid escape sequence '\\p'\n",
            "  cv2.imwrite('images\\processed.jpg', thresh)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Image not found. Check the file path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2347752896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check if image is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image not found. Check the file path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Image not found. Check the file path."
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Use raw string for path\n",
        "img = cv2.imread(r'5.ocr_text_recognition\\images\\lifestyle-02.jpg')\n",
        "\n",
        "# Check if image is loaded\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found. Check the file path.\")\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply threshold\n",
        "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Save processed image\n",
        "cv2.imwrite('images\\processed.jpg', thresh)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9033d9da",
      "metadata": {
        "id": "9033d9da"
      },
      "source": [
        "\n",
        "## ‚úÖ **4. OCR Engines & Libraries**\n",
        "\n",
        "* **Tesseract OCR** (most popular, by Google)\n",
        "* **EasyOCR** (Deep learning-based, supports multiple languages)\n",
        "* **PaddleOCR** (High accuracy)\n",
        "* **Google Vision API** (Cloud-based)\n",
        "\n",
        "---\n",
        "\n",
        "### **Installing Tesseract**\n",
        "\n",
        "**Windows/Linux Setup:**\n",
        "\n",
        "* Install Tesseract from official site.\n",
        "* Add path to environment variables.\n",
        "* Install Python wrapper:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Basic OCR in Python:**\n",
        "\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open('text_image.png')\n",
        "text = pytesseract.image_to_string(img)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d2e0c1",
      "metadata": {
        "id": "19d2e0c1",
        "outputId": "2eaa7c4e-35a1-40fb-9333-d91068583608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from opencv-python) (1.26.4)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract opencv-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2df9528",
      "metadata": {
        "id": "b2df9528"
      },
      "source": [
        "\n",
        "## ‚úÖ **5. Advanced OCR Features**\n",
        "\n",
        "* **Multilingual OCR** ‚Üí Support for 100+ languages.\n",
        "* **Custom language models** ‚Üí Train for new fonts.\n",
        "* **Extracting structured data** ‚Üí Tables, forms.\n",
        "* **Confidence scores** ‚Üí Check accuracy.\n",
        "* **Handwriting recognition** ‚Üí Using deep learning (ICR).\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **6. Improving OCR Accuracy**\n",
        "\n",
        "* Use **high-resolution images**.\n",
        "* Apply **deskewing** & **denoising**.\n",
        "* Convert to **grayscale or binary**.\n",
        "* Train custom models for complex fonts.\n",
        "* Use **Deep Learning (CRNN)** for better accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **7. OCR in Applications**\n",
        "\n",
        "* **Extract text from PDFs** using `pdf2image` + OCR.\n",
        "* **Real-time OCR** using webcam feed.\n",
        "* **Batch OCR** for multiple documents.\n",
        "* **Integrating OCR with Flask/FastAPI for APIs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e1f24d",
      "metadata": {
        "id": "60e1f24d",
        "outputId": "2bbfc13c-3734-4512-f6c0-386c56c387bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdf2image"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pdf2image) (11.3.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqLg9dU_JPVz"
      },
      "outputs": [],
      "source": [
        "### **Example: Extract Text from PDF**\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "pages = convert_from_path('document.pdf', 300)\n",
        "for page in pages:\n",
        "    text = pytesseract.image_to_string(page)\n",
        "    print(text)"
      ],
      "id": "FqLg9dU_JPVz"
    },
    {
      "cell_type": "markdown",
      "id": "38ee246b",
      "metadata": {
        "id": "38ee246b"
      },
      "source": [
        "## Exract data from image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecd9c09",
      "metadata": {
        "id": "8ecd9c09"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from ocr_utils import *\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "st.set_page_config(page_title=\"OCR Text Recognition\")\n",
        "st.title(\"üìù OCR Text Recognition with Pytesseract\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload an image with text\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded_file:\n",
        "    image = load_image(uploaded_file.read())\n",
        "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
        "\n",
        "    thresh = preprocess_image(image)\n",
        "    st.image(thresh, caption=\"Preprocessed Image\", use_column_width=True)\n",
        "\n",
        "    st.subheader(\"üìÑ Extracted Text\")\n",
        "    text = extract_text(thresh)\n",
        "    st.code(text)\n",
        "\n",
        "    st.subheader(\"üîç Word Detection with Bounding Boxes\")\n",
        "    data = extract_data(thresh)\n",
        "    n_boxes = len(data['level'])\n",
        "    for i in range(n_boxes):\n",
        "        (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    st.image(image, caption=\"Detected Words\", use_column_width=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a7f4ef",
      "metadata": {
        "id": "68a7f4ef"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **8. Projects & Case Studies**\n",
        "\n",
        "### **Beginner**\n",
        "\n",
        "‚úî Extract text from an image.\n",
        "‚úî Convert scanned PDF to editable text.\n",
        "\n",
        "### **Intermediate**\n",
        "\n",
        "‚úî License plate recognition.\n",
        "‚úî Business card reader using OCR + OpenCV.\n",
        "\n",
        "### **Advanced**\n",
        "\n",
        "‚úî Automated invoice processing with table extraction.\n",
        "‚úî Real-time subtitle extraction from video feed.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **Practice Session**\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Define OCR and its real-world uses.\n",
        "2. Explain why image preprocessing is important for OCR.\n",
        "3. Write Python code to extract text from an image using Tesseract.\n",
        "4. How do you improve OCR accuracy?\n",
        "5. What is the difference between OCR and ICR?\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **Assignments**\n",
        "\n",
        "1. Extract text from a scanned handwritten note.\n",
        "2. Create an OCR pipeline for multilingual documents.\n",
        "3. Implement OCR for real-time video stream using OpenCV.\n",
        "4. Process 100 scanned documents and export extracted text into Excel.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ **Tools & Libraries**\n",
        "\n",
        "* **OpenCV** ‚Üí Image preprocessing.\n",
        "* **Pytesseract** ‚Üí OCR engine.\n",
        "* **pdf2image** ‚Üí Convert PDFs to images.\n",
        "* **EasyOCR** ‚Üí Multilingual deep learning-based OCR.\n",
        "* **Flask/FastAPI** ‚Üí Build OCR APIs.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518497ca",
      "metadata": {
        "id": "518497ca"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf pillow pytesseract scikit-learn\n"
      ],
      "metadata": {
        "id": "JJ57pOo8AfSQ",
        "outputId": "a6abda3b-bfa0-481b-dfe1-82ec61806094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JJ57pOo8AfSQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, pymupdf\n",
            "Successfully installed pymupdf-1.26.6 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz              # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import sys\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Clean text\n",
        "# -------------------------------------------------\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Extract text from PDF\n",
        "# -------------------------------------------------\n",
        "def extract_from_pdf(path):\n",
        "    doc = fitz.open(path)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in doc:\n",
        "        text += page.get_text() + \"\\n\"\n",
        "\n",
        "    return clean_text(text)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Extract text from image (OCR)\n",
        "# -------------------------------------------------\n",
        "def extract_from_image(path):\n",
        "    img = Image.open(path)\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    return clean_text(text)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Extract text from TXT file\n",
        "# -------------------------------------------------\n",
        "def extract_from_text(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return clean_text(f.read())\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Detect file type + route to correct extractor\n",
        "# -------------------------------------------------\n",
        "def extract_resume(path):\n",
        "    if path.endswith(\".pdf\"):\n",
        "        return extract_from_pdf(path)\n",
        "\n",
        "    elif path.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        return extract_from_image(path)\n",
        "\n",
        "    elif path.endswith(\".txt\"):\n",
        "        return extract_from_text(path)\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Unsupported resume file type.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def extract_job_description(path):\n",
        "    if path.endswith(\".pdf\"):\n",
        "        return extract_from_pdf(path)\n",
        "    else:\n",
        "        return extract_from_text(path)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Calculate ATS Score\n",
        "# -------------------------------------------------\n",
        "def calculate_ats_score(resume_text, job_text):\n",
        "    docs = [resume_text, job_text]\n",
        "    cv = CountVectorizer(stop_words=\"english\")\n",
        "\n",
        "    vectors = cv.fit_transform(docs)\n",
        "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
        "\n",
        "    score = round(similarity * 100, 2)\n",
        "\n",
        "    # Missing keywords\n",
        "    resume_words = set(resume_text.split())\n",
        "    job_words = set(job_text.split())\n",
        "    missing = list(job_words - resume_words)\n",
        "\n",
        "    return score, missing\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Main program\n",
        "# -------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    resume_path = input(\"Enter path to resume (pdf/image/txt): \")\n",
        "    job_path = input(\"Enter path to job description (pdf/txt): \")\n",
        "\n",
        "    print(\"\\nExtracting resume text...\")\n",
        "    resume_text = extract_resume(resume_path)\n",
        "\n",
        "    print(\"Extracting job description text...\")\n",
        "    job_text = extract_job_description(job_path)\n",
        "\n",
        "    print(\"\\nCalculating ATS score...\")\n",
        "    score, missing_keywords = calculate_ats_score(resume_text, job_text)\n",
        "\n",
        "    print(\"\\n-----------------------------------------\")\n",
        "    print(f\"‚úÖ ATS Score: {score}%\")\n",
        "    print(\"-----------------------------------------\")\n",
        "\n",
        "    print(\"\\n‚ùó Missing Keywords:\")\n",
        "    if missing_keywords:\n",
        "        print(\", \".join(missing_keywords))\n",
        "    else:\n",
        "        print(\"No missing keywords! Great match üéâ\")\n",
        "\n",
        "    print(\"\\nDone.\")\n"
      ],
      "metadata": {
        "id": "g4J2gBsUAO_7",
        "outputId": "9018b98c-c4b9-490f-a795-5bb709412f4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "g4J2gBsUAO_7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path to resume (pdf/image/txt): /content/document.pdf\n",
            "Enter path to job description (pdf/txt): /content/jd.txt\n",
            "\n",
            "Extracting resume text...\n",
            "Extracting job description text...\n",
            "\n",
            "Calculating ATS score...\n",
            "\n",
            "-----------------------------------------\n",
            "‚úÖ ATS Score: 44.83%\n",
            "-----------------------------------------\n",
            "\n",
            "‚ùó Missing Keywords:\n",
            "your, type, large, pulled, policy, unique, de, scrutinize, implementation, missing, focused, responsibilities, great, exploratory, person, 1, india, foundation, modern, run, government, 3, desire, datasets, entered, 15th, pay, service, profile, tenure, equivalent, graduates, ministry, research, scale, diploma, processes, handling, builds, survey, week, daily, incoming, correct, at, coursework, 36, working, tracking, chance, summaries, reports, decisions, shortlisting, final, required, economics, exposure, documenting, trails, candidates, month, issues, receipt, good, initial, begin, instructions, checks, location, this, essential, proficiency, one, social, years, surveys, govt, paid, cleaning, entries, sample, indicate, be, office, follow, scripts, deadlines, should, boosting, delhi, generate, corrections, national, role, is, able, full, that, apply, resolution, career, test, public, fresh, length, ensure, cv, credibility, background, consistency, increase, validation, 0, updated, selection, maintaining, qualifications, understanding, monthly, ability, months, procedures, job, annual, nbsp, involved, flag, improvements, multiple, logical, examiner, deadline, 29, based, every, sick, attention, scheme, salary, sept, status, tasks, provident, teams, through, organisation, r, schedules, entry, fund, key, interest, 000, submit, year, increment, coordinate, called, per, verification, field, interact, why, benefits, meaningful, dashboards, allowances, ups, detail, prepare, language, hands, will, review, audit, must, academic, shortlisted, have, description, methodologies, any, monitor, 30, 5, collected, who, analytical, reputed, interview, central, written, programme, process, contractual, resume, basic, outliers, communication, other, 00, validate, matches, adds, strong, days, concepts, agency, manage, offices, clean, assist, frames, quality, document, suggest, clearly, under, degree, how, leave, inconsistent, mindset, question, guidelines, etc, opportunity, contract, initiatives, temporary\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wlYMuUNAXka"
      },
      "id": "-wlYMuUNAXka",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rasa-eA7WAmP0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
<<<<<<< HEAD
  {
   "cell_type": "markdown",
   "id": "9033d9da",
   "metadata": {
    "id": "9033d9da"
   },
   "source": [
    "\n",
    "## ‚úÖ **4. OCR Engines & Libraries**\n",
    "\n",
    "* **Tesseract OCR** (most popular, by Google)\n",
    "* **EasyOCR** (Deep learning-based, supports multiple languages)\n",
    "* **PaddleOCR** (High accuracy)\n",
    "* **Google Vision API** (Cloud-based)\n",
    "\n",
    "---\n",
    "\n",
    "### **Installing Tesseract**\n",
    "\n",
    "**Windows/Linux Setup:**\n",
    "\n",
    "* Install Tesseract from official site.\n",
    "* Add path to environment variables.\n",
    "* Install Python wrapper:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Basic OCR in Python:**\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('text_image.png')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2e0c1",
   "metadata": {
    "id": "19d2e0c1",
    "outputId": "2eaa7c4e-35a1-40fb-9333-d91068583608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9528",
   "metadata": {
    "id": "b2df9528"
   },
   "source": [
    "\n",
    "## ‚úÖ **5. Advanced OCR Features**\n",
    "\n",
    "* **Multilingual OCR** ‚Üí Support for 100+ languages.\n",
    "* **Custom language models** ‚Üí Train for new fonts.\n",
    "* **Extracting structured data** ‚Üí Tables, forms.\n",
    "* **Confidence scores** ‚Üí Check accuracy.\n",
    "* **Handwriting recognition** ‚Üí Using deep learning (ICR).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **6. Improving OCR Accuracy**\n",
    "\n",
    "* Use **high-resolution images**.\n",
    "* Apply **deskewing** & **denoising**.\n",
    "* Convert to **grayscale or binary**.\n",
    "* Train custom models for complex fonts.\n",
    "* Use **Deep Learning (CRNN)** for better accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **7. OCR in Applications**\n",
    "\n",
    "* **Extract text from PDFs** using `pdf2image` + OCR.\n",
    "* **Real-time OCR** using webcam feed.\n",
    "* **Batch OCR** for multiple documents.\n",
    "* **Integrating OCR with Flask/FastAPI for APIs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1f24d",
   "metadata": {
    "id": "60e1f24d",
    "outputId": "2bbfc13c-3734-4512-f6c0-386c56c387bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\.virtualenvs\\rasa-ea7wamp0\\lib\\site-packages (from pdf2image) (11.3.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FqLg9dU_JPVz",
   "metadata": {
    "id": "FqLg9dU_JPVz"
   },
   "outputs": [],
   "source": [
    "### **Example: Extract Text from PDF**\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "pages = convert_from_path('document.pdf', 300)\n",
    "for page in pages:\n",
    "    text = pytesseract.image_to_string(page)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec022690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "def extract_clean_text(pdf_path, txt_out_path=None):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_parts = []\n",
    "\n",
    "    for page in doc:\n",
    "        raw_text = page.get_text(\"text\")\n",
    "        \n",
    "        # Normalize whitespace\n",
    "        clean = re.sub(r\"[ \\t]+\", \" \", raw_text)                # collapse spaces\n",
    "        clean = re.sub(r\"\\n{3,}\", \"\\n\\n\", clean)                 # collapse blank lines\n",
    "        clean = clean.strip()\n",
    "\n",
    "        # Remove weird unicode/control characters\n",
    "        clean = re.sub(r\"[\\x00-\\x1F\\x7F-\\x9F]\", \"\", clean)\n",
    "\n",
    "        text_parts.append(clean)\n",
    "\n",
    "    full_text = \"\\n\\n\".join(text_parts)\n",
    "\n",
    "    # Optional: save to a .txt file\n",
    "    if txt_out_path:\n",
    "        with open(txt_out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "    return full_text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = r\"C:\\Users\\hp\\Documents\\ds_materials\\9.Deep_learning\\class\\11.2 OCR\\2.ocr_text_recognition_project\\Document_text_recognization\\document.pdf\"\n",
    "text = extract_clean_text(pdf_path, \"resume_extracted.txt\")\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee246b",
   "metadata": {
    "id": "38ee246b"
   },
   "source": [
    "## Exract data from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd9c09",
   "metadata": {
    "id": "8ecd9c09"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from ocr_utils import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "st.set_page_config(page_title=\"OCR Text Recognition\")\n",
    "st.title(\"üìù OCR Text Recognition with Pytesseract\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image with text\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "if uploaded_file:\n",
    "    image = load_image(uploaded_file.read())\n",
    "    st.image(image, caption=\"Original Image\", use_column_width=True)\n",
    "\n",
    "    thresh = preprocess_image(image)\n",
    "    st.image(thresh, caption=\"Preprocessed Image\", use_column_width=True)\n",
    "\n",
    "    st.subheader(\"üìÑ Extracted Text\")\n",
    "    text = extract_text(thresh)\n",
    "    st.code(text)\n",
    "\n",
    "    st.subheader(\"üîç Word Detection with Bounding Boxes\")\n",
    "    data = extract_data(thresh)\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    st.image(image, caption=\"Detected Words\", use_column_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7f4ef",
   "metadata": {
    "id": "68a7f4ef"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **8. Projects & Case Studies**\n",
    "\n",
    "### **Beginner**\n",
    "\n",
    "‚úî Extract text from an image.\n",
    "‚úî Convert scanned PDF to editable text.\n",
    "\n",
    "### **Intermediate**\n",
    "\n",
    "‚úî License plate recognition.\n",
    "‚úî Business card reader using OCR + OpenCV.\n",
    "\n",
    "### **Advanced**\n",
    "\n",
    "‚úî Automated invoice processing with table extraction.\n",
    "‚úî Real-time subtitle extraction from video feed.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Practice Session**\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Define OCR and its real-world uses.\n",
    "2. Explain why image preprocessing is important for OCR.\n",
    "3. Write Python code to extract text from an image using Tesseract.\n",
    "4. How do you improve OCR accuracy?\n",
    "5. What is the difference between OCR and ICR?\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Assignments**\n",
    "\n",
    "1. Extract text from a scanned handwritten note.\n",
    "2. Create an OCR pipeline for multilingual documents.\n",
    "3. Implement OCR for real-time video stream using OpenCV.\n",
    "4. Process 100 scanned documents and export extracted text into Excel.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Tools & Libraries**\n",
    "\n",
    "* **OpenCV** ‚Üí Image preprocessing.\n",
    "* **Pytesseract** ‚Üí OCR engine.\n",
    "* **pdf2image** ‚Üí Convert PDFs to images.\n",
    "* **EasyOCR** ‚Üí Multilingual deep learning-based OCR.\n",
    "* **Flask/FastAPI** ‚Üí Build OCR APIs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518497ca",
   "metadata": {
    "id": "518497ca"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
  "nbformat": 4,
  "nbformat_minor": 5
}
>>>>>>> 0cfea5a7449830c582508a4b0bc70c5a5fb8638f
