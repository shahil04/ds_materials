{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsGgaGiAUMWy"
   },
   "outputs": [],
   "source": [
    "# Install the ultralytics package from PyPI\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EucUKiSYUEaR"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create a new YOLO model from scratch\n",
    "model = YOLO(\"yolo11n.yaml\")\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "results = model.train(data=\"coco8.yaml\", epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "success = model.export(format=\"onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfFLx41iUp0J"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"/content/bus.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ayniUouW6C-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QJ6xr_lW6gb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"path/to/video.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"workouts_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init AIGym\n",
    "gym = solutions.AIGym(\n",
    "    show=True,  # display the frame\n",
    "    kpts=[6, 8, 10],  # keypoints for monitoring specific exercise, by default it's for pushup\n",
    "    model=\"yolo11n-pose.pt\",  # path to the YOLO11 pose estimation model file\n",
    "    # line_width=2,  # adjust the line width for bounding boxes and text display\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "\n",
    "    results = gym(im0)\n",
    "\n",
    "    # print(results)  # access the output\n",
    "\n",
    "    video_writer.write(results.plot_im)  # write the processed frame.\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()  # destroy all opened windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqbloWtyXTh-"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(\"path/to/video.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"parking management.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize parking management object\n",
    "parkingmanager = solutions.ParkingManagement(\n",
    "    model=\"yolo11n.pt\",  # path to model file\n",
    "    json_file=\"bounding_boxes.json\",  # path to parking annotations file\n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = parkingmanager(im0)\n",
    "\n",
    "    # print(results)  # access the output\n",
    "\n",
    "    video_writer.write(results.plot_im)  # write the processed frame.\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()  # destroy all opened windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZVExOf5jdu_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5GbW9xYjmXp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUZbRlpijmTd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27712,
     "status": "ok",
     "timestamp": 1759654444284,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "U_WMzo1sjmts",
    "outputId": "50ba86f5-4b4b-4f86-d2ca-285022c3286a"
   },
   "outputs": [],
   "source": [
    "!uv pip install ultralytics\n",
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17628,
     "status": "error",
     "timestamp": 1759654804468,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "m51L25yzjnwR",
    "outputId": "5085143f-d3ae-43b0-d54a-513ac53e8621"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "# !yolo track source=\"/path/to/video.mp4\" save=True\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "# Dictionary to store tracking history with default empty lists\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Load the YOLO model with segmentation capabilities\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"sample.mp4\")\n",
    "\n",
    "# Retrieve video properties: width, height, and frames per second\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer to save the output video with the specified properties\n",
    "out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Create an annotator object to draw on the frame\n",
    "    annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "    # Perform object tracking on the current frame\n",
    "    results = model.track(im0, persist=True)\n",
    "\n",
    "    # Check if tracking IDs and masks are present in the results\n",
    "    if results[0].boxes.is_track and results[0].masks is not None:\n",
    "        # Extract masks and tracking IDs\n",
    "        masks = results[0].masks.xy\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Annotate each mask with its corresponding tracking ID and color\n",
    "        for mask, track_id in zip(masks, track_ids):\n",
    "            if mask.size > 0: # Check if the mask is not empty\n",
    "                annotator.seg_masks(masks=[mask], ids=[track_id], ret_native=True) # Annotate each mask individually\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(im0)\n",
    "    # Display the annotated frame\n",
    "    # cv2.imshow(\"instance-segmentation-object-tracking\", im0)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "\n",
    "# Release the video writer and capture objects, and close all OpenCV windows\n",
    "out.release()\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HRjwD5sVkRhb",
    "outputId": "4df37c53-cf2f-4b59-e96e-455cf4ca5099"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import colors\n",
    "from google.colab.patches import cv2_imshow # Import cv2_imshow\n",
    "\n",
    "# Dictionary to store tracking history (optional for trails)\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Load YOLOv8 segmentation model\n",
    "model = YOLO(\"yolo11n-seg.pt\")  # use yolov8n-seg.pt if faster inference needed\n",
    "\n",
    "# Open input video\n",
    "cap = cv2.VideoCapture(\"sample.mp4\")\n",
    "\n",
    "# Get video properties\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer (full resolution)\n",
    "out = cv2.VideoWriter(\n",
    "    \"instance-segmentation-object-tracking.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
    "    fps,\n",
    "    (w, h),\n",
    ")\n",
    "\n",
    "# Display scaling for small screen\n",
    "display_scale = 0.6  # scale down to 60% for 13-inch laptop\n",
    "\n",
    "# Start time for FPS calculation\n",
    "prev_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"âœ… Video processing completed.\")\n",
    "        break\n",
    "\n",
    "    # YOLO segmentation + tracking\n",
    "    results = model.track(im0, persist=True, verbose=False)\n",
    "\n",
    "    if results[0].boxes.is_track and results[0].masks is not None:\n",
    "        masks = results[0].masks.xy                     # segmentation polygons\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()     # bounding boxes\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()  # tracking IDs\n",
    "\n",
    "        # Annotate each detection\n",
    "        for mask, box, track_id in zip(masks, boxes, track_ids):\n",
    "            # Draw segmentation mask\n",
    "            pts = np.array(mask, dtype=np.int32)\n",
    "            cv2.fillPoly(im0, [pts], color=colors(int(track_id), True))\n",
    "\n",
    "            # Draw bounding box\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cv2.rectangle(im0, (x1, y1), (x2, y2), colors(int(track_id), True), 2)\n",
    "\n",
    "            # Draw label\n",
    "            cv2.putText(\n",
    "                im0,\n",
    "                f\"ID {track_id}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                colors(int(track_id), True),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "    # Calculate FPS\n",
    "    curr_time = time.time()\n",
    "    fps_text = f\"FPS: {1/(curr_time - prev_time):.2f}\" if prev_time != 0 else \"FPS: ...\"\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(im0, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Write full-resolution frame to output video\n",
    "    out.write(im0)\n",
    "\n",
    "    # Resize frame for display\n",
    "    display_frame = cv2.resize(im0, (int(w*display_scale), int(h*display_scale)))\n",
    "    cv2_imshow(display_frame) # Use cv2_imshow\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows() # Comment out or remove this line"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMdchUYOtywrXvpr4Y+kxsO",
   "provenance": [],
   "runtime_attributes": {
    "runtime_version": "2025.07"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
