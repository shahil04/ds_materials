{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSi8C6ta2BAEONz7pwCaVg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#image net\n","-1.AlexNet\n","2. ZFNet\n","3. VGG 16 ,VGG19\n","4. GoogleNet\n","5. ResNet, ResNet50, ResNet50V2\n","6. Xception, InceptionV3\n","7. MobileNet,\n"],"metadata":{"id":"jHk_w0batC1k"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gyaF6UZsL94"},"outputs":[],"source":["# https://keras.io/api/applications/"]},{"cell_type":"code","source":[],"metadata":{"id":"fBPSzkiExw8a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","‚úÖ **Definition**\n","‚úÖ **Architecture summary**\n","‚úÖ **Advantages**\n","‚úÖ **Disadvantages / Limitations**\n","‚úÖ **How to overcome them**\n","‚úÖ **Next evolution (next step)**\n","\n","---\n","\n","## üß† 1. **AlexNet (2012)**\n","\n","**Definition:**\n","AlexNet is the first deep convolutional neural network that significantly outperformed traditional computer vision methods, winning the ImageNet competition with a huge margin.\n","\n","**Advantages:**\n","\n","* Breakthrough in deep learning for vision.\n","* ReLU activation speeds up training.\n","* Data augmentation + dropout reduce overfitting.\n","* Demonstrated GPU acceleration benefits.\n","\n","**Disadvantages / Limitations:**\n","\n","* Large model (60M parameters).\n","* Overfitting risk if dataset is small.\n","* Architecture is shallow by modern standards.\n","* Slow on CPU.\n","\n","**How to Overcome:**\n","\n","* Use smaller filters and deeper networks (VGG).\n","* Reduce parameters (1√ó1 conv or bottlenecks).\n","* Use batch normalization.\n","\n","**Next Step:**\n","‚úÖ **ZFNet** (improved feature extraction) ‚Üí **VGGNet** (deeper architecture).\n","\n","---\n","\n","## üîé 2. **ZFNet (2013)**\n","\n","**Definition:**\n","ZFNet (Zeiler & Fergus Net) improved AlexNet by using smaller filters and better hyperparameters, and introduced visualization tools to understand CNNs.\n","\n","**Advantages:**\n","\n","* Better feature representation.\n","* Visualization reveals what layers learn.\n","* Reduced overfitting risk compared to AlexNet.\n","\n","**Disadvantages / Limitations:**\n","\n","* Still heavy and not very deep.\n","* Visualization is limited to qualitative understanding.\n","* Incremental improvement, not a paradigm shift.\n","\n","**How to Overcome:**\n","\n","* Stack more layers with uniform architecture (VGG).\n","* Add deeper hierarchical features.\n","\n","**Next Step:**\n","‚úÖ **VGGNet** ‚Äì much deeper networks with small filters.\n","\n","---\n","\n","## üß± 3. **VGG16 / VGG19 (2014)**\n","\n","**Definition:**\n","VGG is a deep CNN using only 3√ó3 convolution filters stacked together to increase depth and feature complexity.\n","\n","**Advantages:**\n","\n","* Very simple and elegant architecture.\n","* Good generalization, widely used for transfer learning.\n","* Deeper networks ‚Üí richer feature extraction.\n","\n","**Disadvantages / Limitations:**\n","\n","* Very large model (~138M parameters).\n","* Slow inference and high memory usage.\n","* No internal mechanism to improve efficiency.\n","\n","**How to Overcome:**\n","\n","* Use **1√ó1 convolutions** for dimensionality reduction (GoogLeNet).\n","* Add **residual connections** to go deeper (ResNet).\n","* Compress model or use depthwise separable convs.\n","\n","**Next Step:**\n","‚úÖ **GoogLeNet** (efficient) ‚Üí **ResNet** (deeper with skip connections).\n","\n","---\n","\n","## üåê 4. **GoogLeNet / Inception v1 (2014)**\n","\n","**Definition:**\n","GoogLeNet introduced the **Inception module**, processing input at multiple scales (1√ó1, 3√ó3, 5√ó5) simultaneously and combining outputs.\n","\n","**Advantages:**\n","\n","* Computationally efficient (fewer parameters than VGG).\n","* Multi-scale feature extraction.\n","* 22 layers deep without massive parameter growth.\n","\n","**Disadvantages / Limitations:**\n","\n","* Complex architecture (harder to design & tune).\n","* Limited depth due to vanishing gradients.\n","* Manual design of inception modules is tricky.\n","\n","**How to Overcome:**\n","\n","* Add **residual connections** (ResNet).\n","* Use **batch normalization** and better initialization.\n","* Automate architecture search.\n","\n","**Next Step:**\n","‚úÖ **Inception v3 / v4** (improved modules) ‚Üí **ResNet** (very deep).\n","\n","---\n","\n","## üîÑ 5. **ResNet (2015)**\n","\n","**Definition:**\n","ResNet uses **residual connections (skip connections)** that allow gradients to flow through layers easily, enabling training of very deep networks.\n","\n","**Advantages:**\n","\n","* Solves vanishing gradient problem.\n","* Enables 50, 101, 152+ layers.\n","* State-of-the-art accuracy.\n","* Works well as a backbone for many tasks.\n","\n","**Disadvantages / Limitations:**\n","\n","* Still computationally expensive.\n","* Skip connections increase memory usage.\n","* Deeper ‚â† always better (diminishing returns).\n","\n","**How to Overcome:**\n","\n","* Use **bottleneck layers** to reduce parameters.\n","* Optimize block design (ResNet v2).\n","* Use lightweight versions (MobileNet, EfficientNet).\n","\n","**Next Step:**\n","‚úÖ **ResNetV2** (better block ordering) ‚Üí **DenseNet** (dense connectivity).\n","\n","---\n","\n","## üîÅ 5.1 **ResNet50V2 (2016)**\n","\n","**Definition:**\n","An improved version of ResNet with **pre-activation** order (BatchNorm ‚Üí ReLU ‚Üí Conv), leading to better training stability.\n","\n","**Advantages:**\n","\n","* Faster convergence.\n","* Better generalization.\n","* Slightly improved accuracy over original.\n","\n","**Disadvantages / Limitations:**\n","\n","* Similar computational cost.\n","* Gains are incremental.\n","\n","**How to Overcome:**\n","\n","* Combine with attention or squeeze-excite blocks.\n","* Explore lightweight or hybrid architectures.\n","\n","**Next Step:**\n","‚úÖ **DenseNet**, **EfficientNet**, **RegNet**.\n","\n","---\n","\n","## ‚ú® 6. **Xception (2017)**\n","\n","**Definition:**\n","Xception is an ‚Äúextreme Inception‚Äù network that replaces inception modules with **depthwise separable convolutions**, improving efficiency.\n","\n","**Advantages:**\n","\n","* Higher accuracy with fewer parameters.\n","* More efficient computation.\n","* Better feature learning.\n","\n","**Disadvantages / Limitations:**\n","\n","* Depthwise convs can underperform on small datasets.\n","* Needs optimized hardware support.\n","* Slightly harder to implement.\n","\n","**How to Overcome:**\n","\n","* Use large datasets or pretraining.\n","* Combine with residual connections.\n","\n","**Next Step:**\n","‚úÖ **MobileNet** (optimized for mobile) ‚Üí **EfficientNet** (scaled).\n","\n","---\n","\n","## üìä 7. **InceptionV3 (2015)**\n","\n","**Definition:**\n","Improved version of GoogLeNet with **factorized convolutions**, **label smoothing**, and **auxiliary classifiers**.\n","\n","**Advantages:**\n","\n","* Higher accuracy and more efficient.\n","* Better gradient flow.\n","* Reduces overfitting with label smoothing.\n","\n","**Disadvantages / Limitations:**\n","\n","* Complex architecture.\n","* Harder to design manually.\n","* Still large for mobile devices.\n","\n","**How to Overcome:**\n","\n","* Use depthwise separable convolutions (Xception).\n","* AutoML / NAS for architecture search.\n","\n","**Next Step:**\n","‚úÖ **Inception-ResNet**, **Xception**, **EfficientNet**.\n","\n","---\n","\n","## üì± 8. **MobileNet (2017)**\n","\n","**Definition:**\n","A lightweight CNN designed for **mobile and embedded devices**, using **depthwise separable convolutions** and scaling hyperparameters.\n","\n","**Advantages:**\n","\n","* Extremely fast and lightweight.\n","* Tunable trade-off between accuracy and speed.\n","* Good for edge devices and IoT.\n","\n","**Disadvantages / Limitations:**\n","\n","* Lower accuracy compared to heavy models.\n","* Limited capacity for complex tasks.\n","* Not ideal for large-scale datasets.\n","\n","**How to Overcome:**\n","\n","* Use **MobileNetV2/V3** (better blocks, inverted residuals).\n","* Combine with NAS for optimized models.\n","\n","**Next Step:**\n","‚úÖ **MobileNetV2/V3**, **EfficientNet**, **NASNet**.\n","\n","---\n","\n","## üßæ Final Comparison Table\n","\n","| Model           | Definition                              | Advantages                       | Disadvantages              | How to Overcome                  | Next Step               |\n","| --------------- | --------------------------------------- | -------------------------------- | -------------------------- | -------------------------------- | ----------------------- |\n","| **AlexNet**     | First deep CNN breakthrough             | ReLU, GPU, dropout               | Huge params, overfitting   | Use small filters, deeper layers | ZFNet, VGG              |\n","| **ZFNet**       | Improved AlexNet + visualization        | Better features, insights        | Still shallow, incremental | Deeper network                   | VGG                     |\n","| **VGG16/19**    | Deep network with 3√ó3 convs             | Strong features, simple design   | Heavy, slow                | Use 1√ó1 conv, residuals          | GoogLeNet, ResNet       |\n","| **GoogLeNet**   | Multi-scale Inception modules           | Efficient, fewer params          | Complex, limited depth     | Add residuals, BN                | Inception v3, ResNet    |\n","| **ResNet**      | Residual learning with skip connections | Very deep, no vanishing gradient | Large model, memory        | Bottleneck, lightweight versions | ResNetV2, DenseNet      |\n","| **ResNet50V2**  | Improved residual block order           | Better training                  | Incremental gain           | Add attention, SE blocks         | DenseNet                |\n","| **Xception**    | Depthwise separable convs               | Efficient, accurate              | Needs data, hardware       | Pretrain, residuals              | MobileNet, EfficientNet |\n","| **InceptionV3** | Factorized conv, label smoothing        | High accuracy, efficient         | Complex                    | Use depthwise convs              | Xception                |\n","| **MobileNet**   | Lightweight CNN for mobile              | Fast, tunable                    | Lower accuracy             | Use V2/V3, NAS                   | EfficientNet            |\n","\n","---\n","\n","‚úÖ **Summary Insight:**\n","\n","* **AlexNet ‚Üí ZFNet ‚Üí VGG**: Focused on depth and better feature learning.\n","* **GoogLeNet ‚Üí InceptionV3 ‚Üí Xception**: Focused on efficiency and multi-scale features.\n","* **ResNet ‚Üí ResNetV2 ‚Üí DenseNet**: Solved vanishing gradient and allowed ultra-deep networks.\n","* **MobileNet ‚Üí EfficientNet**: Optimized for mobile/edge and efficiency.\n","\n","---"],"metadata":{"id":"o95NBadWxxul"}},{"cell_type":"markdown","source":["\n","## üìä Comparative Table: CNN Architectures from AlexNet to MobileNet\n","\n","| Model                        | Year | Definition                                                                 | Depth / Layers      | Key Innovation                                              | Advantages                                                                                      | Disadvantages / Limitations                                                     | How to Overcome                                                        | Next Step                    |\n","| ---------------------------- | ---- | -------------------------------------------------------------------------- | ------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------- |\n","| **AlexNet**                  | 2012 | First deep CNN that popularized deep learning by winning ImageNet.         | 8 (5 Conv + 3 FC)   | ReLU activation, dropout, GPU training                      | - Massive accuracy boost<br>- Pioneered deep learning for vision<br>- ReLU speeds training      | - Huge parameters (~60M)<br>- Overfitting risk<br>- Shallow by modern standards | - Use smaller filters<br>- Add more layers<br>- Use BN                 | ZFNet, VGG                   |\n","| **ZFNet**                    | 2013 | Improved AlexNet with better filter size and visualization tools.          | 8                   | Smaller filters, stride tuning, deconvolution visualization | - Better feature representation<br>- More interpretable<br>- Reduced overfitting                | - Still shallow<br>- Only incremental improvement<br>- Limited scalability      | - Add more layers<br>- Standardize architecture                        | VGG                          |\n","| **VGG16 / VGG19**            | 2014 | Deep CNN using uniform 3√ó3 convolution layers stacked together.            | 16 / 19             | Simplicity, depth, small filters                            | - Very strong features<br>- Transfer learning powerhouse<br>- Easy to understand                | - Huge model size (~138M params)<br>- Slow inference<br>- Memory intensive      | - Use 1√ó1 conv to reduce params<br>- Residual connections              | GoogLeNet, ResNet            |\n","| **GoogLeNet (Inception v1)** | 2014 | Multi-scale feature extraction using Inception modules.                    | 22                  | Inception module (1√ó1, 3√ó3, 5√ó5 parallel)                   | - Efficient parameter usage<br>- Multi-scale features<br>- High accuracy with fewer params      | - Complex design<br>- Limited depth (vanishing gradient)<br>- Harder to tune    | - Add residual connections<br>- Use BN<br>- Automate architecture      | Inception v3, ResNet         |\n","| **ResNet**                   | 2015 | Deep residual network solving vanishing gradient via skip connections.     | 34 / 50 / 101 / 152 | Residual connections (F(x)+x)                               | - Enables ultra-deep networks<br>- Solves degradation<br>- Excellent transfer learning backbone | - High computational cost<br>- Memory heavy<br>- Diminishing returns with depth | - Use bottlenecks<br>- Optimize architecture<br>- Lightweight variants | ResNetV2, DenseNet           |\n","| **ResNet50V2**               | 2016 | Improved residual blocks with pre-activation (BN‚ÜíReLU‚ÜíConv).               | 50                  | Pre-activation order                                        | - Faster convergence<br>- Slightly better accuracy<br>- Better generalization                   | - Similar complexity<br>- Incremental improvement                               | - Add attention<br>- Combine with SE blocks                            | DenseNet, EfficientNet       |\n","| **InceptionV3**              | 2015 | Improved GoogLeNet with factorized convolutions and auxiliary classifiers. | ~48                 | Factorized conv, label smoothing                            | - Higher accuracy<br>- Efficient computation<br>- Better gradient flow                          | - Still complex<br>- Large for edge devices<br>- Manual design                  | - Use depthwise separable convs<br>- NAS                               | Xception, Inception-ResNet   |\n","| **Xception**                 | 2017 | Extreme Inception using depthwise separable convolutions.                  | 36                  | Depthwise + pointwise convolution                           | - More efficient<br>- Better accuracy<br>- Fewer parameters                                     | - Needs large data<br>- Hardware support needed<br>- Slightly complex           | - Pretrain<br>- Add residuals<br>- Optimize hardware                   | MobileNet, EfficientNet      |\n","| **MobileNet**                | 2017 | Lightweight CNN for mobile and embedded devices.                           | ~28                 | Depthwise separable conv + width/resolution multipliers     | - Extremely fast<br>- Small size<br>- Tunable trade-off (accuracy vs speed)                     | - Lower accuracy<br>- Limited capacity<br>- Less suited for complex tasks       | - Use MobileNetV2/V3<br>- Add attention or NAS optimization            | MobileNetV2/V3, EfficientNet |\n","\n","---\n","\n","## üîé Key Takeaways (Teaching Notes)\n","\n","| Generation  | Focus                           | Representative Models  | Key Shift                                    |\n","| ----------- | ------------------------------- | ---------------------- | -------------------------------------------- |\n","| **1st Gen** | Proving deep CNNs work          | AlexNet, ZFNet         | ReLU, GPU training, visualization            |\n","| **2nd Gen** | Depth & simplicity              | VGG16/19               | Deep networks, uniform layers                |\n","| **3rd Gen** | Efficiency & multi-scale        | GoogLeNet, InceptionV3 | Inception modules, 1√ó1 conv                  |\n","| **4th Gen** | Ultra-deep & gradient flow      | ResNet, ResNetV2       | Residual connections                         |\n","| **5th Gen** | Parameter efficiency            | Xception, MobileNet    | Depthwise separable conv                     |\n","| **6th Gen** | AutoML & scalable architectures | EfficientNet, NASNet   | Neural architecture search, compound scaling |\n","\n","---\n","\n","### üß† Teaching Insights\n","\n","* üìà **Accuracy vs Efficiency:**\n","\n","  * VGG & ResNet ‚Üí High accuracy but heavy\n","  * GoogLeNet & Xception ‚Üí Balance\n","  * MobileNet ‚Üí Efficiency for edge devices\n","\n","* ‚öôÔ∏è **Depth vs Complexity:**\n","\n","  * AlexNet & VGG ‚Üí Simple but shallow\n","  * ResNet & Inception ‚Üí Deep & complex\n","  * MobileNet ‚Üí Shallow but optimized\n","\n","* üì± **Modern Trend:**\n","\n","  * Efficient architectures (MobileNet, EfficientNet)\n","  * NAS (Neural Architecture Search)\n","  * Attention + CNN hybrids (ConvNeXt, CoAtNet)\n","\n","---\n","\n","‚úÖ **Summary:**\n","The evolution of CNNs from AlexNet to MobileNet shows a journey from **depth and brute-force accuracy** ‚Üí to **efficiency, scalability, and real-world deployment**. Each architecture solved a major limitation of its predecessor and paved the way for modern CNN and hybrid architectures.\n","\n","---\n"],"metadata":{"id":"kaMQ7itmx6jU"}},{"cell_type":"markdown","source":["## Resnet50"],"metadata":{"id":"cFnr89WIuQ-r"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n"],"metadata":{"id":"wF9OLVylsRwT","executionInfo":{"status":"ok","timestamp":1759565064564,"user_tz":-330,"elapsed":9597,"user":{"displayName":"Sahil","userId":"02943187861823395646"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Step 1: Load the pre-trained ResNet50 model\n","# The model is loaded with weights pre-trained on the ImageNet dataset.\n","print(\"Loading ResNet50 model with ImageNet weights...\")\n","model = ResNet50(weights='imagenet')\n","print(\"Model loaded successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-w1-Yc71sZIT","executionInfo":{"status":"ok","timestamp":1758029011040,"user_tz":-330,"elapsed":5299,"user":{"displayName":"Sahil","userId":"02943187861823395646"}},"outputId":"0fe7a6c6-2d0c-4205-dc6a-cbd0090d7dff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ResNet50 model with ImageNet weights...\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","\u001b[1m102967424/102967424\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Model loaded successfully.\n"]}]},{"cell_type":"code","source":["# Step 2: Define image path and load/preprocess an image\n","# The video uses examples like a dog, bread, tomato, and chair images.\n","# Replace 'path/to/your/image.jpg' with the actual path to your image file.\n","# Common target size for ResNet50 is 224x224 pixels.\n","image_path = 'path/to/your/image.jpg' # Example: 'dog.jpg', 'bread.jpg', 'tomato.jpg', 'chair.jpg'\n"],"metadata":{"id":"tcl8Xz9BscLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n","\n","# Step 1: Load the pre-trained ResNet50 model\n","# The model is loaded with weights pre-trained on the ImageNet dataset.\n","print(\"Loading ResNet50 model with ImageNet weights...\")\n","model = ResNet50(weights='imagenet')\n","print(\"Model loaded successfully.\")\n","\n","# Step 2: Define image path and load/preprocess an image\n","# The video uses examples like a dog, bread, tomato, and chair images.\n","# Replace 'path/to/your/image.jpg' with the actual path to your image file.\n","# Common target size for ResNet50 is 224x224 pixels.\n","image_path = 'image.jpg' # Example: 'dog.jpg', 'bread.jpg', 'tomato.jpg', 'chair.jpg'\n","\n","try:\n","    # Load the image and resize it to 224x224 pixels.\n","    img = image.load_img(image_path, target_size=(224, 224))\n","    print(f\"\\nImage '{image_path}' loaded.\")\n","\n","    # Convert the image to a NumPy array.\n","    x = image.img_to_array(img)\n","\n","    # Expand the dimensions of the array to create a batch of 1 image.\n","    # This converts a (224, 224, 3) array into a (1, 224, 224, 3) batch.\n","    x = np.expand_dims(x, axis=0)\n","\n","    # Preprocess the image for the ResNet50 model.\n","    # This function performs operations like mean subtraction, scaling, etc.,\n","    # specific to the ResNet50 model's training on ImageNet.\n","    x = preprocess_input(x)\n","    print(\"Image preprocessed for ResNet50 model.\")\n","\n","    # Step 3: Make predictions using the pre-trained model\n","    # The pre-trained model processes the image and outputs class probabilities.\n","    print(\"Making predictions...\")\n","    predictions = model.predict(x)\n","    print(\"Predictions made.\")\n","\n","    # Step 4: Decode and display the predictions\n","    # This function decodes the top-N predictions from the model's output\n","    # into human-readable labels and their probabilities.\n","    # 'top=3' retrieves the top 3 most likely predictions.\n","    decoded_predictions = decode_predictions(predictions, top=3)\n","\n","    print(\"\\nPredicted classes:\")\n","    for i, (imagenet_id, label, score) in enumerate(decoded_predictions):\n","        print(f\"{i + 1}: {label} ({score:.2f})\")\n","\n","    # The video notes that for a tomato image, the model might show some confusion,\n","    # predicting \"strawberry\" or \"hip\", while for dog, bread, and chair images,\n","    # it predicts accurately (e.g., \"Labrador retriever\", \"French loaf\", \"dining chair\").\n","\n","except FileNotFoundError:\n","    print(f\"Error: The image file at '{image_path}' was not found. Please check the path.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMoFN4ovsSKU","executionInfo":{"status":"ok","timestamp":1758029125736,"user_tz":-330,"elapsed":5231,"user":{"displayName":"Sahil","userId":"02943187861823395646"}},"outputId":"ca2d9853-8ce5-4313-ce68-4841371118fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ResNet50 model with ImageNet weights...\n","Model loaded successfully.\n","\n","Image 'image.jpg' loaded.\n","Image preprocessed for ResNet50 model.\n","Making predictions...\n","\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","Predictions made.\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","\u001b[1m35363/35363\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","\n","Predicted classes:\n","An error occurred: unsupported format string passed to tuple.__format__\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V0YlIZC7s34C"},"execution_count":null,"outputs":[]}]}