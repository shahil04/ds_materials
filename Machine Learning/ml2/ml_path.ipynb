{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maths \n",
    "- stats and probability\n",
    "-equation of line ( slop  and intercept of a line\n",
    "\n",
    "- calculus intutions, derivatives,\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro ML\n",
    "- before start with example catbary ads, chatgpt, \n",
    "    - ajay or agrim mail sagrigate example \n",
    "- terminologies\n",
    "\n",
    "- what is ml ?\n",
    "    -  1959 samual,\n",
    "\n",
    "- traditional Programming paradigam (data+ logic (program) then compute then output)\n",
    "-  ml paradigm (data + logic + compute + output + learn from output)\n",
    "    - data+output --> compute and find logicor pattern  -->then this pattern store as a model\n",
    "\n",
    "\n",
    "- brief history\n",
    "- 1950s: 1st AI program (logic theorem prover)\n",
    "- 1960s: 1st ML program (perceptron)\n",
    "- 1980s: 1st neural network (backpropagation)\n",
    "- 1990s: 1st deep learning (convolutional neural networks)\n",
    "- 2000s: 1st big data (Hadoop, MapReduce)\n",
    "- 2010s: 1st AI winter (ML, DL, NLP, C\n",
    "- 2020s: 1st AI summer (ML, DL, NLP, CV\n",
    "    -  2020: 1st transformer (BERT, RoBERTa)\n",
    "    - 2020s: 1st explainability (SHAP, LIME, TreeExpl\n",
    "- 2021 chatgpt\n",
    "\n",
    "- 1959 > 1975(AN)-> 1997> 2011>2016> 2017>2020>2021\n",
    "\n",
    "- AI vs  ML vs DL vs NLP vs CV vs DS vs DA vs BA vs mlops \n",
    "\n",
    "- types of ml\n",
    "- supervised\n",
    "- unsupervised\n",
    "- semi-supervised\n",
    "- reinforcement learning\n",
    "    - * Extra\n",
    "    - transfer learning\n",
    "    - online learning\n",
    "    - active learning\n",
    "    - few shot learning\n",
    "    - meta learning\n",
    "    - multi-task learning\n",
    "    - federated learning\n",
    "    - adversarial learning\n",
    "    - generative adversarial networks (GANs)\n",
    "    - 1st ml model (perceptron)\n",
    "    - 1st neural network (backpropagation)\n",
    "    - 1st deep learning (convolutional neural networks)\n",
    "    - 1st big data (Hadoop, MapReduce)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- types of ml\n",
    "    - supervised >house price \n",
    "        -  regression >y continous\n",
    "        - classification > y descrete \n",
    "        \n",
    "\n",
    "    - unsupervised > not label\n",
    "        -  clustering > group similar data\n",
    "        - dimensionality reduction > reduce data to lower dimention\n",
    "        - association rule > find relation between data\n",
    "\n",
    "\n",
    "    - semi-supervised\n",
    "        -   few labeled data > use unlabeled data to improve model performance\n",
    "        -   semi-supervised learning > use unlabeled data to improve model performance\n",
    "\n",
    "\n",
    "    - reinforcement learning    \n",
    "        -   agent > take action in environment > get reward or penalty > learn from experience > improve performance\n",
    "        -   goal > maximize cumulative reward > learn policy > take action > get reward > update policy\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model\n",
    "- train test\n",
    "- train validate test\n",
    "- data leakage\n",
    "-  data augmentation\n",
    "- why validations need\n",
    "- validation metrics\n",
    "- parameter\n",
    "-  hyperparameter tuning\n",
    "\n",
    "* ml Framework\n",
    "-  tensorflow\n",
    "-  pytorch\n",
    " -  set of  tools\n",
    " - a predefine process\n",
    " - standarized proces\n",
    "\n",
    "\n",
    "* Model training\n",
    "- given the data estimate the prediction funtions(ml algos) to minimizing error(evaluvation matrix)\n",
    "-  model training process\n",
    "-  model evaluation process\n",
    "-  model validation process\n",
    "- model predictions  process\n",
    "-  model deployment process\n",
    "-  model monitoring process\n",
    "-  model maintenance process\n",
    "-  model update process\n",
    "-  model retraining process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "- **Data**: The information that is stored in a database or a data warehouse.\n",
    "- **Data Warehouse**: A centralized repository that stores data from various sources in a single location, making\n",
    "- overfitting \n",
    "-  **Overfitting**: When a model is too complex and learns the noise in the training data,\n",
    "- **Underfitting**: When a model is too simple and fails to capture the underlying patterns in\n",
    "- Generalization : The ability of a model to perform well on new, unseen data.\n",
    "\n",
    "- **Regularization**: A technique used to prevent overfitting by adding a penalty term to the\n",
    "- **Bias-Variance Tradeoff**: The tradeoff between the bias of a model (its tendency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vectors\n",
    "- opertions on vectors\n",
    "- projections\n",
    "- dot product\n",
    "\n",
    "    - cross product\n",
    "    - vector magnitude\n",
    "    - vector angle\n",
    "    - vector addition and subtraction\n",
    "    - vector scalar multiplication\n",
    "    - vector vector multiplication\n",
    "    - vector projection onto a plane\n",
    "    - vector projection onto a line\n",
    "    - vector projection onto a vector\n",
    "    - vector projection onto a plane with a normal vector\n",
    "    why we do all this  stuff\n",
    "\n",
    "- extras\n",
    "    - vector spaces\n",
    "    - linear transformations\n",
    "    - eigenvalues and eigenvectors\n",
    "    - inner product spaces\n",
    "    - orthogonal projections\n",
    "    - spectral theorem for normal operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear algebra\n",
    "- numerical analysis\n",
    "- matrix addition\n",
    "- matrix multiplication\n",
    "- matrix transpose\n",
    "- matrix determinant\n",
    "- matrix inverse\n",
    "\n",
    "- vector and matrix relationships\n",
    "- rotations ,zsccore(scale up /down) , scaling , translation , reflection , rotation , projection , shear , matrix multiplication , matrix inverse\n",
    "\n",
    "- vector to  matrix calculations\n",
    "- np.linear.sol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data preparation\n",
    "* data analysis\n",
    "* data visualization\n",
    "\n",
    "- feature engineering\n",
    "- model selection\n",
    "- model training\n",
    "- model evaluation\n",
    "\n",
    "#### Simple Linear Regresion\n",
    "- eigen value ,eigen vactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRISP -DM framework"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
