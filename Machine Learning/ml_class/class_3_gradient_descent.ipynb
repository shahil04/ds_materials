{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eafb47f",
   "metadata": {},
   "source": [
    "\n",
    "## We will learn  \n",
    "\n",
    "- Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b3f9d",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37644b",
   "metadata": {},
   "source": [
    "#### What is a Cost Function?\n",
    "It is a function that measures the performance of a model for any given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.\n",
    "\n",
    "#### What is Gradient?\n",
    "A gradient is nothing but a derivative that defines the effects on outputs of the function with a little bit of variation in inputs.\n",
    "\n",
    "#### What is Gradient Descent?\n",
    "Gradient Descent stands as a cornerstone orchestrating the intricate dance of model optimization. At its core, it is a numerical optimization algorithm that aims to find the optimal parameters—weights and biases—of a neural network by minimizing a defined cost function.\n",
    "\n",
    "Gradient Descent (GD) is a widely used optimization algorithm in machine learning and deep learning that minimises the cost function of a neural network model during training. It works by iteratively adjusting the weights or parameters of the model in the direction of the negative gradient of the cost function until the minimum of the cost function is reached.\n",
    "\n",
    "Gradient Descent is a fundamental optimization algorithm in machine learning used to minimize the cost or loss function during model training.\n",
    "\n",
    "It iteratively adjusts model parameters by moving in the direction of the steepest decrease in the cost function.\n",
    "The algorithm calculates gradients, representing the partial derivatives of the cost function concerning each parameter.\n",
    "\n",
    "\n",
    "#### Types of Gradient Descent Algorithm\n",
    "\n",
    "The choice of gradient descent algorithm depends on the problem at hand and the size of the dataset. Batch gradient descent is suitable for small datasets, while stochastic gradient descent algorithm is more suitable for large datasets. Mini-batch is a good compromise between the two and is often used in practice.\n",
    "\n",
    "1. Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2020/10/how-does-the-gradient-descent-algorithm-work-in-machine-learning/\n",
    "# https://www.geeksforgeeks.org/gradient-descent-algorithm-and-its-variants/\n",
    "# https://www.javatpoint.com/gradient-descent-in-machine-learning\n",
    "# https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6e306-f768-4b37-bf0d-2caa46ad1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(X, y, learning_rate, num_iters):\n",
    "  \"\"\"\n",
    "  Performs gradient descent to find optimal weights and bias for linear regression.\n",
    "\n",
    "  Args:\n",
    "      X: A numpy array of shape (m, n) representing the training data features.\n",
    "      y: A numpy array of shape (m,) representing the training data target values.\n",
    "      learning_rate: The learning rate to control the step size during updates.\n",
    "      num_iters: The number of iterations to perform gradient descent.\n",
    "\n",
    "  Returns:\n",
    "      A tuple containing the learned weights and bias.\n",
    "  \"\"\"\n",
    "\n",
    "  # Initialize weights and bias with random values\n",
    "  m, n = X.shape\n",
    "  weights = np.random.rand(n)\n",
    "  bias = 0\n",
    "\n",
    "  # Loop for the number of iterations\n",
    "  for i in range(num_iters):\n",
    "    # Predict y values using current weights and bias\n",
    "    y_predicted = np.dot(X, weights) + bias\n",
    "\n",
    "    # Calculate the error\n",
    "    error = y - y_predicted\n",
    "\n",
    "    # Calculate gradients for weights and bias\n",
    "    weights_gradient = -2/m * np.dot(X.T, error)\n",
    "    bias_gradient = -2/m * np.sum(error)\n",
    "\n",
    "    # Update weights and bias using learning rate\n",
    "    weights -= learning_rate * weights_gradient\n",
    "    bias -= learning_rate * bias_gradient\n",
    "\n",
    "  return weights, bias\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[1, 1], [2, 2], [3, 3]])\n",
    "y = np.array([2, 4, 5])\n",
    "learning_rate = 0.01\n",
    "num_iters = 100\n",
    "\n",
    "weights, bias = gradient_descent(X, y, learning_rate, num_iters)\n",
    "\n",
    "print(\"Learned weights:\", weights)\n",
    "print(\"Learned bias:\", bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28418ea",
   "metadata": {},
   "source": [
    "Gradient Descent is an optimization algorithm used extensively in machine learning and deep learning to minimize a cost function and find the optimal parameters of a model. It is particularly important in training algorithms for models like linear regression, logistic regression, neural networks, and more.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "1. **Cost Function**:\n",
    "   - Represents the error or difference between the predicted and actual values.\n",
    "   - Examples: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n",
    "\n",
    "2. **Objective**:\n",
    "   - Minimize the cost function by iteratively updating the model parameters (weights and biases).\n",
    "\n",
    "3. **Gradient**:\n",
    "   - The gradient is the partial derivative of the cost function with respect to model parameters.\n",
    "   - It indicates the direction and rate of the steepest increase of the cost function.\n",
    "\n",
    "4. **Learning Rate (\\(\\alpha\\))**:\n",
    "   - A hyperparameter that controls the step size in the parameter update.\n",
    "   - If \\(\\alpha\\) is too large, the algorithm might overshoot the minimum. If too small, convergence will be slow.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Gradient Descent Works**\n",
    "For a cost function \\( J(\\theta) \\), where \\( \\theta \\) represents the model parameters:\n",
    "1. Initialize parameters (\\( \\theta \\)) randomly or to zeros.\n",
    "2. Calculate the gradient of \\( J(\\theta) \\) with respect to \\( \\theta \\).\n",
    "3. Update the parameters using the formula:\n",
    "   \\[\n",
    "   \\theta := \\theta - \\alpha \\cdot \\frac{\\partial J(\\theta)}{\\partial \\theta}\n",
    "   \\]\n",
    "   Here:\n",
    "   - \\( \\frac{\\partial J(\\theta)}{\\partial \\theta} \\): Gradient of the cost function.\n",
    "   - \\( \\alpha \\): Learning rate.\n",
    "\n",
    "4. Repeat steps 2 and 3 until convergence (when changes in \\( J(\\theta) \\) are negligible).\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Gradient Descent**\n",
    "1. **Batch Gradient Descent**:\n",
    "   - Uses the entire dataset to compute the gradient.\n",
    "   - Convergence is stable but computationally expensive for large datasets.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**:\n",
    "   - Updates parameters using a single data point (or sample) at each step.\n",
    "   - Faster updates but more noise in convergence.\n",
    "\n",
    "3. **Mini-Batch Gradient Descent**:\n",
    "   - Combines benefits of Batch and SGD.\n",
    "   - Uses small batches of data to compute the gradient.\n",
    "   - Efficient and widely used in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### **Challenges and Solutions**\n",
    "1. **Local Minima**:\n",
    "   - Non-convex functions might have local minima.\n",
    "   - Solution: Use momentum, adaptive optimizers like Adam.\n",
    "\n",
    "2. **Learning Rate Tuning**:\n",
    "   - Choosing an appropriate learning rate is crucial.\n",
    "   - Solution: Use learning rate schedules or adaptive methods (e.g., AdaGrad, RMSProp).\n",
    "\n",
    "3. **Slow Convergence**:\n",
    "   - Near flat regions of the cost function.\n",
    "   - Solution: Use techniques like momentum or Nesterov acceleration.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications in Machine Learning**\n",
    "1. **Linear Regression**:\n",
    "   - Minimize Mean Squared Error to find the best-fit line.\n",
    "2. **Logistic Regression**:\n",
    "   - Minimize Cross-Entropy Loss for binary classification.\n",
    "3. **Neural Networks**:\n",
    "   - Optimize weights and biases to minimize the loss function during backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "Gradient Descent is the foundation of many machine learning algorithms and continues to evolve with advanced optimizers for faster and more robust learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d4f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ecd4d3",
   "metadata": {},
   "source": [
    "## We Will Learn In next \n",
    "- Logistic Regression\n",
    "- CrossValidations\n",
    "- Hyperparameter Tuning\n",
    "- Implementations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
