{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "df.shape\n",
    "\n",
    "# C:\\Users\\hp\\Documents\\ds\\ds_materials\\Machine Learning\\ml2\\class_11_1_car_prediction.ipynb\n",
    "df.info\n",
    "\n",
    "# Check if there are any null values\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "## Univariant\n",
    "# code to plot distribution of schools and checking the count of GP & MS\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='school', data=df, palette='pastel')\n",
    "plt.title('Distribution of Schools')\n",
    "plt.xlabel('School')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA\n",
    "1.**Question:** What is the most common age group among the students in the dataset?\n",
    "\n",
    "**Answer:** The most common age group among the students appears to be around 15 to 16 years old.\n",
    "\n",
    "2.**Question:** Is the distribution of age skewed towards younger or older students?\n",
    "\n",
    "**Answer:** The distribution of age appears to be slightly skewed towards younger students, to the left side (lower ages). However, there is still a significant number of students in the older age groups, suggesting a relatively balanced distribution overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_counts = df['reason'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(reason_counts, labels=reason_counts.index, autopct='%1.1f%%', colors=['lightblue', 'lightgreen', 'lightcoral', 'lightskyblue'])\n",
    "plt.title('Distribution of School Reputation as Reason for Choosing School')\n",
    "plt.show()\n",
    "\n",
    "df['Walc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Very low level of weekend alcohol consumption.\n",
    "\n",
    "2: Low level of weekend alcohol consumption.\n",
    "\n",
    "3: Moderate level of weekend alcohol consumption.\n",
    "\n",
    "4: High level of weekend alcohol consumption.\n",
    "\n",
    "5: Very high level of weekend alcohol consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bi-variant\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting Mother's Education Level\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='Medu', data=df, palette=\"Set2\")\n",
    "plt.xlabel(\"Mother's Education Level\")\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Mother's Education Level Distribution\")\n",
    "\n",
    "# Plotting Father's Education Level\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='Fedu', data=df, palette=\"Set3\")\n",
    "plt.xlabel(\"Father's Education Level\")\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Father's Education Level Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-variant\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='sex', y='G3', hue='address', data=df, palette='Set2')\n",
    "plt.title('Final Grade (G3) by Gender and Address')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Final Grade (G3)')\n",
    "plt.legend(title='Address')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Selecting the numerical columns for visualization\n",
    "numerical_columns = ['age', 'traveltime', 'studytime', 'absences', 'G1', 'G2', 'G3']\n",
    "\n",
    "# Creating a box plot for multiple columns\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df[numerical_columns], palette='Set2')\n",
    "plt.title('Box Plot of Multiple Columns')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Column')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr(numeric_only = True)\n",
    "\n",
    "# Plot the heatmap with adjusted font size\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier\n",
    "\n",
    "def detect_outliers(columns):\n",
    "    outlier_indices = []\n",
    "    for column in columns:\n",
    "        Q1 = students_grades_df[column].quantile(0.25)\n",
    "        Q3 = students_grades_df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1  # IQR is interquartile range.\n",
    "\n",
    "        mask = (students_grades_df[column] >= Q1 - 1.5 *\n",
    "                IQR) & (students_grades_df[column] <= Q3 + 1.5 * IQR)\n",
    "        mask = mask.to_numpy()\n",
    "        false_indices = np.argwhere(~mask)\n",
    "        outlier_indices.append(false_indices)\n",
    "    return np.unique(np.concatenate(outlier_indices).ravel())\n",
    "\n",
    "numerical_columns = ['age', 'absences']\n",
    "outlier_indices = detect_outliers(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X, y = students_grades_df.iloc[:, :-1], students_grades_df.iloc[:, -1]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to know which columns are binary, nominal and numerical\n",
    "def get_columns_by_category():\n",
    "    categorical_mask = X.select_dtypes(\n",
    "        include=['object']).apply(pd.Series.nunique) == 2\n",
    "    numerical_mask = X.select_dtypes(\n",
    "        include=['int64', 'float64']).apply(pd.Series.nunique) > 5\n",
    "\n",
    "    binary_columns = X[categorical_mask.index[categorical_mask]].columns\n",
    "    nominal_columns = X[categorical_mask.index[~categorical_mask]].columns\n",
    "    numerical_columns = X[numerical_mask.index[numerical_mask]].columns\n",
    "\n",
    "    return binary_columns, nominal_columns, numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns, nominal_columns, numerical_columns = get_columns_by_category()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "# Now we can create a column transformer pipeline\n",
    "transformers = [('binary', OrdinalEncoder(), binary_columns),\n",
    "                ('nominal', OneHotEncoder(), nominal_columns),\n",
    "                ('numerical', StandardScaler(), numerical_columns)]\n",
    "\n",
    "transformer_pipeline = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "transformer_pipeline\n",
    "\n",
    "# So now according to columns we have performed transformations. now finally we can go with model training."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
