{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pandas\n",
    "\n",
    "Pandas is a Python library used for data manipulation and analysis. Pandas provides a convenient way to analyze and clean data.\n",
    "\n",
    "The Pandas library introduces two new data structures to Python - Series and DataFrame, both of which are built on top of NumPy.\n",
    "\n",
    "### What is Pandas Used for?\n",
    "\n",
    "Pandas is a powerful library generally used for:\n",
    "\n",
    "- Data Cleaning\n",
    "- Data Transformation\n",
    "- Data Analysis\n",
    "- Machine Learning\n",
    "- Data Visualization\n",
    "\n",
    "### Why Use Pandas?\n",
    "\n",
    "Some of the reasons why we should use Pandas are as follows:\n",
    "\n",
    "1. **Handle Large Data Efficiently**\n",
    "\n",
    "   Pandas is designed for handling large datasets. It provides powerful tools that simplify tasks like data filtering, transforming, and merging.\n",
    "\n",
    "   It also provides built-in functions to work with formats like CSV, JSON, TXT, Excel, and SQL databases.\n",
    "\n",
    "2. **Tabular Data Representation**\n",
    "\n",
    "   Pandas DataFrames, the primary data structure of Pandas, handle data in tabular format. This allows easy indexing, selecting, replacing, and slicing of data.\n",
    "\n",
    "3. **Data Cleaning and Preprocessing**\n",
    "\n",
    "   Data cleaning and preprocessing are essential steps in the data analysis pipeline, and Pandas provides powerful tools to facilitate these tasks. It has methods for handling missing values, removing duplicates, handling outliers, data normalization, etc.\n",
    "\n",
    "4. **Time Series Functionality**\n",
    "\n",
    "   Pandas contains an extensive set of tools for working with dates, times, and time-indexed data as it was initially developed for financial modeling.\n",
    "\n",
    "5. **Free and Open-Source**\n",
    "\n",
    "   Pandas follows the same principles as Python, allowing you to use and distribute Pandas for free, even for commercial use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Pandas\n",
    "\n",
    "To install pandas, you need Python and PIP installed on your system. If you have Python and PIP installed already, you can install pandas by entering the following command in the terminal:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "If the installation completes without any errors, Pandas is now successfully installed on your system. You can start using it in your Python projects by importing the Pandas library.\n",
    "\n",
    "### Import Pandas in Python\n",
    "\n",
    "We can import Pandas in Python using the import statement:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pandas>>data manipulation and data wrangling\n",
    "# create Series, DataFrame ,indexing, columns, data types, assign, create new columns\n",
    "\n",
    "# data cleaning\n",
    "# drop columns,  drop rows, fill missing values, handle outliers, remove duplicates\n",
    "\n",
    "\n",
    "# data transformation\n",
    "# pivot, melt, groupby, sort, sortby, rank, quantile, shift,\n",
    "# data merging\n",
    "# join, merge, concat, append\n",
    "# data analysis\n",
    "# summary statistics, descriptive statistics, correlation, regression, time series analysis\n",
    "# data visualization\n",
    "# plot, scatter plot, bar plot, histogram, box plot, violin plot, heatmap\n",
    "# data export\n",
    "# to_csv, to_excel, to_json, to_pickle, to_sql\n",
    "\n",
    "\n",
    "\n",
    "# A Pandas Series is a one-dimensional labeled array-like object that can hold data of any type.\n",
    "### Labels\n",
    "\n",
    "# The labels in the Pandas Series are \n",
    "# index numbers by default. Like in DataFrame and array, the index number in Series starts from 0.\n",
    "\n",
    "# Create a Series and specify labels\n",
    "# my_series = pd.Series(a, index = [\"x\", \"y\", \"z\"])\n",
    "\n",
    "import pandas as pd\n",
    "li = [34,3,534,34,23]\n",
    "se = pd.Series(li)\n",
    "se[2]\n",
    "se[2:4]\n",
    "\n",
    "se2 = pd.Series([12,32,243,45] , index=['a','b','c','d'])\n",
    "se2[\"c\"]\n",
    "se2[\"c\"] = 24\n",
    "\n",
    "#  data frame\n",
    "pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n",
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]], index=['a','b','c'], columns=['x','y','z'])\n",
    "df\n",
    "pd.DataFrame({\"x\":[1,2,3],\"y\":[4,5,6],\"z\":[7,8,9]})\n",
    "\n",
    "s = pd.Series(list(df['Name'][2:5]), index = ['a', 'b', 'c'])\n",
    "s\n",
    "s1 = pd.Series(list(df['Name'][5:8]))\n",
    "s1\n",
    "s+s1 #series or dataframe doesnt work with +\n",
    "s.append(s1)\n",
    "type(df)\n",
    "\n",
    "#data structure>> series, dataframe\n",
    "#series> 1 dimensional in nature\n",
    "#dataframe> 2 dimensional in nature , multiple series constitute to form a dataframe\n",
    "\n",
    "df.dtypes\n",
    "df.shape\n",
    "df\n",
    "pd.Series([2, 3, 4], index = [100, \"ajay\", 2])\n",
    "d = pd.DataFrame(pd.Series([2, 3, 4], index = [100, \"ajay\", 2]))\n",
    "d[1] = \"Anuj\"\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.rea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version https://git-lfs.github.com/spec/v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oid sha256:567be8c7e70a068367cdedd0728bf4f98b6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>size 19104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          version https://git-lfs.github.com/spec/v1\n",
       "0  oid sha256:567be8c7e70a068367cdedd0728bf4f98b6...\n",
       "1                                         size 19104"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load Diffrent Files\n",
    "df = pd.read_csv(\"services.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load Diffrent Files\n",
    "df = pd.read_csv(\"services.csv\")\n",
    "ex = pd.read_excel(\"basic_data_excel.xlsx\")\n",
    "ex\n",
    "df\n",
    "df3 = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "df3\n",
    "df3.dtypes\n",
    "df3.shape\n",
    "df3.info()\n",
    "df3[['Sex']]\n",
    "\n",
    "df3.columns\n",
    "df4 = df3[['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare']]\n",
    "df4.to_csv(\"test.csv\", index = False)\n",
    "\n",
    "# pip install lxml\n",
    "import lxml\n",
    "url_df = pd.read_html(\"https://www.basketball-reference.com/leagues/NBA_2015_totals.html\")\n",
    "type(url_df)\n",
    "len(url_df)\n",
    "df4 = url_df[0]\n",
    "df4\n",
    "df4.head()\n",
    "df4.shape\n",
    "df4.info()\n",
    "df4.to_csv(\"players.csv\", index=False)\n",
    "\n",
    "json =\"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(df[i]['user']['node_id'])\n",
    "\n",
    "df = pd.DataFrame(df, columns = ['user', 'timeline_url'])\n",
    "\n",
    "# df.to_csv('json_info.csv')\n",
    "#Solving the dataset\n",
    "\n",
    "# mysql connector\n",
    "import mysql.connector  \n",
    " \n",
    "#Create the connection object   \n",
    "myconn = mysql.connector.connect(host = \"127.0.0.1\", user = \"root\",passwd = \"Azsxdcf123@\" ,database = \"mavenmovies\")  \n",
    "  \n",
    "#creating the cursor object  \n",
    "cur = myconn.cursor()  \n",
    "  \n",
    "try:  \n",
    "    #Reading the Employee data      \n",
    "    cur.execute(\"select * from Actor\")  \n",
    "  \n",
    "    #fetching the rows from the cursor object  \n",
    "    result = cur.fetchall()  \n",
    "    #printing the result  \n",
    "  \n",
    "    for x in result:  \n",
    "        print(x);  \n",
    "except:  \n",
    "    myconn.rollback()  \n",
    "  \n",
    "myconn.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================== \n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "df\n",
    "df.columns\n",
    "df.head()\n",
    "df.tail()\n",
    "df.dtypes\n",
    "df.size\n",
    "df.sample(1)\n",
    "df.columns\n",
    "list(df.columns)\n",
    "df.info()\n",
    "df.dtypes\n",
    "df.shape\n",
    "df.describe() #numerical data\n",
    "\n",
    "type(df['id'])\n",
    "\n",
    "# df.numeric.describe()\n",
    "df.describe()\n",
    "df[['PassengerId', 'Survived', 'Pclass']]\n",
    "df.describe(include = 'object')\n",
    "df.describe(include = 'all')\n",
    "df.astype('object').describe()\n",
    "\n",
    "df.dtypes == 'object'\n",
    "df.dtypes\n",
    "df.dtypes[df.dtypes == 'object'].index\n",
    "df[df.dtypes[df.dtypes == 'object'].index]\n",
    "df[df.columns[df.dtypes == 'object']]\n",
    "\n",
    "df[df.dtypes[df.dtypes != 'object'].index].describe()\n",
    "df[df.columns[df.dtypes != 'object']].describe()\n",
    "df[df.dtypes[df.dtypes == 'object'].index].describe()\n",
    "\n",
    "\n",
    "# df.numeric.describe()\n",
    "df.describe()\n",
    "df\n",
    "# Slicing : indexing  by label or position\n",
    "df[10:100:5]\n",
    "pd.Categorical(df['Pclass'])\n",
    "pd.Categorical(df['Cabin'])\n",
    "df['Cabin'].unique()\n",
    "df['Cabin'].nunique()\n",
    "df['Cabin'].value_counts()\n",
    "df\n",
    "df.head()\n",
    "# deep copy shallow copy\n",
    "df3= df\n",
    "df2 = df.copy()   # copy the dataframe\n",
    "\n",
    "# Slicing name basis\n",
    "df4.loc[0:4]   # row  slicing\n",
    "df4.loc[0:4,\"Name\":\"Fare\"] # rows and  columns slice\n",
    "df4.loc[0:4,[\"Name\",\"Fare\"]]\n",
    "\n",
    "# Slicing index\n",
    "df4.iloc[0:4]   # row  slicing\n",
    "df4.iloc[0:4,2:6]\n",
    "df4.iloc[0:4,[2,5]]\n",
    "\n",
    "# create new cols and add into df4\n",
    "df4[\"new col\"] =0\n",
    "\n",
    "#Access df rows #implicit index>internal/integer index and explicit index/named>>define\n",
    "df[0:100]\n",
    "df.iloc[0:2] #start from 0 and go to 1\n",
    "df.loc[0:2] #give me the rows whose name is 0, 1, 2\n",
    "\n",
    "#loc will go with named indexes, iloc will go with inbuilt index\n",
    "df.iloc[0:2, ['Name', 'Sex', 'Age']] #it will throw an error, why?\n",
    "df.loc[0:2, ['Name', 'Sex', 'Age']]\n",
    "\n",
    "df\n",
    "df.iloc[0:2, 3:6]\n",
    "list(df['Name'][2:5])\n",
    "\n",
    "\n",
    "df1[['name']].dropna(axis = 1) #for one column\n",
    "df1.fillna(\"missing_value_here>lalalalalala\", inplace = True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace value example\n",
    "df.loc[7, 'Duration'] = 45\n",
    "\n",
    "# If the value is higher than 120, set it to 120:\n",
    "\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120\n",
    "# Delete rows where \"Duration\" is higher than 120:\n",
    "\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.drop(x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df4.duplicated()\n",
    "df4.duplicated().sum()\n",
    "df4.drop_duplicates()\n",
    "\n",
    "df4.isna()\n",
    "df4.isna().sum()\n",
    "df4.drop(columns=[\"Unnamed: 0\",\"Cabin\"] ,axis=1) \n",
    "df4.drop(columns=[\"Unnamed: 0\",\"Cabin\"] ,axis=1,inplace=True)\n",
    "df4.isnull().sum()\n",
    "\n",
    "df.drop(1, inplace=True)\n",
    "df\n",
    "df.set_index('Name', inplace = True) #time series data>>you will be making date time column as index\n",
    "df\n",
    "df.reset_index(inplace = True)\n",
    "df\n",
    "\n",
    "# use aggrigate funtions\n",
    "df4[\"Age\"].mean()   # for replace value find mean\n",
    "\n",
    "#  fill null age value # replace missing values with 0\n",
    "df4[\"Age\"].fillna(df4[\"Age\"].mean(),  inplace=True)\n",
    "\n",
    "df4.dropna(inplace=True)\n",
    "\n",
    "# change the datatypes\n",
    "df4[\"SibSp\"].astype(\"float32\")\n",
    "# data types change\n",
    "df4[\"SibSp\"] = df4[\"SibSp\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['A'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_976\\2329615999.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# remove duplicates based on column 'A'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# rename columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Salary'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6815\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6816\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6818\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6820\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6946\u001b[0m         \u001b[1;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6947\u001b[0m         \u001b[1;31m# key that doesn't exist.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6948\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6949\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6950\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6953\u001b[0m             \u001b[1;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Index(['A'], dtype='object')"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# remove duplicates based on column 'A'\n",
    "df.drop_duplicates(subset=['A'], keep='first', inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns={'A': 'Age', 'B': 'Name', 'C': 'Salary'}, inplace=True)\n",
    "\n",
    "# remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#  How to remove columns containing only NaN values?\n",
    "# check which columns contain only NaN values\n",
    "columns_with_nan = df.columns[df.isnull().all()]\n",
    "\n",
    "# drop the columns containing only NaN values\n",
    "df = df.drop(columns=columns_with_nan)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Questions form dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Q. How many passengers are less than 5 years old\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df2\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# Questions form dataset\n",
    "\n",
    "#Q. How many passengers are less than 5 years old\n",
    "df2.drop([\"Unnamed: 0\"], inplace=True,axis=1)\n",
    "# unique value count  of age\n",
    "\n",
    "df2['Age'].value_counts()\n",
    "\n",
    "df['Age'] < 5\n",
    "df[df['Age'] < 5]\n",
    "\n",
    "len(df[df['Age'] < 5])\n",
    "\n",
    "#no of passenger >18\n",
    "\n",
    "len(df[df['Age'] > 18])\n",
    "\n",
    "#how many passengers are less than 18 years old\n",
    "\n",
    "len(df) - len(df[df['Age'] > 18])\n",
    "\n",
    "len(df[df['Age'] <= 18]) #missing value in age column\n",
    "\n",
    "#Q. How many passengers have paid less than avg fare\n",
    "\n",
    "df['Fare'].mean()\n",
    "df[df['Fare']<df['Fare'].mean()]\n",
    "len(df[df['Fare'] > df['Fare'].mean()])\n",
    "#How many passengers paid 0 fare\n",
    "list(df[df['Fare'] == 0].Name)\n",
    "\n",
    "#Qhow many passengers are male and female\n",
    "len(df[df['Sex'] == \"male\"])\n",
    "len(df[df['Sex'] == \"female\"])\n",
    "df['Sex'].value_counts(normalize = True)\n",
    "\n",
    "#Q how many passengers of class 1\n",
    "df[df['Pclass'] == 1]\n",
    "\n",
    "#How many passengers survived\n",
    "df[df['Survived'] == 1]\n",
    "df['Survived'].value_counts(normalize = True)\n",
    "\n",
    "#How many females paid more than avg fare\n",
    "df['Sex'] == 'female'\n",
    "df['Fare'].mean()\n",
    "df[(df['Sex'] == 'female') & (df['Fare'] > df['Fare'].mean())]\n",
    "\n",
    "#Q how many passengers are male or who paid greater than avg fare >>or\n",
    "#Qhow many male passenger paid more than avg >>and\n",
    "df[(df['Sex'] == 'male') | (df['Fare'] > df['Fare'].mean())]\n",
    "\n",
    "np.mean(df['Fare'])\n",
    "df['Fare'].mean()\n",
    "max(df['Fare'])\n",
    "min(df['Fare'])\n",
    "\n",
    "#who are the passengers who paid maximum fare\n",
    "df[df['Fare'] == max(df['Fare'])]['Name']\n",
    "\n",
    "# Q. How many passenger have parch greater than 3\n",
    "# Q. How many passenger who survived paid the maximum fare\n",
    "# Q. How many passengers who didnt survived was from class 1\n",
    "# Q. How many passengers are children(<5 years old)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447.016393</td>\n",
       "      <td>2.531876</td>\n",
       "      <td>30.626179</td>\n",
       "      <td>0.553734</td>\n",
       "      <td>0.329690</td>\n",
       "      <td>22.117887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444.368421</td>\n",
       "      <td>1.950292</td>\n",
       "      <td>28.343690</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>48.395408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId    Pclass        Age     SibSp     Parch       Fare\n",
       "Survived                                                                 \n",
       "0          447.016393  2.531876  30.626179  0.553734  0.329690  22.117887\n",
       "1          444.368421  1.950292  28.343690  0.473684  0.464912  48.395408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "df\n",
    "df1=df.copy()\n",
    "df.groupby('Survived').mean(numeric_only=True) #for recent pandas version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245412</td>\n",
       "      <td>1390</td>\n",
       "      <td>Braund, Mr. Owen HarrisAllen, Mr. William Henr...</td>\n",
       "      <td>malemalemalemalemalemalemalefemalemalefemalema...</td>\n",
       "      <td>12985.50</td>\n",
       "      <td>304</td>\n",
       "      <td>181</td>\n",
       "      <td>A/5 2117137345033087717463349909A/5. 215134708...</td>\n",
       "      <td>12142.7199</td>\n",
       "      <td>E46C23 C25 C27B30C83F G73E31A5D26C110B58 B60D2...</td>\n",
       "      <td>SSQSSSSSQSSSCSSCSCSSSSSCSQCSSSCCSCSSCSSSSSCSSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151974</td>\n",
       "      <td>667</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>femalefemalefemalefemalefemalefemalefemalefema...</td>\n",
       "      <td>8219.67</td>\n",
       "      <td>162</td>\n",
       "      <td>159</td>\n",
       "      <td>PC 17599STON/O2. 3101282113803347742237736PP 9...</td>\n",
       "      <td>16551.2294</td>\n",
       "      <td>C85C123G6C103D56A6B78D33C52B28F33C23 C25 C27D1...</td>\n",
       "      <td>CSSSCSSSSCSQSSQCQCCCQQCSSSSCSSSSSSQSSSCSSSQSCS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Pclass  \\\n",
       "Survived                        \n",
       "0              245412    1390   \n",
       "1              151974     667   \n",
       "\n",
       "                                                       Name  \\\n",
       "Survived                                                      \n",
       "0         Braund, Mr. Owen HarrisAllen, Mr. William Henr...   \n",
       "1         Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "\n",
       "                                                        Sex       Age  SibSp  \\\n",
       "Survived                                                                       \n",
       "0         malemalemalemalemalemalemalefemalemalefemalema...  12985.50    304   \n",
       "1         femalefemalefemalefemalefemalefemalefemalefema...   8219.67    162   \n",
       "\n",
       "          Parch                                             Ticket  \\\n",
       "Survived                                                             \n",
       "0           181  A/5 2117137345033087717463349909A/5. 215134708...   \n",
       "1           159  PC 17599STON/O2. 3101282113803347742237736PP 9...   \n",
       "\n",
       "                Fare                                              Cabin  \\\n",
       "Survived                                                                  \n",
       "0         12142.7199  E46C23 C25 C27B30C83F G73E31A5D26C110B58 B60D2...   \n",
       "1         16551.2294  C85C123G6C103D56A6B78D33C52B28F33C23 C25 C27D1...   \n",
       "\n",
       "                                                   Embarked  \n",
       "Survived                                                     \n",
       "0         SSQSSSSSQSSSCSSCSCSSSSSCSQCSSSCCSCSSCSSSSSCSSS...  \n",
       "1         CSSSCSSSSCSQSSQCQCCCQQCSSSSCSSSSSSQSSSCSSSQSCS...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Survived').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Survived').describe()\n",
    "df.groupby('Survived').aggregate([min, 'max', 'mean', 'median', 'count', 'var'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Sorting by column \"Population\"\n",
    "df.sort_values(by=['Fare'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_976\\1239507556.py:3: FutureWarning: The provided callable <function min at 0x000001EAB3CB9BC0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  result = df.groupby('Survived')[numeric_columns].aggregate([np.min, 'max', 'mean', 'median', 'count', 'var'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">PassengerId</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Survived</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Parch</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "      <th>var</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "      <th>var</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>count</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>891</td>\n",
       "      <td>447.016393</td>\n",
       "      <td>455.0</td>\n",
       "      <td>549</td>\n",
       "      <td>67933.454110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549</td>\n",
       "      <td>0.677602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>22.117887</td>\n",
       "      <td>10.5</td>\n",
       "      <td>549</td>\n",
       "      <td>985.219509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>890</td>\n",
       "      <td>444.368421</td>\n",
       "      <td>439.5</td>\n",
       "      <td>342</td>\n",
       "      <td>63684.984102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>342</td>\n",
       "      <td>0.595539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>48.395408</td>\n",
       "      <td>26.0</td>\n",
       "      <td>342</td>\n",
       "      <td>4435.160158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PassengerId                                             Survived      \\\n",
       "                 min  max        mean median count           var      min max   \n",
       "Survived                                                                        \n",
       "0                  1  891  447.016393  455.0   549  67933.454110        0   0   \n",
       "1                  2  890  444.368421  439.5   342  63684.984102        1   1   \n",
       "\n",
       "                      ...     Parch                        Fare            \\\n",
       "         mean median  ...      mean median count       var  min       max   \n",
       "Survived              ...                                                   \n",
       "0         0.0    0.0  ...  0.329690    0.0   549  0.677602  0.0  263.0000   \n",
       "1         1.0    1.0  ...  0.464912    0.0   342  0.595539  0.0  512.3292   \n",
       "\n",
       "                                               \n",
       "               mean median count          var  \n",
       "Survived                                       \n",
       "0         22.117887   10.5   549   985.219509  \n",
       "1         48.395408   26.0   342  4435.160158  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "result = df.groupby('Survived')[numeric_columns].aggregate([np.min, 'max', 'mean', 'median', 'count', 'var'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q what is the average fare paid by people who survived?\n",
    "#groupby >> https://www.w3resource.com/python-exercises/pandas/groupby/index.php\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "df\n",
    "df1=df.copy()\n",
    "df.groupby('Survived').mean(numeric_only=True) #for recent pandas version\n",
    "\n",
    "df.groupby('Survived').mean()\n",
    "df.groupby('Survived').min()\n",
    "df.groupby('Survived').sum()\n",
    "df.groupby('Survived').mean(numeric_only=True)\n",
    "df.groupby('Survived').mean()\n",
    "df.groupby('Survived').describe()\n",
    "df.groupby('Survived').aggregate([min, 'max', 'mean', 'median', 'count', np.std, 'var'])\n",
    "\n",
    "#groupby with two columns\n",
    "#Q. Total people for each sex, pclass\n",
    "df1.groupby(['Sex', 'Pclass'])['Survived'].sum()\n",
    "\n",
    "#To convert the result to dataframe\n",
    "df.groupby(['Sex', 'Pclass'])['Survived'].sum().to_frame()\n",
    "\n",
    "df.groupby(['Sex', 'Pclass'])['Survived'].sum().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby('Pclass').sum(numeric_only = True)\n",
    "df1\n",
    "df1.T\n",
    "df1.transpose()\n",
    "\n",
    "df_1 = df[['Name', 'Sex', 'Age']][0:5]\n",
    "df_1\n",
    "df_2 =  df[['Name', 'Sex', 'Age']][5:10]\n",
    "df_2.reset_index(drop = True, inplace = True)\n",
    "result = pd.concat([df_1, df_2], axis = 0)\n",
    "result\n",
    "pd.concat([df_1, df_2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat\n",
    "#apply\n",
    "df['len_name'] = df['Name'].apply(len)\n",
    "\n",
    "df\n",
    "# convert dollor in rupee\n",
    "def convert(x):\n",
    "    return x*90\n",
    "\n",
    "df['Fare_1'] = df['Fare'].apply(convert)\n",
    "\n",
    "#  ============================\n",
    "def create_flag(x):\n",
    "    if x < 10:\n",
    "        return \"cheap\"\n",
    "    elif x >= 10 and x <20:\n",
    "          return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "df[\"flag_fare\"] = df['Fare'].apply(create_flag)\n",
    "\n",
    "df\n",
    "\n",
    "df1.set_index('c', inplace = True)\n",
    "df.sort_values(by = \"Fare\")\n",
    "\n",
    "# # Sorting by column \"Population\"\n",
    "df.sort_values(by=['Population'], ascending=False)\n",
    "# Sorting by columns \"Country\" and then \"Continent\"\n",
    "df.sort_values(by=['Country', 'Continent'])\n",
    "# Sorting by columns \"Country\" in descending\n",
    "# order and then \"Continent\" in ascending order\n",
    "df.sort_values(by=['Country', 'Continent'],\n",
    "               ascending=[False, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date time\n",
    "df = pd.DataFrame({\"date\": ['2024-02-08', '2024-02-09', '2024-02-10']})\n",
    "df\n",
    "df.dtypes\n",
    "df['updated_date'] = pd.to_datetime(df['date'])\n",
    "df\n",
    "df.dtypes\n",
    "df['month'] = df['updated_date'].dt.month\n",
    "df\n",
    "df['year'] = df['updated_date'].dt.year\n",
    "df\n",
    "df['day'] = df['updated_date'].dt.day\n",
    "df\n",
    "\n",
    "\n",
    "# Convert to date:datatype\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframe is dictionary\n",
    "d = {\"key1\": [2, 3, 4, 5],\n",
    "    \"key2\": [4, 5, 6, 7],\n",
    "    \"key3\": [2, 3, 4, 5]}\n",
    "\n",
    "d\n",
    "pd.DataFrame(d)\n",
    "#make dataframe is dictionary\n",
    "d = {\"key1\": (2, 3, 4, 5),\n",
    "    \"key2\": (4, 5, 6, 7),\n",
    "    \"key3\": (2, 3, 4, 5)}\n",
    "\n",
    "pd.DataFrame(d)\n",
    "pd.merge(df1, df2, how = 'left')\n",
    "df1\n",
    "#merge\n",
    "pd.merge(df1, df2, how = 'right')\n",
    "pd.merge(df1, df2, how = 'left', left_on = 'key2', right_on = 'key4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useful for categorizing passengers\n",
    "# by age groups, which can be helpful for further analysis (e.g., checking survival rates by age group).\n",
    "df['Age_Group'] = pd.cut(df['Age'], \n",
    "                         bins=[0, 12, 18, 60, 80], \n",
    "                         labels=['Child', 'Teen', 'Adult', 'Senior'])\n",
    "# pd.cut() function, which segments the data into bins (ranges) and labels those\n",
    "# bins with categorical names (e.g., 'Child', 'Teen', 'Adult', 'Senior') based on the values in the Age column.\n",
    "\n",
    "\n",
    "# Further Analysis:\n",
    "# You can now analyze data based on these groups.\n",
    "df['Age_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a detailed explanation of each of the provided data manipulation techniques in Pandas:\n",
    "\n",
    "### 1. **Pivot the DataFrame**\n",
    "\n",
    "The `pivot_table()` function reshapes the data by summarizing it. It allows you to group by one or more columns and calculate aggregate values (e.g., mean, sum).\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "pivot_table = df.pivot_table(values='Fare', index='Pclass', columns='Sex', aggfunc='mean')\n",
    "```\n",
    "\n",
    "- **`values='Fare'`**: The column we want to aggregate.\n",
    "- **`index='Pclass'`**: Rows will be grouped by the `Pclass` (Passenger Class) column.\n",
    "- **`columns='Sex'`**: The unique values in the `Sex` column will become the columns in the resulting table (i.e., Male, Female).\n",
    "- **`aggfunc='mean'`**: The aggregation function, in this case, calculates the **mean** fare for each combination of `Pclass` and `Sex`.\n",
    "\n",
    "#### Example Output:\n",
    "| Sex    | Female | Male |\n",
    "|--------|--------|------|\n",
    "| Pclass |        |      |\n",
    "| 1      | 100.0  | 80.0 |\n",
    "| 2      | 40.0   | 20.0 |\n",
    "| 3      | 10.0   | 5.0  |\n",
    "\n",
    "This gives the **mean fare** for each combination of **Passenger Class (`Pclass`)** and **Sex**.\n",
    "\n",
    "### 2. **Melt the DataFrame (Unpivot)**\n",
    "\n",
    "The `pd.melt()` function reshapes the DataFrame from wide format to long format (unpivot). It is useful when you want to convert multiple columns into rows.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "df_melted = pd.melt(df, id_vars=['Pclass'], value_vars=['Age', 'Fare'])\n",
    "```\n",
    "\n",
    "- **`id_vars=['Pclass']`**: These columns are kept intact.\n",
    "- **`value_vars=['Age', 'Fare']`**: These columns will be \"melted\" into one single column of values, creating a long-form DataFrame.\n",
    "\n",
    "#### Example Output:\n",
    "\n",
    "| Pclass | variable | value |\n",
    "|--------|----------|-------|\n",
    "| 1      | Age      | 22    |\n",
    "| 1      | Fare     | 71.0  |\n",
    "| 2      | Age      | 26    |\n",
    "| 2      | Fare     | 12.0  |\n",
    "\n",
    "The new DataFrame is in a **long** format, with each row representing a single observation for `Age` or `Fare`.\n",
    "\n",
    "### 3. **Group by 'Pclass' and Calculate Mean Fare**\n",
    "\n",
    "The `groupby()` function groups the DataFrame by one or more columns and allows you to apply aggregation functions like `mean`, `sum`, etc.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "df_grouped = df.groupby('Pclass')['Fare'].mean()\n",
    "```\n",
    "\n",
    "- **`groupby('Pclass')`**: Groups the data by `Pclass` (Passenger Class).\n",
    "- **`['Fare']`**: Selects the `Fare` column.\n",
    "- **`.mean()`**: Calculates the **mean fare** for each group.\n",
    "\n",
    "#### Example Output:\n",
    "\n",
    "| Pclass | Fare  |\n",
    "|--------|-------|\n",
    "| 1      | 84.0  |\n",
    "| 2      | 20.0  |\n",
    "| 3      | 13.0  |\n",
    "\n",
    "This shows the **mean fare** paid by passengers in each class (`Pclass`).\n",
    "\n",
    "### 4. **Sort by 'Age' Column**\n",
    "\n",
    "The `sort_values()` function sorts the DataFrame by one or more columns.\n",
    "\n",
    "#### Syntax:\n",
    "```python\n",
    "df_sorted = df.sort_values(by='Age', ascending=False)\n",
    "```\n",
    "\n",
    "- **`by='Age'`**: Specifies the column by which to sort the DataFrame (here, `Age`).\n",
    "- **`ascending=False`**: Sorts the data in **descending** order, so the oldest passengers appear first.\n",
    "\n",
    "#### Example Output:\n",
    "\n",
    "| Name  | Age | Fare |\n",
    "|-------|-----|------|\n",
    "| John  | 80  | 100  |\n",
    "| Jane  | 60  | 50   |\n",
    "| Mark  | 45  | 20   |\n",
    "\n",
    "This sorts the DataFrame by **Age** in descending order, so the oldest passengers are listed first.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "- **Pivot Table**: Reshapes the DataFrame by summarizing values based on rows and columns.\n",
    "- **Melt**: Unpivots the DataFrame, converting wide format into long format.\n",
    "- **GroupBy**: Groups the data by one or more columns and applies aggregation functions (like `mean`).\n",
    "- **Sort**: Sorts the DataFrame by specified columns in either ascending or descending order.\n",
    "\n",
    "These operations are fundamental for transforming and analyzing data in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Transformation\n",
    "# Pivot the DataFrame\n",
    "pivot_table = df.pivot_table(values='Fare', index='Pclass', columns='Sex', aggfunc='mean')\n",
    "\n",
    "# Melt the DataFrame (unpivot)\n",
    "df_melted = pd.melt(df, id_vars=['Pclass'], value_vars=['Age', 'Fare'])\n",
    "\n",
    "# Group by 'Pclass' and calculate mean fare\n",
    "df_grouped = df.groupby('Pclass')['Fare'].mean()\n",
    "\n",
    "# Sort by 'Age' column\n",
    "df_sorted = df.sort_values(by='Age', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "d = pd.Series([1, 2, 8, 4, 5, 6])\n",
    "d.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/user_guide/visualization.html\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
