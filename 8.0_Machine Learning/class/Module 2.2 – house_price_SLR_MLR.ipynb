{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9G6Bn4OPhpB"
   },
   "source": [
    "# Implement The Linear Regression ML Models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "df = pd.read_csv(r\"Cleaned_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Building\n",
    "# 1. select the numerical columns\n",
    "# 2. seprate the x and y\n",
    "# 2.1 split the data into training testing\n",
    "# 3. load the algorithms and create the object of algoritms\n",
    "# 4. train the model --> find the pattern value from data\n",
    "# 5. test then model/predict\n",
    "# 6. Evaluate/accuracy the model\n",
    "\n",
    "# 7. fine tuning the model(for improve accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. with only numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. select the numerical columns\n",
    "df = df.drop(columns=[\"area_type\",\"location\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. seprate the x and y\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. split the data into training testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. load the algorithms and create the object of algoritms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. train the model --> find the pattern value from data\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffecient, intercept\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2score for check variance\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. with categorical and numerical columns with pipeline Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebH5D2SMbHah"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotStandardScalerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1762234733302,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "Za_6qesN0cCt",
    "outputId": "e55b590c-618f-481f-e8e4-9e12a17e3819"
   },
   "outputs": [],
   "source": [
    "# task 1 transform applying\n",
    "# columns transform\n",
    "columns_trans = ColumnTransformer(\n",
    "    [('onehot_location', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), ['location']),\n",
    "     ('onehot_area_type', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), [\"area_type\"]),\n",
    "     ('scaler', StandardScaler(), [\"total_sqft\", \"bath\"]),\n",
    "\n",
    "     ],\n",
    "    remainder='passthrough')\n",
    "# task 2 model a\n",
    "# model\n",
    "lr = LinearRegression()\n",
    "\n",
    "#pipeline\n",
    "pipe = make_pipeline(columns_trans,lr)\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWCQarpvwQQB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([155.50296562,  92.4472685 , 102.94028748, ..., 169.02451684,\n",
       "       106.82742062, 128.69041058])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z48yfF6owpF5"
   },
   "source": [
    "# Performance Matrix\n",
    "Measuring Performance metrics-Lost and Cost Function (MAE,MSE,RMSE,R2 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1762225603914,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "tF-foT1jwsU9",
    "outputId": "47f33f70-ae73-4f70-c3a8-47305ebca191"
   },
   "outputs": [],
   "source": [
    "# cost functions --> calculate erros\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,root_mean_squared_error\n",
    "\n",
    "print(\"MAE:\",mean_absolute_error(y_test,y_pred))\n",
    "print(\"MSE:\",mean_squared_error(y_test,y_pred))\n",
    "print(\"RMSE:\",root_mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1762225603944,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "SwJQVM2zwYbi",
    "outputId": "b2d7eb86-c133-450d-acdd-9f20536d6c4f"
   },
   "outputs": [],
   "source": [
    "# Regression Performance check using r2_score ,and Adjusted r2 score\n",
    "from sklearn.metrics import r2_score\n",
    "r_squared = r2_score(y_test,y_pred)\n",
    "r_squared\n",
    "\n",
    "# https://benjaminobi.medium.com/what-really-is-r2-score-in-linear-regression-20cafdf5b87c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXgJv8xZwnFX"
   },
   "outputs": [],
   "source": [
    "# adjusted_r2\n",
    "n_samples = df.shape[0]\n",
    "n_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1762225604041,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "ftGG4eK4w3uF",
    "outputId": "7eba3024-da13-4945-eebf-3ac5615e1664"
   },
   "outputs": [],
   "source": [
    "adjusted_r2 = 1 - (1 - r_squared) * (n_samples - 1) / (n_samples - n_features - 1)\n",
    "adjusted_r2\n",
    "# https://www.shiksha.com/online-courses/articles/adjusted-r-squared/\n",
    "# https://benjaminobi.medium.com/what-really-is-r2-score-in-linear-regression-20cafdf5b87c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaifYfjg9Tf-"
   },
   "outputs": [],
   "source": [
    "# save the movel for future use\n",
    "import pickle\n",
    "pickle.dump(pipe,open(\"model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxmkpgmg9Y1o"
   },
   "outputs": [],
   "source": [
    "locations = df[\"location\"].unique()\n",
    "# save the data for future use\n",
    "pickle.dump(locations, open(\"locations.pkl\",\"wb\"))\n",
    "\n",
    "# carpet area\n",
    "carpet_area = df[\"area_type\"].unique()\n",
    "# save the data for future use\n",
    "pickle.dump(carpet_area, open(\"area_type.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnJSLbWR9equ"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "pipe = pickle.load(open(\"model.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PVAdB-w9irL"
   },
   "outputs": [],
   "source": [
    "# # load the model\n",
    "# pipe = pickle.load(open(\"model.pkl\",\"rb\"))\n",
    "\n",
    "# # take input from user\n",
    "# location = input(\"Enter location: \")\n",
    "# area_type = input(\"Enter area type: \")\n",
    "# total_sqft = float(input(\"Enter total square feet: \"))\n",
    "# bath = float(input(\"Enter number of bathrooms: \"))\n",
    "# bhk = int(input(\"Enter number of bedrooms (BHK): \"))\n",
    "# balcony = int(input(\"Enter number of balcony: \"))\n",
    "\n",
    "# # Create a DataFrame from user input\n",
    "# user_input = pd.DataFrame([[location, area_type, total_sqft, bath, bhk,balcony]],\n",
    "#                           columns=['location', 'area_type', 'total_sqft', 'bath', 'bhk',\"balcony\"])\n",
    "\n",
    "# # Predict the price\n",
    "# predicted_price = pipe.predict(user_input)\n",
    "\n",
    "# print(f\"The predicted price is: {predicted_price[0]:.2f} Lakhs\")\n",
    "# # Electronic City Phase II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Streamlit app code to app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Dropdown meanu use\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ----------------------\n",
    "# Load Model & Dropdown Data\n",
    "# ----------------------\n",
    "pipe = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "locations = pickle.load(open(\"locations.pkl\", \"rb\"))\n",
    "area_types = pickle.load(open(\"area_type.pkl\", \"rb\"))\n",
    "\n",
    "# ----------------------\n",
    "# Streamlit App\n",
    "# ----------------------\n",
    "st.set_page_config(page_title=\"House Price Prediction\", layout=\"centered\")\n",
    "st.title(\"ðŸ  House Price Prediction App\")\n",
    "st.write(\"Enter property details below to get an estimated price (in Lakhs).\")\n",
    "\n",
    "# User inputs\n",
    "location = st.selectbox(\"Select Location\", locations)\n",
    "area_type = st.selectbox(\"Select Area Type\", area_types)\n",
    "total_sqft = st.number_input(\"Enter Total Square Feet\", min_value=100.0, step=10.0)\n",
    "bath = st.number_input(\"Enter Number of Bathrooms\", min_value=1.0, step=1.0)\n",
    "bhk = st.number_input(\"Enter Number of Bedrooms (BHK)\", min_value=1, step=1)\n",
    "balcony = st.number_input(\"Enter number of Balcony: \", min_value=0)\n",
    "\n",
    "\n",
    "# Prediction button\n",
    "if st.button(\"Predict Price\"):\n",
    "    # Create DataFrame from inputs\n",
    "    user_input = pd.DataFrame([[location, area_type, total_sqft, bath, bhk,balcony]],\n",
    "                          columns=['location', 'area_type', 'total_sqft', 'bath', 'bhk','balcony'])\n",
    "\n",
    "    # Make prediction\n",
    "    predicted_price = pipe.predict(user_input)[0]\n",
    "\n",
    "    st.success(f\"ðŸ’° Estimated Price: **{predicted_price:.2f} Lakhs**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps\n",
    "# 1. take all pkl files in one folder after training\n",
    "# 2. create aap.py --> insert all code\n",
    "# 3. create requirements.txt --> write all library which is needed to run project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model improvement check relationship \n",
    "# and change models to improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression models --> liner---> LinearRegression, ridge lasso, SGDRegressor ,\n",
    "#       non-linear -->(Decision tree) DecisionTreeRegressor, RandomForestRegressor,\n",
    "#       ensembles models --> GradientBoostingRegressor , support_vector_regression\n",
    "\n",
    "# classifications ---> Logistic regression(linear)\n",
    "# (non-linear) SVM(SVC), KNN,naive bayes, Decision tree(classifier),RandomForestClassifer,\n",
    "#       ensembles models --> all\n",
    "\n",
    "\n",
    "\n",
    "# Deeplearning --> non-linear -Neural Network (only change in architecture for diffrent work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZOaVspqr7C3"
   },
   "source": [
    "### Topics\n",
    "- Assumptions of Machine Learning(all ready done)\n",
    "- Simple linear regression\n",
    "- multiple linear regression\n",
    "- variant of LR for RIDGE, LASSO ,ELASTICNET\n",
    "- Measuring Performance metrics-Lost and Cost Function Model Evaluation Metrics ( MSE, MAE, RMSE)(RÂ²-score, Adjusted RÂ²-score)\n",
    "\n",
    "variant of Linear models\n",
    "- Polynomial Regression\n",
    "- Linear Regression with OLS\n",
    "- Linear Regression with SGD\n",
    "\n",
    "- Under fitting and Overfitting\n",
    "- Regularization ,Lasso & Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEvycIun_XUj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtK5PwuR_YLS"
   },
   "source": [
    "# 1. assumption In Linear Regression\n",
    "\n",
    "- Homoscedasticity\n",
    "\n",
    "The variance of residuals should be approximately equal for all predicted values of the dependent variable.\n",
    "\n",
    "- Normality - Errors are normally distributed\n",
    "\n",
    "The residuals should be normally distributed.Linear relationship\n",
    "\n",
    "There is a linear relationship between the dependent and independent variables\n",
    "\n",
    "The error terms are normally distributed and the data do not contain outliers\n",
    "\n",
    "- Independence of errors\n",
    "\n",
    "The residual errors are independent of each other.\n",
    "\n",
    "- No or low multicollinearity\n",
    "\n",
    "There is no or little collinearity among input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zw7Z7D8L-Ghs"
   },
   "source": [
    "#\n",
    "https://www.geeksforgeeks.org/machine-learning/assumptions-of-linear-regression/\n",
    "https://www.kdnuggets.com/2021/02/machine-learning-assumptions.html\n",
    "\n",
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20241025105428904464/Assumptions-of-Linear-Regression.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgALXOr-uJHd"
   },
   "source": [
    "<!-- #### MultiColiniarity\n",
    "(optional)\n",
    "\n",
    "- What it is\n",
    "\n",
    "Multicollinearity occurs when independent variables are correlated, which can make it difficult to estimate each variable's relationship with the outcome variable.\n",
    "\n",
    "- Why it's a problem\n",
    "\n",
    "Multicollinearity can negatively impact model predictions on unseen data, and can make it difficult to explain the model's behavior.\n",
    "\n",
    "- How to detect it\n",
    "\n",
    "A correlation matrix can help identify multicollinearity, but a heatmap of correlations can be more intuitive. A variance inflation factor (VIF) can also be used to measure the amount of multicollinearity.\n",
    "\n",
    "- How to address it\n",
    "\n",
    "If multicollinearity is detected, it can be addressed by using a VIF to identify the correlated variables, and then removing or transforming those variables\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['Price'] = data.target\n",
    "\n",
    "\n",
    "#multicollinearity>> when one feature is explained by all other features\n",
    "#when two features>> correlation\n",
    "#more than two features>> vif, clustermap\n",
    "\n",
    "sns.heatmap(df.corr(), annot = True, vmin = -1, vmax = 1)\n",
    "\n",
    "#clustermap table shows group(cluster ) relationship\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.clustermap(df.corr(), vmin = -1, vmax =1, annot = True)\n",
    "\n",
    "### What is the function of variance_inflation_factor?\n",
    "Variance Inflation Factor (VIF)\n",
    "\n",
    "A variance inflation factor (VIF) is a measure of the amount of multicollinearity in regression analysis. Multicollinearity exists when there is a correlation between multiple independent variables in a multiple regression model. This can adversely affect the regression results.\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['Feature'] = df.columns\n",
    "vif\n",
    "\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "\n",
    "df1 = df.copy()\n",
    "\n",
    "df1.drop(\"Longitude\", axis=1, inplace=True)\n",
    "df1\n",
    "vif = pd.DataFrame()\n",
    "vif['Feature'] = df1.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
    "\n",
    "vif\n",
    "\n",
    "df1.drop(\"AveRooms\", axis=1, inplace=True)\n",
    "vif = pd.DataFrame()\n",
    "vif['Feature'] = df1.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
    "\n",
    "df1.drop(\"Latitude\", axis=1, inplace=True)\n",
    "vif = pd.DataFrame()\n",
    "vif['Feature'] = df1.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
    "\n",
    "Recursive Feature Elimination (RFE) is a feature selection method that iteratively removes features and trains a model on the remaining ones, evaluating its performance at each step. By repeatedly eliminating the least important features, RFE identifies the features that contribute most to the model's accuracy. It's a valuable tool for simplifying models and improving their efficiency.\n",
    "\n",
    "#RFE >> recruseive feature elimination\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator = LinearRegression(), n_features_to_select=6)\n",
    "\n",
    "rfe.fit(X, y)\n",
    "\n",
    "rfe.predict(X)\n",
    "\n",
    "rfe.support_\n",
    "\n",
    "X.columns\n",
    "\n",
    "rfe.ranking_\n",
    "\n",
    " -->\n",
    "rivision codes inside this markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1eJJBsCMSZd"
   },
   "source": [
    "## 2. Simple Linear Regression\n",
    "\n",
    "- y=mx +c\n",
    "single feature use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl-p7QfcMs9r"
   },
   "source": [
    "## 3. Multiple Linear Regression\n",
    "\n",
    "- multiple  feature/X use\n",
    "- y =M1x1 +M2x2 + M3x3 + MnXn +c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "494ca2f9"
   },
   "source": [
    "## 4. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1762225605257,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "2f292ae7",
    "outputId": "7729e751-cbd1-4771-99b5-2e4efe9d7716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 11184.5695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "# pipe_lr = make_pipeline(columns_trans, lr)\n",
    "pipe_ridge = make_pipeline(columns_trans, Ridge(alpha=1.0))\n",
    "\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = pipe_ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "\n",
    "print(f\"Ridge Regression MSE: {mse_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1762225606759,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "fbbc394a",
    "outputId": "f860a94d-dbd2-49f6-dd95-b6829b291c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression MSE: 11665.5722\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "pipe_lasso = make_pipeline(columns_trans, Lasso(alpha=0.1))\n",
    "\n",
    "\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = pipe_lasso.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"Lasso Regression MSE: {mse_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1762225607360,
     "user": {
      "displayName": "Sahil",
      "userId": "02943187861823395646"
     },
     "user_tz": -330
    },
    "id": "1c09e434",
    "outputId": "d3d02997-4a2d-4bc7-c165-4e75140f1939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regression MSE: 12471.4969\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net Regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "pipe_elastic_net = make_pipeline(columns_trans, ElasticNet(alpha=0.1, l1_ratio=0.5))\n",
    "\n",
    "\n",
    "pipe_elastic_net.fit(X_train, y_train)\n",
    "y_pred_elastic_net = pipe_elastic_net.predict(X_test)\n",
    "mse_elastic_net = mean_squared_error(y_test, y_pred_elastic_net)\n",
    "\n",
    "print(f\"Elastic Net Regression MSE: {mse_elastic_net:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/6Rd6kDRgG11fqSFbFkD+",
   "mount_file_id": "1KD5WVe09fjG_Eg5qVEYkJZ3q8bdNuwH5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
