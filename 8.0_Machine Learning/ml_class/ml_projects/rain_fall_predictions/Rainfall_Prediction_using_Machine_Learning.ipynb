{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEItIK33hRBD"
      },
      "source": [
        "**Importing the dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm6EE3X8iSAz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "\n",
        "# import all classifications models \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier ,GradientBoostingClassifier\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install xgboost\n",
        "# !pip install lightgbm\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAKV5UtHkAcj"
      },
      "source": [
        "**Data Collection and Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQVgaeE3jIEd"
      },
      "outputs": [],
      "source": [
        "# laod the dataset to a pandas dataframe\n",
        "# data = pd.read_csv(\"Rainfall.csv\")\n",
        "\n",
        "data = pd.read_csv(r'https://media.githubusercontent.com/media/shahil04/ds_materials/refs/heads/main/8.0_Machine%20Learning/ml_class/ml_projects/rain_fall_predictions/Rainfall.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X09thXyakP0C",
        "outputId": "8d2eed14-0c28-4d69-8083-b4c3021dd9be"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIiIWhW_kSJu",
        "outputId": "307ec7a6-0ac4-4760-a75f-61d742743bce"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2hfNHtXPkU4_",
        "outputId": "f00f8c8b-f40a-4120-df21-4ccccc7c0952"
      },
      "outputs": [],
      "source": [
        "# cheack null \n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VU3q7vaHkZzT",
        "outputId": "e69c4b94-cd8a-4780-b1c7-7a9d783cd92e"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaKQzgywlp6R",
        "outputId": "288f3028-4100-4b1a-bb47-d71ea31edd2e"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVEv2BKClLZY"
      },
      "outputs": [],
      "source": [
        "# remove extra  spaces in all columns\n",
        "data.columns = data.columns.str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLf3gNYElwjw",
        "outputId": "c051ea10-d235-4cb2-b71f-9719d16089ec"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEjl4K7lzLJ",
        "outputId": "268bd8a7-9309-4492-e6ee-8bd119f8af88"
      },
      "outputs": [],
      "source": [
        "print(\"Data Info:\")\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()\n",
        "# show the stating data where day are for jan month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"day\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dF7Hh4El1KY"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=[\"day\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GGKhxQmLmByn",
        "outputId": "352ce6d9-c862-461e-8479-412780ef062a"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_IRIu7pmCp4",
        "outputId": "743caf8e-74a9-4510-8980-96c158893e0b"
      },
      "outputs": [],
      "source": [
        "# checking the number of missing values\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSOIPIyWnwKu"
      },
      "outputs": [],
      "source": [
        "# converting the yes & no to 1 and 0 respectively\n",
        "data[\"rainfall\"] = data[\"rainfall\"].map({\"yes\": 1, \"no\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C2V8TpLxn_5Z",
        "outputId": "a7062126-349b-420e-dc0a-ff43c686f8d0"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zit4FaWyoHIY"
      },
      "source": [
        "**Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87hXdZaNoBh4",
        "outputId": "ecdf5c08-2fa1-4f31-9f69-bd0d4a17cf27"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCEC7tmZoNXd"
      },
      "outputs": [],
      "source": [
        "# setting plot style for all the plots\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "GBZvgcgNoZzE",
        "outputId": "5dfac88a-7d09-452c-fb07-41aa22a5af98"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmoVcnAQruf_",
        "outputId": "91ff58ef-57f8-4ad0-8a65-a68572002881"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "XKf1029Qoeqa",
        "outputId": "0be42167-b92e-4459-ff3d-c139ada54a6a"
      },
      "outputs": [],
      "source": [
        "# check the distributions using histograms\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(['pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity','cloud', 'sunshine', 'windspeed'], 1):\n",
        "  plt.subplot(3, 3, i)\n",
        "  sns.histplot(data[column], kde=True)\n",
        "  plt.title(f\"Distribution of {column}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ljGkqq0Ss2a8",
        "outputId": "32a6ca77-fffa-4724-a8e6-e3516bfab502"
      },
      "outputs": [],
      "source": [
        "# show the label data Y count\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=\"rainfall\", data=data)\n",
        "plt.title(\"Distribution of Rainfall\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "nOZiTVk6uDHN",
        "outputId": "e34441ee-72b8-491b-b593-b87e64e74ed9"
      },
      "outputs": [],
      "source": [
        "# correlation matrix --> for check the relationship bw x(features ) and y(label)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "kgpXLXcwue3D",
        "outputId": "612d3624-f1fc-49b8-b277-0c689aa64144"
      },
      "outputs": [],
      "source": [
        "# check the outliers  \n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, column in enumerate(['pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity','cloud', 'sunshine', 'windspeed'], 1):\n",
        "  plt.subplot(3, 3, i)\n",
        "  sns.boxplot(data[column])\n",
        "  plt.title(f\"Boxplot of {column}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove outliers\n",
        "data[data['pressure']>1030]\n",
        "\n",
        "data = data[data['pressure']<1030]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ic4pF8cwBMH"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNnu6UwAvf72"
      },
      "outputs": [],
      "source": [
        "# drop highly correlated column bewtween x feature --> colinearity\n",
        "data = data.drop(columns=['maxtemp', 'temparature', 'mintemp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RLMEus8ZwSBH",
        "outputId": "5ca436ee-f320-4c79-8963-22718908f1fb"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvaWRILVzUy7",
        "outputId": "fad7b447-3269-4553-c3b4-ce3a254ae97f"
      },
      "outputs": [],
      "source": [
        "print(data[\"rainfall\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqHvahpXwSx9"
      },
      "outputs": [],
      "source": [
        "# separate majority and minority class\n",
        "df_majority = data[data[\"rainfall\"] == 1]\n",
        "\n",
        "df_minority = data[data[\"rainfall\"] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIcP4uw3zz4j",
        "outputId": "88bcafb3-a9f8-48a3-8f41-ace64e9bf733"
      },
      "outputs": [],
      "source": [
        "print(df_majority.shape)\n",
        "print(df_minority.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laxjXe8jz5Eo"
      },
      "outputs": [],
      "source": [
        "# downsample majority class to match minority count\n",
        "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIJKpKMt0V2f",
        "outputId": "adde9cc8-f1a5-4453-f460-eace9a791e23"
      },
      "outputs": [],
      "source": [
        "df_majority_downsampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcMARKcQ0YbA"
      },
      "outputs": [],
      "source": [
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TulqUXVb0jsg",
        "outputId": "3025c5bf-8f00-46f5-8514-7f79eaf918f5"
      },
      "outputs": [],
      "source": [
        "df_downsampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df_downsampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UHWgAd0R0lx_",
        "outputId": "f09735da-bff3-45ef-fb71-12cbcdb9b58c"
      },
      "outputs": [],
      "source": [
        "df_downsampled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwvmE4Gf0p5K"
      },
      "outputs": [],
      "source": [
        "# shuffle the final dataframe\n",
        "df_downsampled = df_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dBFm9t5G06tO",
        "outputId": "6bce0c81-e876-4970-eccc-6113b44cb114"
      },
      "outputs": [],
      "source": [
        "df_downsampled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "EMK-Lfiw08lg",
        "outputId": "3f7225a5-3510-4395-accd-fe0d4082404f"
      },
      "outputs": [],
      "source": [
        "df_downsampled[\"rainfall\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2v1OgbP1Pp3"
      },
      "outputs": [],
      "source": [
        "# split features and target as X and y\n",
        "X = df_downsampled.drop(columns=[\"rainfall\"])\n",
        "y = df_downsampled[\"rainfall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8qcP1Hl1bZB",
        "outputId": "09b72628-271c-4263-8896-f8c56a556974"
      },
      "outputs": [],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ZSSjt51egt",
        "outputId": "b02f0d9b-c278-45be-80ca-98a6f956d6cd"
      },
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ZdLLo60_xw"
      },
      "outputs": [],
      "source": [
        "# splitting the data into training data and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIq-XcGb3XHI"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWZRKC9Q20Jm"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid_rf = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"max_depth\": [None, 10, 20, 30],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "rt-f_FBu3Tax",
        "outputId": "f525177d-28dc-45e4-9346-bbdf75cfa2ec"
      },
      "outputs": [],
      "source": [
        "# Hypertuning using GridSearchCV\n",
        "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=2, n_jobs=-1, verbose=3)\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aVDOZZ938cM",
        "outputId": "34806e16-42f0-463f-8e34-1d7c58dc3bee"
      },
      "outputs": [],
      "source": [
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "print(\"best parameters for Random Forest:\", grid_search_rf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99CaTZLp4oWV"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sj1BJbm4eUZ",
        "outputId": "b7e3f50e-2e14-4194-9581-e4f3ef4b67be"
      },
      "outputs": [],
      "source": [
        "cv_scores = cross_val_score(best_rf_model, X_train, y_train, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(cv_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW5LcHnc5ZvK",
        "outputId": "ea7101f3-e6b9-4701-9e80-b7c5084847ad"
      },
      "outputs": [],
      "source": [
        "# test set performance\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "print(\"Test set Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Test set Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### apply all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'lr': LogisticRegression(),\n",
        "    'svc': SVC(),\n",
        "    'knn': KNeighborsClassifier(),\n",
        "    'nb': GaussianNB(),\n",
        "    'dt': DecisionTreeClassifier(max_depth=4),\n",
        "    'rf': RandomForestClassifier(),\n",
        "    'ada': AdaBoostClassifier(),\n",
        "    'gb': GradientBoostingClassifier(),\n",
        "    'xgb': XGBClassifier(),\n",
        "    'lgbm': LGBMClassifier()\n",
        "}\n",
        "\n",
        "accuracy_scores = {}\n",
        "for  name, model in models.items():\n",
        "  print(name, model)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  # print(name, accuracy_score(y_test,y_pred))\n",
        "  accuracy_scores[name] = accuracy_score(y_test,y_pred)\n",
        "  print('===================================')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show all \n",
        "accuracy_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now  use best models without tuning\n",
        "\n",
        "best_model = DecisionTreeClassifier(max_depth=4)\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tuning \n",
        "\n",
        "# Parameter grids for each model\n",
        "param_grids = {\n",
        "    'lr': {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'solver': ['liblinear']\n",
        "    },\n",
        "    'svc': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': ['scale', 'auto'],\n",
        "        'kernel': ['rbf', 'poly']\n",
        "    },\n",
        "    'knn': {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'nb': {\n",
        "        # GaussianNB has no major hyperparameters\n",
        "        'var_smoothing': [1e-09, 1e-08, 1e-07]\n",
        "    },\n",
        "    'dt': {\n",
        "        'max_depth': [2, 4, 6, 8],\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    },\n",
        "    'rf': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [4, 6, 8, None],\n",
        "        'min_samples_split': [2, 5]\n",
        "    },\n",
        "    'ada': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 1]\n",
        "    },\n",
        "    'gb': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 4, 5]\n",
        "    },\n",
        "    'xgb': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 4, 5],\n",
        "        'subsample': [0.8, 1]\n",
        "    },\n",
        "    'lgbm': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'num_leaves': [31, 50, 70]\n",
        "    }\n",
        "}\n",
        "\n",
        "# To store results\n",
        "best_models = {}\n",
        "best_scores = {}\n",
        "best_params = {}\n",
        "\n",
        "# LOOP grid search for each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüîç Running GridSearchCV for: {name.upper()}\")\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grids[name],\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_models[name] = grid.best_estimator_\n",
        "    best_scores[name] = grid.best_score_\n",
        "    best_params[name] = grid.best_params_\n",
        "\n",
        "    print(f\"‚û° Best Score: {grid.best_score_}\")\n",
        "    print(f\"‚û° Best Params: {grid.best_params_}\")\n",
        "\n",
        "print(\"\\n============================\")\n",
        "print(\" FINAL COMPARISON SUMMARY \")\n",
        "print(\"============================\")\n",
        "\n",
        "for name in best_models:\n",
        "    print(f\"\\nModel: {name.upper()}\")\n",
        "    print(f\"Best CV Score: {best_scores[name]}\")\n",
        "    print(f\"Best Params: {best_params[name]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na_n6PId6Dmn"
      },
      "source": [
        "## **Prediction on unknown data** \n",
        "\n",
        "or take input from users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pressure = float(input(\"enter the pressure : \"))\n",
        "dewpoint = float(input(\"enter the pressure : \"))\n",
        "\n",
        "pd.DataFrame([pressure,dewpoint])\n",
        "# rainfall_prediction_model.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMCgSQh95tlQ"
      },
      "outputs": [],
      "source": [
        "input_data = (1015.9, 19.9, 95, 81, 0.0, 40.0, 13.7)\n",
        "\n",
        "input_df = pd.DataFrame([input_data], columns=['pressure', 'dewpoint', 'humidity', 'cloud', 'sunshine','winddirection', 'windspeed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "LIMsmZnb6hcG",
        "outputId": "0b7eefcd-5715-4a87-8e1a-2b98f83f96c7"
      },
      "outputs": [],
      "source": [
        "input_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDJNgnHF7GNc"
      },
      "outputs": [],
      "source": [
        "prediction = best_rf_model.predict(input_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxOl-o5L7GKv",
        "outputId": "8319c92e-a652-42be-e785-773a35cdc4f7"
      },
      "outputs": [],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9PluHKv7JsG",
        "outputId": "7c437001-c648-4a38-888a-8a5922baa179"
      },
      "outputs": [],
      "source": [
        "prediction[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjqouBN6ihz",
        "outputId": "ce1170d5-180e-4a13-8ba1-52f67be3f064"
      },
      "outputs": [],
      "source": [
        "prediction = best_rf_model.predict(input_df)\n",
        "print(\"Prediction result:\", \"yes Rainfall happen \" if prediction[0] == 1 else \"No Rainfall not happen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsJR2Kz47FEv"
      },
      "outputs": [],
      "source": [
        "# save model and feature names to a pickle file\n",
        "model_data = {\"model\": best_rf_model, \"feature_names\": X.columns.tolist()}\n",
        "\n",
        "with open(\"rainfall_prediction_model.pkl\", \"wb\") as file:\n",
        "  pickle.dump(model_data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D69tJr-z76J4"
      },
      "source": [
        "**Load the saved model and file and use it for prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfzzq7Ea7rsi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7XSWrIT8CSK"
      },
      "outputs": [],
      "source": [
        "# load the trained model and feature names from the pickle file\n",
        "with open(\"rainfall_prediction_model.pkl\", \"rb\") as file:\n",
        "  model_data = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjUUrlal8LuA"
      },
      "outputs": [],
      "source": [
        "model = model_data[\"model\"]\n",
        "feature_names = model_data[\"feature_names\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYximjll8ThL"
      },
      "outputs": [],
      "source": [
        "input_data = (1015.9, 19.9, 95, 81, 0.0, 40.0, 13.7)\n",
        "\n",
        "input_df = pd.DataFrame([input_data], columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4wThCd08dgR",
        "outputId": "a4d9a4ac-009a-4483-8a12-5891391d214b"
      },
      "outputs": [],
      "source": [
        "prediction = best_rf_model.predict(input_df)\n",
        "print(\"Prediction result:\", \"Rainfall\" if prediction[0] == 1 else \"No Rainfall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shCCUs0-8gBL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaJat3C38uo4"
      },
      "source": [
        "**To Try:**\n",
        "1. SMOTE for class balancing\n",
        "2. PCA for dimensionality reduction\n",
        "3. Simpler models like Logistic Regression (with Feature scaling)\n",
        "4. Model Selection with hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn1omU-s8uKN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a3euO8o8uHf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a **complete Streamlit project** you can run locally for **Rainfall Prediction** using your uploaded dataset (`Rainfall.csv`).\n",
        "I‚Äôm giving you **full project structure + code for each file** so you can copy-paste and run immediately.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **üåßÔ∏è Rainfall Prediction Streamlit Project**\n",
        "\n",
        "---\n",
        "\n",
        "# üìÅ **Project Structure**\n",
        "\n",
        "```\n",
        "rainfall_prediction_app/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ app.py\n",
        "‚îú‚îÄ‚îÄ model.py\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îî‚îÄ‚îÄ Rainfall.csv   ‚Üê your dataset\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üîÆ **1. model.py ‚Äî Train & Save Model**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import joblib\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    df = pd.read_csv(\"Rainfall.csv\")\n",
        "\n",
        "    # --- BASIC CLEANING (customize based on your dataset) ---\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Assuming \"Rainfall\" is the target variable\n",
        "    X = df.drop(\"Rainfall\", axis=1)\n",
        "    y = df[\"Rainfall\"]\n",
        "\n",
        "    # Convert categorical columns if present\n",
        "    X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    model = RandomForestRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    joblib.dump((model, X.columns), \"rainfall_model.pkl\")\n",
        "\n",
        "    return \"Model trained & saved as rainfall_model.pkl\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(train_model())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üé® **2. app.py ‚Äî Streamlit UI for Predictions**\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "st.title(\"üåßÔ∏è Rainfall Prediction App\")\n",
        "st.write(\"Upload input values and get rainfall predictions!\")\n",
        "\n",
        "# Load model\n",
        "model, feature_names = joblib.load(\"rainfall_model.pkl\")\n",
        "\n",
        "# Sidebar Input Form\n",
        "st.sidebar.header(\"Input Features\")\n",
        "\n",
        "input_data = {}\n",
        "\n",
        "for feature in feature_names:\n",
        "    input_data[feature] = st.sidebar.number_input(f\"Enter {feature}\", value=0.0)\n",
        "\n",
        "# Convert to DataFrame\n",
        "input_df = pd.DataFrame([input_data])\n",
        "\n",
        "# Prediction\n",
        "if st.button(\"Predict Rainfall\"):\n",
        "    prediction = model.predict(input_df)[0]\n",
        "    st.success(f\"üåßÔ∏è Predicted Rainfall: **{prediction:.2f} mm**\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üì¶ **3. requirements.txt**\n",
        "\n",
        "```\n",
        "streamlit\n",
        "pandas\n",
        "scikit-learn\n",
        "joblib\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ‚ñ∂Ô∏è **How to Run the App Locally**\n",
        "\n",
        "### **Step 1: Install dependencies**\n",
        "\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### **Step 2: Train the model**\n",
        "\n",
        "```\n",
        "python model.py\n",
        "```\n",
        "\n",
        "### **Step 3: Run Streamlit**\n",
        "\n",
        "```\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üéâ Your Rainfall Prediction App is Ready!\n",
        "\n",
        "If you want:\n",
        "\n",
        "‚úÖ Add graphs\n",
        "‚úÖ Add EDA dashboard\n",
        "‚úÖ Add model selection (RandomForest/XGBoost/Linear Regression)\n",
        "‚úÖ Add UI styling\n",
        "‚úÖ Deploy to Streamlit Cloud or Hugging Face\n",
        "\n",
        "Just tell me ‚Äî I can upgrade this into a full production-level project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Below is the **fully upgraded Streamlit Rainfall Prediction Project** with:\n",
        "\n",
        "‚úÖ **Model Selection**\n",
        "‚ÄÉ‚Äî Random Forest\n",
        "‚ÄÉ‚Äî XGBoost\n",
        "‚ÄÉ‚Äî Linear Regression\n",
        "\n",
        "‚úÖ **EDA Dashboard**\n",
        "‚ÄÉ‚Äî Dataset preview\n",
        "‚ÄÉ‚Äî Summary statistics\n",
        "‚ÄÉ‚Äî Missing values\n",
        "‚ÄÉ‚Äî Correlation heatmap\n",
        "‚ÄÉ‚Äî Histograms & boxplots\n",
        "\n",
        "‚úÖ **Graphs**\n",
        "‚ÄÉ‚Äî Prediction vs Actual\n",
        "‚ÄÉ‚Äî Feature importance\n",
        "\n",
        "---\n",
        "\n",
        "# üìÅ **UPDATED PROJECT STRUCTURE**\n",
        "\n",
        "```\n",
        "rainfall_prediction_app/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ app.py\n",
        "‚îú‚îÄ‚îÄ train_model.py\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îî‚îÄ‚îÄ Rainfall.csv\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìå **1. train_model.py (Full Model Training + Saving)**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "\n",
        "def train_all_models():\n",
        "\n",
        "    df = pd.read_csv(\"Rainfall.csv\")\n",
        "    df = df.dropna()\n",
        "\n",
        "    y = df[\"Rainfall\"]\n",
        "    X = df.drop(\"Rainfall\", axis=1)\n",
        "\n",
        "    # One-Hot Encode categorical columns\n",
        "    X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    models = {\n",
        "        \"RandomForest\": RandomForestRegressor(),\n",
        "        \"LinearRegression\": LinearRegression(),\n",
        "        \"XGBoost\": XGBRegressor(objective='reg:squarederror')\n",
        "    }\n",
        "\n",
        "    # Train & save each model\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        joblib.dump((model, X.columns), f\"{model_name}.pkl\")\n",
        "\n",
        "    return \"All models trained & saved!\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(train_all_models())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìå **2. app.py (Full Streamlit App: EDA + Model Selection + Prediction + Graphs)**\n",
        "\n",
        "```python\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# -------------------------------------------\n",
        "# App Title\n",
        "# -------------------------------------------\n",
        "st.title(\"üåßÔ∏è Rainfall Prediction System\")\n",
        "st.write(\"Select model, explore EDA, and predict rainfall.\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# Load Dataset\n",
        "# -------------------------------------------\n",
        "df = pd.read_csv(\"Rainfall.csv\")\n",
        "\n",
        "# -------------------------------------------\n",
        "# Sidebar Options\n",
        "# -------------------------------------------\n",
        "st.sidebar.header(\"Navigation\")\n",
        "options = st.sidebar.radio(\n",
        "    \"Go to\",\n",
        "    [\"EDA Dashboard\", \"Prediction\"]\n",
        ")\n",
        "\n",
        "# -------------------------------------------\n",
        "# EDA Dashboard\n",
        "# -------------------------------------------\n",
        "if options == \"EDA Dashboard\":\n",
        "    st.subheader(\"üìä Exploratory Data Analysis\")\n",
        "\n",
        "    st.write(\"### ‚û§ Dataset Preview\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "    st.write(\"### ‚û§ Summary Statistics\")\n",
        "    st.dataframe(df.describe())\n",
        "\n",
        "    st.write(\"### ‚û§ Missing Values\")\n",
        "    st.dataframe(df.isnull().sum())\n",
        "\n",
        "    st.write(\"### ‚û§ Correlation Heatmap\")\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", ax=ax)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    st.write(\"### ‚û§ Feature Distributions\")\n",
        "    for col in df.select_dtypes(include=np.number).columns:\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.histplot(df[col], kde=True, ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    st.write(\"### ‚û§ Boxplots\")\n",
        "    for col in df.select_dtypes(include=np.number).columns:\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.boxplot(x=df[col], ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "# -------------------------------------------\n",
        "# Prediction Page\n",
        "# -------------------------------------------\n",
        "elif options == \"Prediction\":\n",
        "\n",
        "    st.subheader(\"üîÆ Predict Rainfall\")\n",
        "\n",
        "    # Model Selection\n",
        "    model_name = st.selectbox(\n",
        "        \"Choose Model\",\n",
        "        [\"RandomForest\", \"LinearRegression\", \"XGBoost\"]\n",
        "    )\n",
        "\n",
        "    # Load selected model\n",
        "    model, feature_names = joblib.load(f\"{model_name}.pkl\")\n",
        "\n",
        "    st.write(f\"### ‚úî Loaded model: **{model_name}**\")\n",
        "\n",
        "    # Input Fields\n",
        "    input_data = {}\n",
        "\n",
        "    st.write(\"### üîß Enter Feature Values\")\n",
        "\n",
        "    for feature in feature_names:\n",
        "        value = st.number_input(f\"{feature}\", value=0.0)\n",
        "        input_data[feature] = value\n",
        "\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "\n",
        "    # Predict\n",
        "    if st.button(\"Predict Rainfall\"):\n",
        "        prediction = model.predict(input_df)[0]\n",
        "        st.success(f\"üåßÔ∏è Predicted Rainfall: **{prediction:.2f} mm**\")\n",
        "\n",
        "    # Feature Importance - only for RF & XGB\n",
        "    if st.checkbox(\"Show Feature Importance (RF & XGB only)\"):\n",
        "        if model_name in [\"RandomForest\", \"XGBoost\"]:\n",
        "            importances = model.feature_importances_\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            sns.barplot(x=feature_names, y=importances)\n",
        "            plt.xticks(rotation=90)\n",
        "            st.pyplot(fig)\n",
        "        else:\n",
        "            st.info(\"Feature importance not available for Linear Regression.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìå **3. requirements.txt**\n",
        "\n",
        "```\n",
        "streamlit\n",
        "pandas\n",
        "scikit-learn\n",
        "xgboost\n",
        "joblib\n",
        "seaborn\n",
        "matplotlib\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ‚ñ∂Ô∏è **How to Run the App**\n",
        "\n",
        "### **Step 1 ‚Äî Install packages**\n",
        "\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### **Step 2 ‚Äî Train all models**\n",
        "\n",
        "```\n",
        "python train_model.py\n",
        "```\n",
        "\n",
        "### **Step 3 ‚Äî Start Streamlit app**\n",
        "\n",
        "```\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üéâ DONE!\n",
        "\n",
        "Your app now includes:\n",
        "\n",
        "### ‚úÖ Full EDA Dashboard\n",
        "\n",
        "### ‚úÖ Interactive visualizations\n",
        "\n",
        "### ‚úÖ Model selection\n",
        "\n",
        "### ‚úÖ Feature importance\n",
        "\n",
        "### ‚úÖ Prediction interface\n",
        "\n",
        "### ‚úÖ XGBoost + RandomForest + Linear Regression\n",
        "\n",
        "---\n",
        "\n",
        "If you want:\n",
        "\n",
        "üöÄ Add model comparison\n",
        "üåê Deploy on Streamlit Cloud\n",
        "üìä Add time-series graphs\n",
        "üìÅ Add file upload option\n",
        "üéõ Advanced preprocessing (scaling, encoding)\n",
        "\n",
        "Just tell me ‚Äî I can upgrade!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
