{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e40541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_models.py\n",
    "===================\n",
    "Train multiple regression models on IPL ball‚Äëby‚Äëball data, evaluate them, save the best\n",
    "one (based on lowest Mean Absolute Error), plus artefacts required by the Streamlit app\n",
    "(label encoders and scaler).\n",
    "\n",
    "USAGE:\n",
    "    python train_models.py --data ipl_data.csv\n",
    "\n",
    "Outputs (in ./models):\n",
    "    best_model.pkl          ‚Äì scikit‚Äëlearn estimator\n",
    "    scaler.pkl              ‚Äì MinMaxScaler fitted on features\n",
    "    encoders.pkl            ‚Äì dict of LabelEncoders keyed by column name\n",
    "    report.csv              ‚Äì table of model ‚Üí MAE sorted ascending\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Optional libraries ‚Äì install if available\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    HAS_LGBM = True\n",
    "except ImportError:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "MODELS = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.001),\n",
    "    \"Polynomial2\": Pipeline([(\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                              (\"lr\", LinearRegression())]),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=10, epsilon=0.1),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=8, random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42, n_jobs=-1),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=300, learning_rate=0.05, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "if HAS_XGB:\n",
    "    MODELS[\"XGBoost\"] = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                                     subsample=0.8, colsample_bytree=0.8, objective=\"reg:squarederror\",\n",
    "                                     random_state=42)\n",
    "if HAS_LGBM:\n",
    "    MODELS[\"LightGBM\"] = LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=-1,\n",
    "                                       subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "\n",
    "def preprocess(df: pd.DataFrame):\n",
    "    # label encode high‚Äëcardinality categoricals (same as original notebook)\n",
    "    cat_cols = [\"bat_team\", \"bowl_team\", \"venue\", \"batsman\", \"bowler\"]\n",
    "\n",
    "    label_encoders = {}\n",
    "    for c in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[c] = le.fit_transform(df[c])\n",
    "        label_encoders[c] = le\n",
    "\n",
    "    feature_cols = [\"bat_team\", \"bowl_team\", \"venue\", \"runs\", \"wickets\",\n",
    "                    \"overs\", \"striker\", \"batsman\", \"bowler\"]\n",
    "\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[\"total\"].copy()\n",
    "    return X, y, label_encoders\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", required=True)\n",
    "    parser.add_argument(\"--out\", default=\"models\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    out_dir = Path(args.out)\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    data = pd.read_csv(args.data)\n",
    "    X, y, encoders = preprocess(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_s = scaler.transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    scores = {}\n",
    "    for name, model in MODELS.items():\n",
    "        model.fit(X_train_s, y_train)\n",
    "        preds = model.predict(X_test_s)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        scores[name] = mae\n",
    "        print(f\"{name:15s}  MAE = {mae:.2f}\")\n",
    "\n",
    "    # pick best (lowest MAE)\n",
    "    best_name = min(scores, key=scores.get)\n",
    "    best_model = MODELS[best_name]\n",
    "\n",
    "    # persist artefacts\n",
    "    joblib.dump(best_model, out_dir / \"best_model.pkl\")\n",
    "    joblib.dump(encoders, out_dir / \"encoders.pkl\")\n",
    "    joblib.dump(scaler, out_dir / \"scaler.pkl\")\n",
    "    pd.Series(scores).sort_values().to_csv(out_dir / \"report.csv\", header=[\"MAE\"])\n",
    "\n",
    "    print(f\"\\nBest model: {best_name} (MAE={scores[best_name]:.2f}). Saved to '{out_dir}'.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"app.py\n",
    "========\n",
    "A Streamlit web app that loads the best saved model plus scaler & encoders and provides\n",
    "an interactive form for predicting the final innings total.\n",
    "\n",
    "RUN:\n",
    "    streamlit run app.py\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(__file__).parent / \"models\"\n",
    "encoders = joblib.load(MODEL_DIR / \"encoders.pkl\")\n",
    "scaler = joblib.load(MODEL_DIR / \"scaler.pkl\")\n",
    "model = joblib.load(MODEL_DIR / \"best_model.pkl\")\n",
    "\n",
    "st.set_page_config(page_title=\"IPL Score Predictor\", page_icon=\"üèè\", layout=\"centered\")\n",
    "st.title(\"üèè IPL Final Score Predictor (ML edition)\")\n",
    "\n",
    "# Convenience ‚Äì sort for nicer UX\n",
    "venues = sorted(encoders[\"venue\"].classes_)\n",
    "bat_teams = sorted(encoders[\"bat_team\"].classes_)\n",
    "bowl_teams = sorted(encoders[\"bowl_team\"].classes_)\n",
    "batsmen = sorted(encoders[\"batsman\"].classes_)\n",
    "bowlers = sorted(encoders[\"bowler\"].classes_)\n",
    "\n",
    "with st.form(\"predict_form\"):\n",
    "    c1, c2 = st.columns(2)\n",
    "    venue = c1.selectbox(\"Venue\", venues)\n",
    "    bat_team = c1.selectbox(\"Batting team\", bat_teams)\n",
    "    bowl_team = c1.selectbox(\"Bowling team\", bowl_teams)\n",
    "    striker = c1.selectbox(\"Current striker\", batsmen)\n",
    "    bowler = c1.selectbox(\"Current bowler\", bowlers)\n",
    "\n",
    "    runs = c2.number_input(\"Current runs scored\", min_value=0, value=0, step=1)\n",
    "    wickets = c2.number_input(\"Wickets down\", min_value=0, value=0, step=1)\n",
    "    overs = c2.number_input(\"Overs completed\", min_value=0.0, max_value=20.0, value=0.0, step=0.1)\n",
    "    striker_ind = c2.number_input(\"Striker indicator (0 or 1)\", min_value=0, max_value=1, value=0, step=1)\n",
    "\n",
    "    submitted = st.form_submit_button(\"Predict\")\n",
    "\n",
    "if submitted:\n",
    "    # Encode categoricals\n",
    "    encoded_inputs = [\n",
    "        encoders[\"bat_team\"].transform([bat_team])[0],\n",
    "        encoders[\"bowl_team\"].transform([bowl_team])[0],\n",
    "        encoders[\"venue\"].transform([venue])[0],\n",
    "        runs,\n",
    "        wickets,\n",
    "        overs,\n",
    "        striker_ind,\n",
    "        encoders[\"batsman\"].transform([striker])[0],\n",
    "        encoders[\"bowler\"].transform([bowler])[0],\n",
    "    ]\n",
    "\n",
    "    features = np.array(encoded_inputs).reshape(1, -1)\n",
    "    features_scaled = scaler.transform(features)\n",
    "    pred_total = model.predict(features_scaled)[0]\n",
    "\n",
    "    st.success(f\"üèÜ Predicted Final Score: **{pred_total:.0f} runs**\")\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b166bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f760da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d180e6a",
   "metadata": {},
   "source": [
    "# IPL Score Prediction using Multiple ML Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    HAS_LGBM = True\n",
    "except ImportError:\n",
    "    HAS_LGBM = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e849b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Step 2: Load and Preprocess Data\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"ipl_data.csv\")\n",
    "data = data.copy()\n",
    "\n",
    "cat_cols = [\"bat_team\", \"bowl_team\", \"venue\", \"batsman\", \"bowler\"]\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "feature_cols = [\"bat_team\", \"bowl_team\", \"venue\", \"runs\", \"wickets\", \"overs\", \"striker\", \"batsman\", \"bowler\"]\n",
    "X = data[feature_cols]\n",
    "y = data[\"total\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fbb454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Step 3: Train-Test Split and Scaling\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "## Step 4: Define ML Models\n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.001),\n",
    "    \"Polynomial2\": Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"lr\", LinearRegression())\n",
    "    ]),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=10, epsilon=0.1),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=8, random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=300, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=300, learning_rate=0.05, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "if HAS_XGB:\n",
    "    MODELS[\"XGBoost\"] = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                                     subsample=0.8, colsample_bytree=0.8, objective=\"reg:squarederror\",\n",
    "                                     random_state=42)\n",
    "if HAS_LGBM:\n",
    "    MODELS[\"LightGBM\"] = LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3223d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression    : MAE = 14.90\n",
      "Ridge               : MAE = 14.91\n",
      "Lasso               : MAE = 14.90\n",
      "Polynomial2         : MAE = 14.34\n",
      "SVR                 : MAE = 13.40\n",
      "DecisionTree        : MAE = 14.98\n",
      "RandomForest        : MAE = 4.35\n",
      "AdaBoost            : MAE = 18.08\n",
      "GradientBoosting    : MAE = 14.35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>4.352683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>13.403773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial2</th>\n",
       "      <td>14.344442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>14.352597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>14.904315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>14.904519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>14.905624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>14.977850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>18.076771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MAE\n",
       "RandomForest       4.352683\n",
       "SVR               13.403773\n",
       "Polynomial2       14.344442\n",
       "GradientBoosting  14.352597\n",
       "LinearRegression  14.904315\n",
       "Lasso             14.904519\n",
       "Ridge             14.905624\n",
       "DecisionTree      14.977850\n",
       "AdaBoost          18.076771"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 5: Train and Evaluate All Models\n",
    "from sklearn.metrics import r2_score\n",
    "results = {}\n",
    "\n",
    "for name, model in MODELS.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2  = r2_score(y_test, preds)\n",
    "    results[name] = mae\n",
    "    print(f\"{name:<20}: MAE = {mae:.2f} , R2 Score = {r2:.2f}\")\n",
    "\n",
    "results_df = pd.Series(results).sort_values().to_frame(\"MAE\")\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4971525",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Save Best Model, Scaler, Encoders\n",
    "\n",
    "best_model_name = results_df.idxmin().values[0]\n",
    "best_model = MODELS[best_model_name]\n",
    "\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "joblib.dump(best_model, \"models/best_model.pkl\")\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"models/encoders.pkl\")\n",
    "results_df.to_csv(\"models/report.csv\")\n",
    "\n",
    "print(f\"Best model: {best_model_name} saved successfully.\")\n",
    "\n",
    "\n",
    "## Step 7: Ready for Streamlit Interface\n",
    "# You can now use `app.py` to load these artefacts and predict via Streamlit.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
